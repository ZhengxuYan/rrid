Link/DOI,Publication Date,Title,Authors,Abstract
https://arxiv.org/abs/2403.00763,2024-03-01,Optical modeling of systematic uncertainties in detector polarization angles for the Atacama Cosmology Telescope,"['Colin C. Murphy', 'Steve K. Choi', 'Rahul Datta', 'Mark J. Devlin', 'Matthew Hasselfield', 'Brian J. Koopman', 'Jeff McMahon', 'Sigurd Naess', 'Michael D. Niemack', 'Lyman A. Page', 'Suzanne T. Staggs', 'Robert Thornton', 'Edward J. Wollack']","We present an estimate of the Atacama Cosmology Telescope (ACT) detector polarization angle systematic uncertainty from optics perturbation analysis using polarization-sensitive ray tracing in CODE V optical design software. Uncertainties in polarization angle calibration in CMB measurements can limit constraints on cosmic birefringence and other cosmological measurements. Our framework estimates the angle calibration systematic uncertainties from possible displacements in lens positions and orientations, and anti-reflection coating (ARC) thicknesses and refractive indices. With millimeter displacements in lens positions and percent-level perturbations in ARC thicknesses and indices from design, we find the total systematic uncertainty for three ACT detector arrays operating between 90--220 GHz to be at the tenth of degree scale. Reduced lens position and orientation uncertainties from physical measurements could lead to a reduction in the systematic uncertainty estimated with the framework presented here. This optical modeling can inform polarization angle systematic uncertainties for current and future microwave polarimeters, such as the CCAT Observatory, Simons Observatory, and CMB-S4."
https://arxiv.org/abs/2403.00762,2024-03-01,Point Could Mamba: Point Cloud Learning via State Space Model,"['Tao Zhang', 'Xiangtai Li', 'Haobo Yuan', 'Shunping Ji', 'Shuicheng Yan']","In this work, for the first time, we demonstrate that Mamba-based point cloud methods can outperform point-based methods. Mamba exhibits strong global modeling capabilities and linear computational complexity, making it highly attractive for point cloud analysis. To enable more effective processing of 3-D point cloud data by Mamba, we propose a novel Consistent Traverse Serialization to convert point clouds into 1-D point sequences while ensuring that neighboring points in the sequence are also spatially adjacent. Consistent Traverse Serialization yields six variants by permuting the order of x, y, and z coordinates, and the synergistic use of these variants aids Mamba in comprehensively observing point cloud data. Furthermore, to assist Mamba in handling point sequences with different orders more effectively, we introduce point prompts to inform Mamba of the sequence's arrangement rules. Finally, we propose positional encoding based on spatial coordinate mapping to inject positional information into point cloud sequences better. Based on these improvements, we construct a point cloud network named Point Cloud Mamba, which combines local and global modeling. Point Cloud Mamba surpasses the SOTA point-based method PointNeXt and achieves new SOTA performance on the ScanObjectNN, ModelNet40, and ShapeNetPart datasets."
https://arxiv.org/abs/2403.00761,2024-03-01,Orbital analysis of stars in the nuclear stellar disc of the Milky Way,"['N. Nieuwmunster', 'M. Schultheis', 'M. Sormani', 'F. Fragkoudi', 'F. Nogueras-Lara', 'R. SchÃ¶del', 'P. McMillan']","While orbital analysis studies were so far mainly focused on the Galactic halo, it is possible now to do these studies in the heavily obscured region close to the Galactic Centre. We aim to do a detailed orbital analysis of stars located in the nuclear stellar disc (NSD) of the Milky Way allowing us to trace the dynamical history of this structure. We integrated orbits of the observed stars in a non-axisymmetric potential. We used a Fourier transform to estimate the orbital frequencies. We compared two orbital classifications, one made by eye and the other with an algorithm, in order to identify the main orbital families. We also compared the Lyapunov and the frequency drift techniques to estimate the chaoticity of the orbits. We identified several orbital families as chaotic, $z$-tube, $x$-tube, banana, fish, saucer, pretzel, 5:4, and 5:6 orbits. As expected for stars located in a NSD, the large majority of orbits are identified as $z$-tubes (or as a sub-family of $z$-tubes). Since the latter are parented by $x_{2}$ orbits, this result supports the contribution of the bar (in which $x_{2}$ orbits are dominant in the inner region) in the formation of the NSD. Moreover, most of the chaotic orbits are found to be contaminants from the bar or bulge which would confirm the predicted contamination from the most recent NSD models. Based on a detailed orbital analysis, we were able to classify orbits into various families, most of which are parented by $x_{2}$-type orbits, which are dominant in the inner part of the bar."
https://arxiv.org/abs/2403.00760,2024-03-01,"Faulhaber's formula, Bernoulli numbers and the equation $f(x)+x^k=f(x+1)$",['Chai Wah Wu'],In modern usage the Bernoulli numbers and polynomials follow Euler's approach and are defined using generating functions. We consider the functional equation $f(x)+x^k=f(x+1)$ and show that a solution can be derived from Faulhaber's formula for the sum of powers. We show how these solutions provide a characterization of Bernoulli numbers and related results.
https://arxiv.org/abs/2403.00759,2024-03-01,Large deformations in terms of stretch and rotation and local solution to the non-stationary problem,"['Abramo Agosti', 'Michel Fremond']","In this paper we consider and generalize a model, recently proposed and analytically investigated in its quasi-stationary approximation by the authors, for visco-elasticity with large deformations and conditional compatibility, where the independent variables are the stretch and the rotation tensors. The model takes the form of a system of integro-differential coupled equations. Here, its derivation is generalized to consider mixed boundary conditions, which may represent a wider range of physical applications then the case with Dirichlet boundary conditions considered in our previous contribution. This also introduces nontrivial technical difficulties in the theoretical framework, related to the definition and the regularity of the solutions of elliptic operators with mixed boundary conditions. As a novel contribution, we develop the analysis of the fully non-stationary version of the system where we consider inertia. In this context, we prove the existence of a local in time weak solution in three space dimensions, employing techniques from PDEs and convex analysis."
https://arxiv.org/abs/2403.00758,2024-03-01,Mitigating Reversal Curse via Semantic-aware Permutation Training,"['Qingyan Guo', 'Rui Wang', 'Junliang Guo', 'Xu Tan', 'Jiang Bian', 'Yujiu Yang']","While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the ""reversal curse"". It is a typical example that the model knows ""A's father is B"", but is unable to reason ""B's child is A"". This limitation poses a challenge to the advancement of artificial general intelligence (AGI), as it suggests a gap in the models' ability to comprehend and apply bidirectional reasoning. In this paper, we first conduct substantial evaluation and identify that the root cause of the reversal curse lies in the different word order between the training and inference stage, namely, the poor ability of causal language models to predict antecedent words within the training data. Accordingly, permutation on the training data is considered as a potential solution, since this can make the model predict antecedent words or tokens. However, previous permutation methods may disrupt complete phrases or entities, thereby posing challenges for the model to comprehend and learn from training data. To address this issue, we propose Semantic-aware Permutation Training (SPT), which addresses this issue by segmenting the training sentences into semantic units (i.e., entities or phrases) with an assistant language model and permuting these units before feeding into the model. Extensive experiments demonstrate that SPT effectively mitigates the reversal curse since the performance on reversed questions approximates that on the forward ones, and significantly advances the performance of existing works."
https://arxiv.org/abs/2403.00757,2024-03-01,Investigating Ionization in the Intergalactic Medium,"['Brad Koplitz', 'Anjali Ramesh', 'Sanchayeeta Borthakur']","The Intergalactic Medium (IGM) contains $>$50% of the baryonic mass of the Universe, yet the mechanisms responsible for keeping the IGM ionized has not been fully explained. Hence, we investigate ion abundances from the largest blind QSO absorption catalog for clouds that show C IV, N V, and O VI simultaneously. The wavelength range of present UV spectrographs, however, make it possible to probe C IV and O VI over a small range of redshift ($z \approx 0.12 - 0.15$). As a result, we only have five IGM absorbing clouds, yet these provide a powerful and representative tool to probe the IGM ionization state. We found one cloud to be in collisional ionization equilibrium while three of five showed signs of being produced by non-equilibrium processes, specifically conductive interfaces and turbulent mixing layers. None of the models we explore here were able to reproduce the ionization state of the remaining system. Energetic processes, such as galactic feedback from star formation and AGN winds, would be excellent candidates that can cause such widespread ionization."
https://arxiv.org/abs/2403.00756,2024-03-01,Scalable Multispecies Ion Transport in a Grid Based Surface-Electrode Trap,"['Robert D. Delaney', 'Lucas R. Sletten', 'Matthew J. Cich', 'Brian Estey', 'Maya Fabrikant', 'David Hayes', 'Ian M. Hoffman', 'James Hostetter', 'Christopher Langer', 'Steven A. Moses', 'Abigail R. Perry', 'Timothy A. Peterson', 'Andrew Schaffer', 'Curtis Volin', 'Grahame Vittorini', 'William Cody Burton']","We present a scalable method for the control of ion crystals in a grid-based surface electrode Paul trap and characterize it in the context of transport operations that sort and reorder multispecies crystals. By combining co-wiring of control electrodes at translationally symmetric locations in each grid site with the site-wise ability to exchange the voltages applied to two special electrodes gated by a binary input, site-dependent operations are achieved using only a fixed number of analog voltage signals and a single digital input per site. In two separate experimental systems containing nominally identical grid traps, one using $^{171}\mathrm{Yb}^{+}$-$^{138}\mathrm{Ba}^{+}$ crystals and the other $^{137}\mathrm{Ba}^{+}$-$^{88}\mathrm{Sr}^{+}$, we demonstrate this method by characterizing the conditional intra-site crystal reorder and the conditional exchange of ions between adjacent sites on the grid. Averaged across a multi-site region of interest, we measure sub-quanta motional excitation in the axial in-phase and out-of-phase modes of the crystals following these operations at exchange rates of 2.5 kHz. These conditional transport operations display all necessary components for sorting qubits, and could be extended to implement other conditional operations involving control fields such as gates, initialization, and measurement."
https://arxiv.org/abs/2403.00755,2024-03-01,Carbon-contaminated topological defects in hBN: a potential new class of single photon emitters,"['Rohit Babar', 'Igor A. Abrikosov', 'Gergely Barcza', 'Viktor IvÃ¡dy']","Topological defects, such as Stone-Wales defects and grain boundaries, are common in 2D materials. In this exploratory study, we investigate the intricate interplay of carbon contamination and topological defects revealing a new class of color centers in hexagonal boron nitride. We demonstrate that carbon contamination and strain can both stabilize Stone-Wales configurations with desirable optical properties. Inspired by these results, we further demonstrate that carbon atoms at grain boundaries can resolve energetic B-B and N-N bonds and give rise to highly favorable atomic structures potentially leading to the accumulation of carbon contamination at grain boundaries. We identify carbon-contaminated topological defects that give rise to color centers emitting in the visible spectral range with short radiative lifetime and high Debye-Waller factors. Our discoveries shed light on a new class of defects and pave the way towards the identification of color centers and single photon emitters in hBN."
https://arxiv.org/abs/2403.00754,2024-03-01,The quark-mass dependence of the potential energy between static colour sources in the QCD vacuum with light and strange quarks,"['John Bulava', 'Francesco Knechtli', 'Vanessa Koch', 'Colin Morningstar', 'Michael Peardon']","The low-lying energy spectrum of the static-colour-source-anti-source system in a vacuum containing light and strange quarks is computed using lattice QCD for a range of different light quark masses. The resulting levels are described using a simple model Hamiltonian and the parameters in this model are extrapolated to the physical light-quark masses. In this framework, the QCD string tension is found to be $\sqrtÏ=445(3)_{\rm stat}(6)_{\rm sys}$ MeV."
https://arxiv.org/abs/2403.00753,2024-03-01,The role of the likelihood for elastic scattering uncertainty quantification,"['C. D. Pruitt', 'A. E. Lovell', 'C. Hebborn', 'F. M. Nunes']",Background: Analyses of elastic scattering with the optical model (OMP) are widely used in nuclear reactions.
https://arxiv.org/abs/2403.00752,2024-03-01,An Experimental Study of Low-Latency Video Streaming over 5G,"['Imran Khan', 'Tuyen X. Tran', 'Matti Hiltunen', 'Theodore Karagioules', 'Dimitrios Koutsonikolas']","Low-latency video streaming over 5G has become rapidly popular over the last few years due to its increased usage in hosting virtual events, online education, webinars, and all-hands meetings. Our work aims to address the absence of studies that reveal the real-world behavior of low-latency video streaming. To that end, we provide an experimental methodology and measurements, collected in a US metropolitan area over a commercial 5G network, that correlates application-level QoE and lower-layer metrics on the devices, such as RSRP, RSRQ, handover records, etc., under both static and mobility scenarios. We find that RAN-side information, which is readily available on every cellular device, has the potential to enhance throughput estimation modules of video streaming clients, ultimately making low-latency streaming more resilient against network perturbations and handover events."
https://arxiv.org/abs/2403.00751,2024-03-01,Machine learning that predicts well may not learn the correct physical descriptions of glassy systems,"['Arabind Swain', 'Sean Alexander Ridout', 'Ilya Nemenman']","The complexity of glasses makes it challenging to explain their dynamics. Machine Learning (ML) has emerged as a promising pathway for understanding glassy dynamics by linking their structural features to rearrangement dynamics. Support Vector Machine (SVM) was one of the first methods used to detect such correlations. Specifically, a certain output of SVMs trained to predict dynamics from structure, the distance from the separating hyperplane, was interpreted as being linearly related to the activation energy for the rearrangement. By numerical analysis of toy models, we explore under which conditions it is possible to infer the energy barrier to rearrangements from the distance to the separating hyperplane. We observe that such successful inference is possible only under very restricted conditions. Typical tests, such as the apparent Arrhenius dependence of the probability of rearrangement on the inferred energy and the temperature, or high cross-validation accuracy do not guarantee success. We propose practical approaches for measuring the quality of the energy inference and for modifying the inferred model to improve the inference, which should be usable in the context of realistic datasets."
https://arxiv.org/abs/2403.00750,2024-03-01,"Edge open packing: complexity, algorithmic aspects, and bounds","['BoÅ¡tjan BreÅ¡ar', 'Babak Samadi']","Given a graph $G$, two edges $e_{1},e_{2}\in E(G)$ are said to have a common edge $e$ if $e$ joins an endvertex of $e_{1}$ to an endvertex of $e_{2}$. A subset $B\subseteq E(G)$ is an edge open packing set in $G$ if no two edges of $B$ have a common edge in $G$, and the maximum cardinality of such a set in $G$ is called the edge open packing number, $Ï_{e}^{o}(G)$, of $G$. In this paper, we prove that the decision version of the edge open packing number is NP-complete even when restricted to graphs with universal vertices, Eulerian bipartite graphs, and planar graphs with maximum degree $4$, respectively. In contrast, we present a linear-time algorithm that computes the edge open packing number of a tree. We also resolve two problems posed in the seminal paper [Edge open packing sets in graphs, RAIRO-Oper.\ Res.\ 56 (2022) 3765--3776]. Notably, we characterize the graphs $G$ that attain the upper bound $Ï_e^o(G)\le |E(G)|/Î´(G)$, and provide lower and upper bounds for the edge-deleted subgraph of a graph and establish the corresponding realization result."
https://arxiv.org/abs/2403.00749,2024-03-01,Shrinkage estimators in zero-inflated Bell regression model with application,"['Solmaz Seifollahi', 'Hossein Bevrani', 'Zakariya Yahya Algamal']","We propose Stein-type estimators for zero-inflated Bell regression models by incorporating information on model parameters. These estimators combine the advantages of unrestricted and restricted estimators. We derive the asymptotic distributional properties, including bias and mean squared error, for the proposed shrinkage estimators. Monte Carlo simulations demonstrate the superior performance of our shrinkage estimators across various scenarios. Furthermore, we apply the proposed estimators to analyze a real dataset, showcasing their practical utility."
https://arxiv.org/abs/2403.00748,2024-03-01,Primal-Dual iLQR,"['JoÃ£o Sousa-Pinto', 'Dominique Orban']","We introduce a new algorithm for solving unconstrained discrete-time optimal control problems. Our method follows a direct multiple shooting approach, and consists of applying the SQP method together with an $\ell_2$ augmented Lagrangian primal-dual merit function. We use the LQR algorithm to efficiently solve the primal-dual SQP problem. As our algorithm is a specialization of NPSQP (Gill et al. 1992), it inherits its generic properties, including global convergence, fast local convergence, and the lack of need for second order corrections, improving on existing direct multiple shooting approaches such as GNMS (Giftthaler et al. 2018) and FDDP (Mastalli et al. 2020)."
https://arxiv.org/abs/2403.00747,2024-03-01,The QCD theta-parameter in canonical quantization,"['Wen-Yuan Ai', 'Bjorn Garbrecht', 'Carlos Tamarit']","The role of the QCD theta-parameter is investigated in pure Yang-Mills theory in the spacetime given by the four-dimensional Euclidean torus. While in this setting the introduction of possibly unphysical boundary conditions is avoided, it must be specified how the sum over the topological sectors is to be carried out. To connect with observables in real time, we perceive the partition function as the trace over the canonical density matrix. The system then corresponds to one of a finite temperature on a spatial three-torus. Carrying out the trace operation requires canonical quantization and gauge fixing. Fixing the gauge and demanding that the Hermiticity of the Hamiltonian is maintained leads to a restriction of the Hilbert space of physical wave functionals that generalizes the constraints derived from imposing Gauss' law. Consequently, we find that the states in the Hilbert space are properly normalizable under an inner product that integrates over each physical configuration represented by the gauge potential one time and one time only. The observables derived from the constrained Hilbert space do not violate charge-parity symmetry. We note that an exact hidden symmetry of the theory that is present for arbitrary values of theta in the Hamiltonian is effectively promoted to parity conservation in this constrained space. These results, derived on a torus in order to avoid the introduction of boundary conditions, also carry over to Minkowski spacetime when taking account of all possible gauge transformations."
https://arxiv.org/abs/2403.00746,2024-03-01,A time-stepping deep gradient flow method for option pricing in (rough) diffusion models,"['Antonis Papapantoleon', 'Jasper Rou']","We develop a novel deep learning approach for pricing European options in diffusion models, that can efficiently handle high-dimensional problems resulting from Markovian approximations of rough volatility models. The option pricing partial differential equation is reformulated as an energy minimization problem, which is approximated in a time-stepping fashion by deep artificial neural networks. The proposed scheme respects the asymptotic behavior of option prices for large levels of moneyness, and adheres to a priori known bounds for option prices. The accuracy and efficiency of the proposed method is assessed in a series of numerical examples, with particular focus in the lifted Heston model."
https://arxiv.org/abs/2403.00745,2024-03-01,AtP*: An efficient and scalable method for localizing LLM behaviour to components,"['JÃ¡nos KramÃ¡r', 'Tom Lieberum', 'Rohin Shah', 'Neel Nanda']","Activation Patching is a method of directly computing causal attributions of behavior to model components. However, applying it exhaustively requires a sweep with cost scaling linearly in the number of model components, which can be prohibitively expensive for SoTA Large Language Models (LLMs). We investigate Attribution Patching (AtP), a fast gradient-based approximation to Activation Patching and find two classes of failure modes of AtP which lead to significant false negatives. We propose a variant of AtP called AtP*, with two changes to address these failure modes while retaining scalability. We present the first systematic study of AtP and alternative methods for faster activation patching and show that AtP significantly outperforms all other investigated methods, with AtP* providing further significant improvement. Finally, we provide a method to bound the probability of remaining false negatives of AtP* estimates."
https://arxiv.org/abs/2403.00744,2024-03-01,On the properties and implications of collapse-driven MHD turbulence,"['Enrique VÃ¡zquez-Semadeni', 'Yue Hu', 'Siyao Xu', 'RubÃ©n Guerrero-Gamboa', 'Alex Lazarian']","We numerically investigate the driving of MHD turbulence by gravitational contraction using simulations of an initially spherical, magnetically supercritical cloud core with initially transonic and trans-AlfvÃ©nic turbulence. We perform a Helmholtz decomposition of the velocity field, and investigate the evolution of its solenoidal and compressible parts, as well as of the velocity component along the gravitational acceleration vector, a proxy for the infall component of the velocity field. We find that: 1) In spite of being supercritical, the core first contracts to a sheet perpendicular to the mean field, and the sheet itself collapses. 2) The solenoidal component of the turbulence remains at roughly its initial level throughout the simulation, while the compressible component increases continuously. This implies that turbulence does {\it not} dissipate towards the center of the core. 3) The distribution of simulation cells in the $B$-$Ï$ plane occupies a wide triangular region at low densities, bounded below by the expected trend for fast MHD waves ($B \propto Ï$, applicable for high local AlfvÃ©nic Mach number $\Ma$) and above by the trend expected for slow waves ($B \sim$ constant, applicable for low local $\Ma$). At high densities, the distribution follows a single trend $B \propto Ï^{\gamef}$, with $1/2 < \gamef < 2/3$, as expected for gravitational compression. 4) The measured mass-to-magnetic flux ratio $Î»$ increases with radius $r$, due to the different scalings of the mass and magnetic flux with $r$. At a fixed radius, $Î»$ increases with time due to the accretion of material along field lines. 5) The solenoidal energy fraction is much smaller than the total turbulent component, indicating that the collapse drives the turbulence mainly compressibly, even in directions orthogonal to that of the collapse."
https://arxiv.org/abs/2403.00743,2024-03-01,Neural Acceleration of Incomplete Cholesky Preconditioners,"['Joshua Dennis Booth', 'Hongyang Sun', 'Trevor Garnett']","The solution of a sparse system of linear equations is ubiquitous in scientific applications. Iterative methods, such as the Preconditioned Conjugate Gradient method (PCG), are normally chosen over direct methods due to memory and computational complexity constraints. However, the efficiency of these methods depends on the preconditioner utilized. The development of the preconditioner normally requires some insight into the sparse linear system and the desired trade-off of generating the preconditioner and the reduction in the number of iterations. Incomplete factorization methods tend to be black box methods to generate these preconditioners but may fail for a number of reasons. These reasons include numerical issues that require searching for adequate scaling, shifting, and fill-in while utilizing a difficult to parallelize algorithm. With a move towards heterogeneous computing, many sparse applications find GPUs that are optimized for dense tensor applications like training neural networks being underutilized. In this work, we demonstrate that a simple artificial neural network trained either at compile time or in parallel to the running application on a GPU can provide an incomplete sparse Cholesky factorization that can be used as a preconditioner. This generated preconditioner is as good or better in terms of reduction of iterations than the one found using multiple preconditioning techniques such as scaling and shifting. Moreover, the generated method also works and never fails to produce a preconditioner that does not reduce the iteration count."
https://arxiv.org/abs/2403.00742,2024-03-01,"Dialect prejudice predicts AI decisions about people's character, employability, and criminality","['Valentin Hofmann', 'Pratyusha Ria Kalluri', 'Dan Jurafsky', 'Sharese King']","Hundreds of millions of people now interact with language models, with uses ranging from serving as a writing aid to informing hiring decisions. Yet these language models are known to perpetuate systematic racial prejudices, making their judgments biased in problematic ways about groups like African Americans. While prior research has focused on overt racism in language models, social scientists have argued that racism with a more subtle character has developed over time. It is unknown whether this covert racism manifests in language models. Here, we demonstrate that language models embody covert racism in the form of dialect prejudice: we extend research showing that Americans hold raciolinguistic stereotypes about speakers of African American English and find that language models have the same prejudice, exhibiting covert stereotypes that are more negative than any human stereotypes about African Americans ever experimentally recorded, although closest to the ones from before the civil rights movement. By contrast, the language models' overt stereotypes about African Americans are much more positive. We demonstrate that dialect prejudice has the potential for harmful consequences by asking language models to make hypothetical decisions about people, based only on how they speak. Language models are more likely to suggest that speakers of African American English be assigned less prestigious jobs, be convicted of crimes, and be sentenced to death. Finally, we show that existing methods for alleviating racial bias in language models such as human feedback training do not mitigate the dialect prejudice, but can exacerbate the discrepancy between covert and overt stereotypes, by teaching language models to superficially conceal the racism that they maintain on a deeper level. Our findings have far-reaching implications for the fair and safe employment of language technology."
https://arxiv.org/abs/2403.00741,2024-03-01,Transchromatic phenomena in the equivariant slice spectral sequence,"['Lennart Meier', 'XiaoLin Danny Shi', 'Mingcong Zeng']","In this paper, we prove a transchromatic phenomenon for Hill--Hopkins--Ravenel and Lubin--Tate theories. This establishes a direct relationship between the equivariant slice spectral sequences of height-$h$ and height-$(h/2)$ theories. As applications of this transchromatic phenomenon, we prove periodicity and vanishing line results for these theories."
https://arxiv.org/abs/2403.00740,2024-03-01,A Universal Roadmap For Searching Repulsive Casimir Forces Between Magneto-Electric Materials,"['Zixuan Dai', 'Qing-Dong Jiang']","The Casimir effect, arising from vacuum quantum fluctuations, plays a fundamental role in the development of modern quantum electrodynamics. In parallel, the field of condensed matter has flourished through the discovery of various materials exhibiting broken symmetries, often connected to topology and characterized by magneto-electric coupling. Here, we calculate the Casimir forces between materials with time-reversal symmetry and/or parity symmetry breaking. Remarkably, we obtain a universal phase diagram governing the sign of symmetry-breaking-induced Casimir forces, contributing to a comprehensive understanding on the sign of Casimir force for linear optical materials. The discovered phase diagram serves as a roadmap for searching repulsive Casimir forces, a subject bearing both theoretical interest and practical significance."
https://arxiv.org/abs/2403.00739,2024-03-01,Numerical challenges for energy conservation in N-body simulations of collapsing self-interacting dark matter haloes,"['Moritz S. Fischer', 'Klaus Dolag', 'Hai-Bo Yu']","Dark matter (DM) haloes can be subject to gravothermal collapse if DM is not collisionless but has strong self-interactions. When the scattering can efficiently transfer heat from the centre to the outskirts, the central region of the halo collapses and reaches densities much higher than those for collisionless DM. This phenomenon is potentially observable in studies of strong lensing. Current theoretical efforts are motivated by observations of surprisingly dense substructures. A comparison with them requires accurate predictions. One method to obtain such predictions is to use N-body simulations. The collapsed haloes are extreme systems that pose severe challenges to state-of-the-art codes used to model self-interacting dark matter (SIDM). We investigate the root of such problems with a focus on energy non-conservation. We run N-body simulations with and without DM self-interactions of an isolated DM-only halo and change numerical parameters relevant to the accuracy of the simulation. We find that not only the numerical scheme for the DM self-interactions can lead to energy non-conservation but also the modelling of gravitational interaction and the time integration are problematic. The issues we found are: (a) particles changing their time step in a non-time-reversible manner; (b) the asymmetry in the tree-based gravitational force evaluation; (c) SIDM velocity kicks break the symplectic nature and time symmetry. Tuning the parameters of the simulation to achieve a high accuracy allows for conserving energy not only at early stages of the evolution but also at late ones. However, the cost of the simulations becomes prohibitively large. Some problems making the simulations of the gravothermal collapse phase inaccurate, can be overcome by choosing appropriate numerical schemes. However, others remain challenging. Our findings motivate further work on addressing these challenges."
https://arxiv.org/abs/2403.00738,2024-03-01,Prospect of high-temperature superconductivity in layered metal borocarbides,"['Charlsey R. Tomassetti', 'Gyanu P. Kafle', 'Edan T. Marcial', 'Elena R. Margine', 'Aleksey N. Kolmogorov']","Delithiation of the known layered LiBC compound was predicted to induce conventional superconductivity at liquid nitrogen temperatures but extensive experimental work over the past two decades has detected no signs of the expected superconducting transition. Using a combination of first-principles stability analysis and anisotropic Migdal-Eliashberg formalism, we have investigated possible Li$_x$BC morphologies and established what particular transformations of the planar honeycomb BC layers are detrimental to the material's superconductivity. We propose that Li$_x$BC reintercalation with select alkali and alkaline earth metals could lead to synthesis of otherwise inaccessible metastable Li$_x$M$_y$BC superconductors with critical temperatures ($T_{c}$) up to 73 K. The large-scale exploration of metal borocarbides has revealed that NaBC and Li$_{1/2}$Na$_y$BC layered phases are likely true ground states at low temperatures. The findings indicate that this compositional space may host overlooked synthesizable compounds with potential to break the $T_{c}$ record for conventional superconductivity in ambient-pressure materials."
https://arxiv.org/abs/2403.00737,2024-03-01,Happy Ending: An Empty Hexagon in Every Set of 30 Points,"['Marijn J. H. Heule', 'Manfred Scheucher']","Satisfiability solving has been used to tackle a range of long-standing open math problems in recent years. We add another success by solving a geometry problem that originated a century ago. In the 1930s, Esther Klein's exploration of unavoidable shapes in planar point sets in general position showed that every set of five points includes four points in convex position. For a long time, it was open if an empty hexagon, i.e., six points in convex position without a point inside, can be avoided. In 2006, Gerken and NicolÃ¡s independently proved that the answer is no. We establish the exact bound: Every 30-point set in the plane in general position contains an empty hexagon. Our key contributions include an effective, compact encoding and a search-space partitioning strategy enabling linear-time speedups even when using thousands of cores."
https://arxiv.org/abs/2403.00736,2024-03-01,The Probability to Hit Every Bin with a Linear Number of Balls,['Stefan Walzer'],"Assume that $2n$ balls are thrown independently and uniformly at random into $n$ bins. We consider the unlikely event $E$ that every bin receives at least one ball, showing that $\Pr[E] = Î(b^n)$ where $b \approx 0.836$. Note that, due to correlations, $b$ is not simply the probability that any single bin receives at least one ball. More generally, we consider the event that throwing $Î±n$ balls into $n$ bins results in at least $d$ balls in each bin."
https://arxiv.org/abs/2403.00735,2024-03-01,On the moduli space of simple sheaves on singular K3 surfaces,"['Barbara Fantechi', 'Rosa M. MirÃ³-Roig']","Mukai proved that the moduli space of simple sheaves on a smooth projective K3 surface is symplectic, and in \cite{FM2} we gave two constructions allowing one to construct new locally closed Lagrangian/isotropic subspaces of the moduli from old ones. In this paper, we extend both Mukai's result and our construction to reduced projective K3 surfaces; for the former we need to restrict our attention to perfect sheaves. There are two key points where we cannot get a straightforward generalization. In each, we need to prove that a certain differential form on the moduli space of simple, perfect sheaves vanishes, and we introduce a smoothability condition to complete the proof."
https://arxiv.org/abs/2403.00734,2024-03-01,MIGHTEE-HI: HI galaxy properties in the large scale structure environment at z~0.37 from a stacking experiment,"['Francesco Sinigaglia', 'Giulia Rodighiero', 'Ed Elson', 'Alessandro Bianchetti', 'Mattia Vaccari', 'Natasha Maddox', 'Anastasia A. Ponomareva', 'Bradley S. Frank', 'Matt J. Jarvis', 'Barbara Catinella', 'Luca Cortese', 'Sambit Roychowdhury', 'Maarten Baes', 'Jordan D. Collier', 'Olivier Ilbert', 'Ali A. Khostovan', 'Sushma Kurapati', 'Hengxing Pan', 'Isabella Prandoni', 'Sambatriniaina H. A. Rajohnson', 'Mara Salvato', 'Srikrishna Sekhar', 'Gauri Sharma']","We present the first measurement of HI mass of star-forming galaxies in different large scale structure environments from a blind survey at $z\sim 0.37$. In particular, we carry out a spectral line stacking analysis considering $2875$ spectra of colour-selected star-forming galaxies undetected in HI at $0.23 < z < 0.49$ in the COSMOS field, extracted from the MIGHTEE-HI Early Science datacubes, acquired with the MeerKAT radio telescope. We stack galaxies belonging to different subsamples depending on three different definitions of large scale structure environment: local galaxy overdensity, position inside the host dark matter halo (central, satellite, or isolated), and cosmic web type (field, filament, or knot). We first stack the full star-forming galaxy sample and find a robust HI detection yielding an average galaxy HI mass of $M_{\rm HI}=(8.12\pm 0.75)\times 10^9\, {\rm M}_\odot$ at $\sim 11.8Ï$. Next, we investigate the different subsamples finding a negligible difference in $M_{\rm HI}$ as a function of the galaxy overdensity. We report an HI excess compared to the full sample in satellite galaxies ($M_{\rm HI}=(11.31\pm1.22)\times 10^9$, at $\sim 10.2 Ï$) and in filaments ($M_{\rm HI}=(11.62\pm 0.90)\times 10^9$. Conversely, we report non-detections for the central and knot galaxies subsamples, which appear to be HI-deficient. We find the same qualitative results also when stacking in units of HI fraction ($f_{\rm HI}$). We conclude that the HI amount in star-forming galaxies at the studied redshifts correlates with the large scale structure environment."
https://arxiv.org/abs/2403.00733,2024-03-01,"Remarks on ""Successive Convexification: A Superlinearly Convergent Algorithm for Non-convex Optimal Control Problems""","['Dayou Luo', 'Purnanand Elango', 'Behcet Acikmese']","The purpose of this note is to highlight and address inaccuracies in the convergence guarantees of SCvx, a nonconvex trajectory optimization algorithm proposed by Mao et al. (arXiv:1804.06539), and make connections to relevant prior work. Specifically, we identify errors in the convergence proof within Mao et al. (arXiv:1804.06539) and reestablish the proof of convergence by employing a new method under stricter assumptions."
https://arxiv.org/abs/2403.00732,2024-03-01,Silicon Photonic Microresonator-Based High-Resolution Line-by-Line Pulse Shaping,"['Lucas M. Cohen', 'Kaiyi Wu', 'Karthik V. Myilswamy', 'Saleha Fatema', 'Navin B. Lingaraju', 'Andrew M. Weiner']","Optical pulse shaping stands as a formidable technique in ultrafast optics, radio-frequency photonics, and quantum communications. While existing systems rely on bulk optics or integrated platforms with planar waveguide sections for spatial dispersion, they face limitations in achieving finer (few- or sub-GHz) spectrum control. These methods either demand considerable space or suffer from pronounced phase errors and optical losses when assembled to achieve fine resolution. Addressing these challenges, we present a foundry-fabricated six-channel silicon photonic shaper using microresonator filter banks with inline phase control and high spectral resolution. Leveraging existing comb-based spectroscopic techniques, we devise a novel system to mitigate thermal crosstalk and enable the versatile use of our on-chip shaper. Our results demonstrate the shaper's ability to phase-compensate six comb lines at tunable channel spacings of 3, 4, and 5 GHz. Specifically, at a 3 GHz channel spacing, we showcase the generation of arbitrary waveforms in the time domain. This scalable design and control scheme holds promise in meeting future demands for high-precision spectral shaping capabilities."
https://arxiv.org/abs/2403.00731,2024-03-01,On Locally Conformal Spin(7) Structure,['Eyup Yalcinkaya'],"This article reveals a significant connection in geometry: when the Lee form $Î¸$ is normal to an almost Hermitian manifold $N$, it implies that $N$ possesses a nearly KÃ¤hler structure. Investigating locally conformally Spin(7) manifolds with 2-vector fields, our study provides a concise yet rigorous proof of this relationship."
https://arxiv.org/abs/2403.00730,2024-03-01,Covariance and symmetry algebras,"['Antoine Rignon-Bret', 'Simone Speziale']","In general relativity as well as gauge theories, non-trivial symmetries can appear at boundaries. In the presence of radiation some of the symmetries are not Hamiltonian vector fields, hence the definition of charges for the symmetries becomes delicate. It can lead to the problem of field-dependent 2-cocycles in the charge algebra, as opposed to the central extensions allowed in standard classical mechanics. We show that if the Wald-Zoupas prescription is implemented, its covariance requirement guarantees that the algebra of Noether currents is free of field-dependent 2-cocycles, and its stationarity requirement further removes central extensions. Therefore the charge algebra admits at most a time-independent field-dependent 2-cocycle, whose existence depends on the boundary conditions. We report on new results for asymptotic symmetries at future null infinity that can be derived with this approach."
https://arxiv.org/abs/2403.00729,2024-03-01,Can Transformers Capture Spatial Relations between Objects?,"['Chuan Wen', 'Dinesh Jayaraman', 'Yang Gao']","Spatial relationships between objects represent key scene information for humans to understand and interact with the world. To study the capability of current computer vision systems to recognize physically grounded spatial relations, we start by proposing precise relation definitions that permit consistently annotating a benchmark dataset. Despite the apparent simplicity of this task relative to others in the recognition literature, we observe that existing approaches perform poorly on this benchmark. We propose new approaches exploiting the long-range attention capabilities of transformers for this task, and evaluating key design principles. We identify a simple ""RelatiViT"" architecture and demonstrate that it outperforms all current approaches. To our knowledge, this is the first method to convincingly outperform naive baselines on spatial relation prediction in in-the-wild settings. The code and datasets are available in \url{https://sites.google.com/view/spatial-relation}."
https://arxiv.org/abs/2403.00728,2024-03-01,Emergence of interfacial magnetism in strongly-correlated nickelate-titanate superlattices,"['Teguh Citra Asmara', 'Robert J. Green', 'Andreas Suter', 'Yuan Wei', 'Wenliang Zhang', 'Grant Harris', 'Yi Tseng', 'Tianlun Yu', 'Davide Betto', 'Mirian Garcia-Fernandez', 'Stefano Agrestini', 'Yannick Maximilian Klein', 'Neeraj Kumar', 'Carlos William Galdino', 'Zaher Salman', 'Thomas Prokscha', 'Marisa Medarde', 'Elisabeth MÃ¼ller', 'Yona Soh', 'Nicholas B. Brookes', 'Ke-Jin Zhou', 'Milan Radovic', 'Thorsten Schmitt']","Strongly-correlated transition-metal oxides are widely known for their various exotic phenomena. This is exemplified by rare-earth nickelates such as LaNiO$_{3}$, which possess intimate interconnections between their electronic, spin, and lattice degrees of freedom. Their properties can be further enhanced by pairing them in hybrid heterostructures, which can lead to hidden phases and emergent phenomena. An important example is the LaNiO$_{3}$/LaTiO$_{3}$ superlattice, where an interlayer electron transfer has been observed from LaTiO$_{3}$ into LaNiO$_{3}$ and is predicted to result in a high-spin state. However, macroscopic emergence of magnetic order has so far not been observed. Here, by using muon spin rotation, x-ray absorption, and resonant inelastic x-ray scattering, we present direct evidence of an emergent antiferromagnetic order with high magnon energy and exchange interactions at the LaNiO$_{3}$/LaTiO$_{3}$ interface. As the magnetism is purely interfacial, a single LaNiO$_{3}$/LaTiO$_{3}$ interface can essentially behave as an atomically thin quasi-two-dimensional antiferromagnet, potentially allowing its technological utilisation in advanced spintronic devices. Furthermore, its strong quasi-two-dimensional magnetic correlations and orbitally-polarized planar ligand holes make its electronic and magnetic configurations resemble the precursor states of superconducting cuprates and nickelates, but with an S $\rightarrow$ 1 spin state instead."
https://arxiv.org/abs/2403.00727,2024-03-01,Moduli of sheaves on fourfolds as derived Lagrangian intersections,"['Nachiketa Adhikari', 'Yun Shi']","We show that any $(-2)$-shifted symplectic derived scheme $\textbf{X}$ (of finite type over an algebraically closed field of characteristic zero) is locally equivalent to the derived intersection of two Lagrangian morphisms to a $(-1)$-shifted symplectic derived scheme which is the $(-1)$-shifted cotangent stack of a smooth classical scheme. This leads to the possibility of the following viewpoint that is, at least to us, new: any $n$-shifted symplectic derived scheme can be obtained, locally, by repeated derived Lagrangian intersections in a smooth classical scheme."
https://arxiv.org/abs/2403.00726,2024-03-01,Dichotomous Dynamics of Magnetic Monopole Fluids,"['Chun-Chih Hsu', 'Hiroto Takahashi', 'Fabian Jerzembeck', 'Jahnatta Dasini', 'Chaia Carroll', 'Ritika Dusad', 'Jonathan Ward', 'Catherine Dawson', 'Graeme Luke', 'Stephen J. Blundell', 'Claudio Castelnovo', 'Jonathan N. HallÃ©n', 'Roderich Moessner', 'J. C. SÃ©amus Davis']","A recent advance in the study of emergent magnetic monopoles was the discovery that monopole motion is restricted to dynamical fractal trajectories (J. HallÃ©n et al, Science 378, 1218 (2022)) thus explaining the characteristics of magnetic monopole noise spectra (Dusad, R. et al. Nature 571, 234 (2019); Samarakoon, A. M. et al. Proc. Natl. Acad. Sci. 119, e2117453119 (2022)). Here we apply this new theory to explore the dynamics of field-driven monopole currents, finding them comprised of two quite distinct transport processes: initially swift fractal rearrangements of local monopole configurations followed by conventional monopole diffusion. This theory also predicts a characteristic frequency dependence of the dissipative loss-angle for AC-field-driven currents. To explore these novel perspectives on monopole transport, we introduce simultaneous monopole current control and measurement techniques using SQUID-based monopole current sensors. For the canonical material Dy2Ti2O7, we measure $Î¦(t)$, the time-dependence of magnetic flux threading the sample when a net monopole current $J(t) = \dotÎ¦(t)/Î¼_0$ is generated by applying an external magnetic field $B_0(t)$. These experiments find a sharp dichotomy of monopole currents, separated by their distinct relaxation time-constants before and after $t \approx 600 Î¼s$ from monopole current initiation. Application of sinusoidal magnetic fields $B_0(t) = Bcos(Ït)$ generates oscillating monopole currents whose loss angle $Î¸(f)$ exhibits a characteristic transition at frequency $f \approx 1.8$ kHz over the same temperature range. Finally, the magnetic noise power is also dichotomic, diminishing sharply after $t \approx 600 Î¼s$. This complex phenomenology represents a new form of heterogeneous dynamics generated by the interplay of fractionalization and local spin configurational symmetry."
https://arxiv.org/abs/2403.00725,2024-03-01,Cost-Effective Activity Control of Asymptomatic Carriers in Layered Temporal Social Networks,"['Masoumeh Moradian', 'Aresh Dadlani', 'Rasul Kairgeldin', 'Ahmad Khonsari']","The robustness of human social networks against epidemic propagation relies on the propensity for physical contact adaptation. During the early phase of infection, asymptomatic carriers exhibit the same activity level as susceptible individuals, which presents challenges for incorporating control measures in epidemic projection models. This paper focuses on modeling and cost-efficient activity control of susceptible and carrier individuals in the context of the susceptible-carrier-infected-removed (SCIR) epidemic model over a two-layer contact network. In this model, individuals switch from a static contact layer to create new links in a temporal layer based on state-dependent activation rates. We derive conditions for the infection to die out or persist in a homogeneous network. Considering the significant costs associated with reducing the activity of susceptible and carrier individuals, we formulate an optimization problem to minimize the disease decay rate while constrained by a limited budget. We propose the use of successive geometric programming (SGP) approximation for this optimization task. Through simulation experiments on Poisson random graphs, we assess the impact of different parameters on disease prevalence. The results demonstrate that our SGP framework achieves a cost reduction of nearly 33% compared to conventional methods based on degree and closeness centrality."
https://arxiv.org/abs/2403.00724,2024-03-01,Few-Shot Relation Extraction with Hybrid Visual Evidence,"['Jiaying Gong', 'Hoda Eldardiry']","The goal of few-shot relation extraction is to predict relations between name entities in a sentence when only a few labeled instances are available for training. Existing few-shot relation extraction methods focus on uni-modal information such as text only. This reduces performance when there are no clear contexts between the name entities described in text. We propose a multi-modal few-shot relation extraction model (MFS-HVE) that leverages both textual and visual semantic information to learn a multi-modal representation jointly. The MFS-HVE includes semantic feature extractors and multi-modal fusion components. The MFS-HVE semantic feature extractors are developed to extract both textual and visual features. The visual features include global image features and local object features within the image. The MFS-HVE multi-modal fusion unit integrates information from various modalities using image-guided attention, object-guided attention, and hybrid feature attention to fully capture the semantic interaction between visual regions of images and relevant texts. Extensive experiments conducted on two public datasets demonstrate that semantic visual information significantly improves the performance of few-shot relation prediction."
https://arxiv.org/abs/2403.00723,2024-03-01,"Characterization of process-related interfacial dielectric loss in aluminum-on-silicon by resonator microwave measurements, materials analysis, and imaging","['Lert Chayanun', 'Janka BiznÃ¡rovÃ¡', 'Lunjie Zeng', 'Per Malmberg', 'Andreas Nylander', 'Amr Osman', 'Marcus Rommel', 'Pui Lam Tam', 'Eva Olsson', 'August Yurgens', 'Jonas Bylander', 'Anita Fadavi Roudsari']","We systematically investigate the influence of the fabrication process on dielectric loss in aluminum-on-silicon superconducting coplanar waveguide resonators with internal quality factors ($Q_i$) of about one million at the single-photon level. These devices are essential components in superconducting quantum processors; they also serve as proxies for understanding the energy loss of superconducting qubits. By systematically varying several fabrication steps, we identify the relative importance of reducing loss at the substrate-metal and the substrate-air interfaces. We find that it is essential to clean the silicon substrate in hydrogen fluoride (HF) prior to aluminum deposition. A post-fabrication removal of the oxides on the surface of the silicon substrate and the aluminum film by immersion in HF further improves the $Q_i$. We observe a small, but noticeable, adverse effect on the loss by omitting either standard cleaning (SC1), pre-deposition heating of the substrate to 300$Â°$C, or in-situ post-deposition oxidation of the film's top surface. We find no improvement due to excessive pumping meant to reach a background pressure below $6{\times} 10^{-8}$ mbar. We correlate the measured loss with microscopic properties of the substrate-metal interface through characterization with X-ray photoelectron spectroscopy (XPS), time-of-flight secondary ion mass spectroscopy (ToF-SIMS), transmission electron microscopy (TEM), energy-dispersive X-ray spectroscopy (EDS), and atomic force microscopy (AFM)."
https://arxiv.org/abs/2403.00722,2024-03-01,Hyperbolic phonon-plasmon polaritons in a hBN-graphene van der Waals structure,"['Yu. V. Bludov', 'D. A. Bahamon', 'N. M. R. Peres', 'C. J. S. de Matos']","In this paper a thorough theoretical study of a new class of collective excitations, dubbed hyperbolic surface phonon plasmon polaritons, is performed. This new type of light-matter excitations are shown to have unique properties that allows to explore them both as the basis of ultra-sensitive devices to the dielectric nature of its surroundings. The system is a van der Waals heterostructure -- a layered metamaterial, composed of different 2D materials in direct contact one with another, namely graphene ribbons and hexagonal boron nitride slabs of nanometric size. In the paper we discuss the spectrum of these new class of excitations, the associated electromagnetic fields, the sensitivity to the dielectric function of its surroundings, and the absorption spectrum. All this is accomplished using an analytical model that considerably diminishes the computational burden, as well as elucidates the underling physical mechanism of the excitations supported by the device."
https://arxiv.org/abs/2403.00721,2024-03-01,New cluster algebras from old: integrability beyond Zamolodchikov periodicity,"['Andrew N. W. Hone', 'Wookyung Kim', 'Takafumi Mase']","We consider discrete dynamical systems obtained as deformations of mutations in cluster algebras associated with finite-dimensional simple Lie algebras. The original (undeformed) dynamical systems provide the simplest examples of Zamolodchikov periodicity: they are affine birational maps for which every orbit is periodic with the same period. Following on from preliminary work by one of us with Kouloukas, here we present integrable maps obtained from deformations of cluster mutations related to the following simple root systems: $A_3$, $B_2$, $B_3$ and $D_4$. We further show how new cluster algebras arise, by considering Laurentification, that is, a lifting to a higher-dimensional map expressed in a set of new variables (tau functions), for which the dynamics exhibits the Laurent property. For the integrable map obtained by deformation of type $A_3$, which already appeared in our previous work, we show that there is a commuting map of Quispel-Roberts-Thompson (QRT) type which is built from a composition of mutations and a permutation applied to the same cluster algebra of rank 6, with an additional 2 frozen variables. Furthermore, both the deformed $A_3$ map and the QRT map correspond to addition of a point in the Mordell-Weil group of a rational elliptic surface of rank two, and the underlying cluster algebra comes from a quiver that mutation equivalent to the $q$-PainlevÃ© III quiver found by Okubo. The deformed integrable maps of types $B_2$, $B_3$ and $D_4$ are also related to elliptic surfaces."
https://arxiv.org/abs/2403.00720,2024-03-01,Subhomogeneous Deep Equilibrium Models,"['Pietro Sittoni', 'Francesco Tudisco']","Implicit-depth neural networks have grown as powerful alternatives to traditional networks in various applications in recent years. However, these models often lack guarantees of existence and uniqueness, raising stability, performance, and reproducibility issues. In this paper, we present a new analysis of the existence and uniqueness of fixed points for implicit-depth neural networks based on the concept of subhomogeneous operators and the nonlinear Perron-Frobenius theory. Compared to previous similar analyses, our theory allows for weaker assumptions on the parameter matrices, thus yielding a more flexible framework for well-defined implicit networks. We illustrate the performance of the resulting subhomogeneous networks on feed-forward, convolutional, and graph neural network examples."
https://arxiv.org/abs/2403.00719,2024-03-01,The PÃ³lya-Tchebotarev problem with semiclassical external fields,"['Victor Alves', 'Guilherme Silva']","The classical PÃ³lya-Tchebotarev problem, commonly stated as a max-min logarithmic energy problem, asks for finding a compact of minimal capacity in the complex plane which connects a prescribed collection of fixed points. Variants of this problem have found ramifications and applications in the theory of non-hermitian orthogonal polynomials, random matrices, approximation theory, among others. Here we consider an extension of this classical problem, including a semiclassical external field, and enforcing finitely many prescribed collections of points to be connected, possibly also to infinity. Our method is based on Rakhmanov's approach to max-min problems in logarithmic potential theory, utilizes the developed machinery by MartÃ­nez-Finkelshtein and Rakhmanov on critical measures, and extends the development of Kuijlaars and the second named author from the context of polynomial external fields to the semiclassical case considered here."
https://arxiv.org/abs/2403.00718,2024-03-01,A study of anomalies using functional integration and perturbative calculations,['Thalis JosÃ© Girardi'],"We present two lines of investigation involving anomalies. First, we review mechanisms behind the classical and quantum conservation of symmetries using functional integration. This discussion clarifies conditions for quantum violations, as acknowledged in chiral theories. Then, we elucidate the subject of gauge anomaly cancellation when all fields are quantized. Such an outcome requires gauge invariance of the bosonic measure, so our first object is proving this invariance within Fujikawa's approach. Second, we investigate anomalies in fermionic perturbative amplitudes using Implicit Regularization. The discussion of the single-axial triangle fundaments this analysis, bringing the elements necessary to approach the single-axial box. When organizing their mathematical structure, we highlight the role of traces involving the chiral matrix. Choosing a specific expression for them reflects on the position of symmetry violations, which has implications regarding the linearity of integration. Power counting and tensor structure imply the presence of surface terms related to momenta ambiguities. We present the results without computing these surface terms. In this neutral perspective, we explore possibilities achieved under different prescriptions."
https://arxiv.org/abs/2403.00717,2024-03-01,MAIDR: Making Statistical Visualizations Accessible with Multimodal Data Representation,"['JooYoung Seo', 'Yilin Xia', 'Bongshin Lee', 'Sean McCurry', 'Yu Jun Yam']","This paper investigates new data exploration experiences that enable blind users to interact with statistical data visualizations$-$bar plots, heat maps, box plots, and scatter plots$-$leveraging multimodal data representations. In addition to sonification and textual descriptions that are commonly employed by existing accessible visualizations, our MAIDR (multimodal access and interactive data representation) system incorporates two additional modalities (braille and review) that offer complementary benefits. It also provides blind users with the autonomy and control to interactively access and understand data visualizations. In a user study involving 11 blind participants, we found the MAIDR system facilitated the accurate interpretation of statistical visualizations. Participants exhibited a range of strategies in combining multiple modalities, influenced by their past interactions and experiences with data visualizations. This work accentuates the overlooked potential of combining refreshable tactile representation with other modalities and elevates the discussion on the importance of user autonomy when designing accessible data visualizations."
https://arxiv.org/abs/2403.00716,2024-03-01,Few-shot genes selection: subset of PAM50 genes for breast cancer subtypes classification,"['Leandro Y. S. Okimoto', 'Rayol Mendonca-Neto', 'FabÃ­ola G. Nakamura', 'Eduardo F. Nakamura', 'David FenyÃ¶', 'Claudio T. Silva']","Background: In recent years, researchers have made significant strides in understanding the heterogeneity of breast cancer and its various subtypes. However, the wealth of genomic and proteomic data available today necessitates efficient frameworks, instruments, and computational tools for meaningful analysis. Despite its success as a prognostic tool, the PAM50 gene signature's reliance on many genes presents challenges in terms of cost and complexity. Consequently, there is a need for more efficient methods to classify breast cancer subtypes using a reduced gene set accurately."
https://arxiv.org/abs/2403.00715,2024-03-01,Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive Ratio Analysis and Best-of-Both-Worlds,"['Shinji Ito', 'Taira Tsuchiya', 'Junya Honda']","Follow-The-Regularized-Leader (FTRL) is known as an effective and versatile approach in online learning, where appropriate choice of the learning rate is crucial for smaller regret. To this end, we formulate the problem of adjusting FTRL's learning rate as a sequential decision-making problem and introduce the framework of competitive analysis. We establish a lower bound for the competitive ratio and propose update rules for learning rate that achieves an upper bound within a constant factor of this lower bound. Specifically, we illustrate that the optimal competitive ratio is characterized by the (approximate) monotonicity of components of the penalty term, showing that a constant competitive ratio is achievable if the components of the penalty term form a monotonically non-increasing sequence, and derive a tight competitive ratio when penalty terms are $Î¾$-approximately monotone non-increasing. Our proposed update rule, referred to as \textit{stability-penalty matching}, also facilitates constructing the Best-Of-Both-Worlds (BOBW) algorithms for stochastic and adversarial environments. In these environments our result contributes to achieve tighter regret bound and broaden the applicability of algorithms for various settings such as multi-armed bandits, graph bandits, linear bandits, and contextual bandits."
https://arxiv.org/abs/2403.00714,2024-03-01,Entropy Driven Inductive Response of Topological Insulators,"['A. Mert Bozkurt', 'Sofie KÃ¶lling', 'Alexander Brinkman', 'Ä°nanÃ§ Adagideli']","3D topological insulators are characterized by an insulating bulk and extended surface states exhibiting a helical spin texture. In this work, we investigate the hyperfine interaction between the spin-charge coupled transport of electrons and the nuclear spins in these surface states. Previous work has predicted that in the quantum spin Hall insulator phase, work can be extracted from a bath of polarized nuclear spins as a resource. We employ nonequilibrium Green's function analysis to show that a similar effect exists on the surface of a 3D topological insulator, albeit rescaled by the ratio between electronic mean free path and device length. The induced current due to thermal relaxation of polarized nuclear spins has an inductive nature. We emphasize the inductive response by rewriting the current-voltage relation in harmonic response as a lumped element model containing two parallel resistors and an inductor. In a low-frequency analysis, a universal inductance value emerges that is only dependent on the device's aspect ratio. This scaling offers a means of miniaturizing inductive circuit elements. An efficiency estimate follows from comparing the spin-flip induced current to the Ohmic contribution. The inductive effect is most prominent in topological insulators which have a large number of spinful nuclei per coherent segment, of which the volume is given by the mean free path length, Fermi wavelength and penetration depth of the surface state."
https://arxiv.org/abs/2403.00713,2024-03-01,From spectral to scattering form factor,"['Massimo Bianchi', 'Maurizio Firrotta', 'Jacob Sonnenschein', 'Dorin Weissman']","We propose a novel indicator for chaotic quantum scattering processes, the scattering form factor (ScFF). It is based on mapping the locations of peaks in the scattering amplitude to random matrix eigenvalues, and computing the analog of the spectral form factor (SFF). We compute the spectral and scattering form factors of several non-chaotic systems. We determine the ScFF associated with the phase shifts of the leaky torus, closely related to the distribution of the zeros of Riemann zeta function. We compute the ScFF for the decay amplitude of a highly excited string states into two tachyons. We show that it displays the universal features expected from random matrix theory - a decline, a ramp and a plateau - and is in general agreement with the Gaussian unitary ensemble. It also shows some new features, owning to the special structure of the string amplitude, including a ""bump"" before the ramp associated with gaps in the average eigenvalue density. The ""bump"" is removed for highly excited string states with an appropriate state dependent unfolding. We also discuss the SFF for the Gaussian $Î²$- ensemble, writing an interpolation between the known results of the Gaussian orthogonal, unitary, and symplectic ensembles."
https://arxiv.org/abs/2403.00712,2024-03-01,Rethinking Inductive Biases for Surface Normal Estimation,"['Gwangbin Bae', 'Andrew J. Davison']","Despite the growing demand for accurate surface normal estimation models, existing methods use general-purpose dense prediction models, adopting the same inductive biases as other tasks. In this paper, we discuss the inductive biases needed for surface normal estimation and propose to (1) utilize the per-pixel ray direction and (2) encode the relationship between neighboring surface normals by learning their relative rotation. The proposed method can generate crisp - yet, piecewise smooth - predictions for challenging in-the-wild images of arbitrary resolution and aspect ratio. Compared to a recent ViT-based state-of-the-art model, our method shows a stronger generalization ability, despite being trained on an orders of magnitude smaller dataset. The code is available at https://github.com/baegwangbin/DSINE."
https://arxiv.org/abs/2403.00711,2024-03-01,Non-radial oscillations in anisotropic dark energy stars,"['O. P. Jyothilakshmi', 'Lakshmi J. Naik', 'V. Sreekanth']","We study the non-radial $f$-mode oscillations of both isotropic and anisotropic dark energy stars by using the modified Chaplygin prescription of dark energy to model the stellar matter. The anisotropic pressure in the system is modeled with Bowers-Liang prescription. By solving the stellar structure equations in presence of anisotropy, we study the global properties of the dark energy star and compare the mass-radius profiles with data from GW events and milli-second pulsars. We proceed to determine the prominent non-radial $l=2$ $f$-mode frequencies of the anisotropic dark energy star by employing the Cowling approximation and analyse and quantify the spectra by varying the anisotropic parameter. We report that $f$-mode spectra of dark energy star have distinctly different behaviour compared to neutron star and quark star, and this may possibly help in its future identification. Further, the tidal deformability factors of the anisotropic dark energy stars have also been analyzed."
https://arxiv.org/abs/2403.00710,2024-03-01,Decoherence in Andreev spin qubits,"['Silas Hoffman', 'Max Hays', 'Kyle Serniak', 'Thomas Hazard', 'Charles Tahan']","We theoretically study the dephasing of an Andreev spin qubit (ASQ) due to electric and magnetic noise. Using a tight-binding model, we calculate the Andreev states formed in a Josephson junction where the link is a semiconductor with strong spin-orbit interaction. As a result of both the spin-orbit interaction and induced superconductivity, the local charge and spin of these states varies as a function of externally controllable parameters: the phase difference between the superconducting leads, an applied magnetic field, and filling of the underlying semiconductor. Concomitantly, coupling to fluctuations of the electric or magnetic environment will vary, which informs the rate of dephasing. We qualitatively predict the dependence of dephasing on the nature of the environment, magnetic field, phase difference between the junction, and filling of the semiconductor. Comparing the simulated electric- and magnetic-noise-induced dephasing rate to experiment suggests that the dominant source of noise is magnetic. Moreover, by appropriately tuning these external parameters, we find sweet-spots at which we predict an enhancement in ASQ coherence times."
https://arxiv.org/abs/2403.00709,2024-03-01,Spin current control of magnetism,"['L. Chen', 'Y. Sun', 'S. Mankovsky', 'T. N. G. Meier', 'M. Kronseder', 'H. Ebert', 'D. Weiss', 'C. H. Back']","Exploring novel strategies to manipulate the order parameter of magnetic materials by electrical means is of great importance, not only for advancing our understanding of fundamental magnetism, but also for unlocking potential practical applications. A well-established concept to date uses gate voltages to control magnetic properties, such as saturation magnetization, magnetic anisotropies, coercive field, Curie temperature and Gilbert damping, by modulating the charge carrier population within a capacitor structure. Note that the induced carriers are non-spin-polarized, so the control via the electric-field is independent of the direction of the magnetization. Here, we show that the magnetocrystalline anisotropy (MCA) of ultrathin Fe films can be reversibly modified by a spin current generated in Pt by the spin Hall effect. The effect decreases with increasing Fe thickness, indicating that the origin of the modification can be traced back to the interface. Uniquely, the change in MCA due to the spin current depends not only on the polarity of the charge current but also on the direction of magnetization, i.e. the change in MCA has opposite sign when the direction of magnetization is reversed. The control of magnetism by the spin current results from the modified exchange splitting of majority- and minority-spin bands, and differs significantly from the manipulation by gate voltages via a capacitor structure, providing a functionality that was previously unavailable and could be useful in advanced spintronic devices."
https://arxiv.org/abs/2403.00708,2024-03-01,On the Hamilton-Lott conjecture in higher dimensions,"['Alix Deruelle', 'Felix Schulze', 'Miles Simon']","We study $n$-dimensional Ricci flows with non-negative Ricci curvature where the curvature is pointwise controlled by the scalar curvature and bounded by $C/t$, starting at metric cones which are Reifenberg outside the tip. We show that any such flow behaves like a self-similar solution up to an exponential error in time. As an application, we show that smooth $n$-dimensional complete non-compact Riemannian manifolds which are uniformly PIC1-pinched, with positive asymptotic volume ratio, are Euclidean. This confirms a higher dimensional version of a conjecture of Hamilton and Lott under the assumption of non-collapsing. It also yields a new and more direct proof of the original conjecture of Hamilton and Lott in three dimensions."
https://arxiv.org/abs/2403.00707,2024-03-01,Dimensionality reduction techniques to support insider trading detection,"['Adele Ravagnani', 'Fabrizio Lillo', 'Paola Deriu', 'Piero Mazzarisi', 'Francesca Medda', 'Antonio Russo']","Identification of market abuse is an extremely complicated activity that requires the analysis of large and complex datasets. We propose an unsupervised machine learning method for contextual anomaly detection, which allows to support market surveillance aimed at identifying potential insider trading activities. This method lies in the reconstruction-based paradigm and employs principal component analysis and autoencoders as dimensionality reduction techniques. The only input of this method is the trading position of each investor active on the asset for which we have a price sensitive event (PSE). After determining reconstruction errors related to the trading profiles, several conditions are imposed in order to identify investors whose behavior could be suspicious of insider trading related to the PSE. As a case study, we apply our method to investor resolved data of Italian stocks around takeover bids."
https://arxiv.org/abs/2403.00706,2024-03-01,Reducing the error rate of a superconducting logical qubit using analog readout information,"['Hany Ali', 'Jorge Marques', 'Ophelia Crawford', 'Joonas Majaniemi', 'Marc Serra-Peralta', 'David Byfield', 'Boris Varbanov', 'Barbara M. Terhal', 'Leonardo DiCarlo', 'Earl T. Campbell']","Quantum error correction enables the preservation of logical qubits with a lower logical error rate than the physical error rate, with performance depending on the decoding method. Traditional error decoding approaches, relying on the binarization (`hardening') of readout data, often ignore valuable information embedded in the analog (`soft') readout signal. We present experimental results showcasing the advantages of incorporating soft information into the decoding process of a distance-three ($d=3$) bit-flip surface code with transmons. To this end, we use the $3\times3$ data-qubit array to encode each of the $16$ computational states that make up the logical state $\ket{0_{\mathrm{L}}}$, and protect them against bit-flip errors by performing repeated $Z$-basis stabilizer measurements. To infer the logical fidelity for the $\ket{0_{\mathrm{L}}}$ state, we average across the $16$ computational states and employ two decoding strategies: minimum weight perfect matching and a recurrent neural network. Our results show a reduction of up to $6.8\%$ in the extracted logical error rate with the use of soft information. Decoding with soft information is widely applicable, independent of the physical qubit platform, and could reduce the readout duration, further minimizing logical error rates."
https://arxiv.org/abs/2403.00705,2024-03-01,First-principles Investigation of Thermodynamic Properties of CrNbO4 and CrTaO4,"['Shuang Lin', 'Shun-Li Shang', 'Allison M. Beese', 'Zi-Kui Liu']","In the present study, the DFT+U method was employed to predict the thermodynamic properties of Cr2O3, Nb2O5, and Ta2O5. Results were benchmarked with experimental data showing high accuracy, except for the negative thermal expansion (NTE) of Nb2O5, which is attributed to its polymorphic complexity. Additionally, we extended our analysis to rutile-type oxides CrNbO4 and CrTaO4, examining their entropy and heat capacity at finite temperatures. CrNbO4 displayed slightly higher entropy and heat capacity at high temperatures. The mean linear thermal expansion coefficients for CrNbO4 and CrTaO4 from 500 K to 2000 K were predicted to be 6.00*10-6/K and 13.49*10-6/K, respectively, corroborating with DFT predictions and experimental evidence. Our research highlights the precision of the DFT+U and phonon methods in predicting the thermodynamic properties of oxide materials, offering insights into the design of corrosion-resistant materials."
https://arxiv.org/abs/2403.00704,2024-03-01,Representing Guardedness in Call-by-Value and Guarded Parametrized Monads,['Sergey Goncharov'],"Like the notion of computation via (strong) monads serves to classify various flavours of impurity, including exceptions, non-determinism, probability, local and global store, the notion of guardedness classifies well-behavedness of cycles in various settings. In its most general form, the guardedness discipline applies to general symmetric monoidal categories and further specializes to Cartesian and co-Cartesian categories, where it governs guarded recursion and guarded iteration respectively. Here, even more specifically, we deal with the semantics of call-by-value guarded iteration. It was shown by Levy, Power and Thielecke that call-by-value languages can be generally interpreted in Freyd categories, but in order to represent effectful function spaces, such a category must canonically arise from a strong monad. We generalize this fact by showing that representing guarded effectful function spaces calls for certain parametrized monads (in the sense of Uustalu). This provides a description of guardedness as an intrinsic categorical property of programs, complementing the existing description of guardedness as a predicate on a category."
https://arxiv.org/abs/2403.00703,2024-03-01,Understanding Trap States in InP and GaP Quantum Dots Through Density Functional Theory,"['Ezra Alexander', 'Matthias Kick', 'Alexandra McIsaac', 'Troy Van Voorhis']","The widespread application of III-V colloidal quantum dots (QDs) as non-toxic, highly tunable emitters is stymied by their high density of trap states. Here, we utilize density functional theory (DFT) to investigate trap state formation in a diverse set of realistically passivated core-only InP and GaP QDs. Through orbital localization techniques, we deconvolute the dense manifold of trap states to allow for detailed assignment of surface defects. We find that the three-coordinate species dominate trapping in III-V QDs and identify features in the geometry and charge environment of trap centers capable of deepening, or sometimes passivating, traps. Furthermore, we observe stark differences in surface reconstruction between InP and GaP, where the more labile InP reconstructs to passivate three-coordinate indium at the cost of distortion elsewhere. These results offer explanations for experimentally observed trapping behavior and suggest new avenues for controlling trap states in III-V QDs."
https://arxiv.org/abs/2403.00702,2024-03-01,Ab initio simulation of single vibronic level fluorescence spectra of anthracene using Hagedorn wavepackets,"['Zhan Tong Zhang', 'JiÅÃ­ J. L. VanÃ­Äek']","Single vibronic level (SVL) fluorescence spectroscopy contributes to the understanding of molecular vibrational structures and relaxation processes. Based on Hagedorn wavepackets, we have recently proposed a time-dependent approach to compute SVL spectra from arbitrary initial vibrational levels, i.e., higher excitations in multiple modes, and validated it against exact quantum calculations on model systems. Here, we extend the application of our method to a realistic molecular system, anthracene, employing a harmonic model constructed from ab initio electronic structure data. With the Hagedorn approach, we not only successfully reproduce the previously reported simulation results for singly excited $12^{1}$ and $\overline{11}^{1}$ levels, but are also able to compute SVL spectra from multiply excited levels in good agreement with experiments and from the same Hagedorn wavepacket trajectory without any additional propagation beyond what is required for ground-state emission spectra."
https://arxiv.org/abs/2403.00701,2024-03-01,Bayesian Model Averaging for Partial Ordering Continual Reassessment Methods,"['Luka Kovacevic', 'Thomas Jaki', 'Helen Barnett', 'Pavel Mozgunov']","Phase I clinical trials are essential to bringing novel therapies from chemical development to widespread use. Traditional approaches to dose-finding in Phase I trials, such as the '3+3' method and the Continual Reassessment Method (CRM), provide a principled approach for escalating across dose levels. However, these methods lack the ability to incorporate uncertainty regarding the dose-toxicity ordering as found in combination drug trials. Under this setting, dose-levels vary across multiple drugs simultaneously, leading to multiple possible dose-toxicity orderings. The Partial Ordering CRM (POCRM) extends to these settings by allowing for multiple dose-toxicity orderings. In this work, it is shown that the POCRM is vulnerable to 'estimation incoherency' whereby toxicity estimates shift in an illogical way, threatening patient safety and undermining clinician trust in dose-finding models. To this end, the Bayesian model averaged POCRM (BMA-POCRM) is proposed. BMA-POCRM uses Bayesian model averaging to take into account all possible orderings simultaneously, reducing the frequency of estimation incoherencies. The effectiveness of BMA-POCRM in drug combination settings is demonstrated through a specific instance of estimate incoherency of POCRM and simulation studies. The results highlight the improved safety, accuracy and reduced occurrence of estimate incoherency in trials applying the BMA-POCRM relative to the POCRM model."
https://arxiv.org/abs/2403.00700,2024-03-01,Characteristics of dark current from an S-band rf gun with exchangeable photocathode system,"['Frank Jackson', 'Louise Cowie', 'Marta Furmaniak Phillipe Goudket', 'Boris Militsyn', 'Julian McKenzie Tim Noakes']","Field emission or dark current from RF electron guns is problematic for accelerators for several reasons, and can be more difficult to predict, measure and understand, compared to the main beam. The work presented here is a study of the dark current emitted from the CLARA 3GHz 2.5 cell electron gun with exchangeable photocathode, which is a type of gun used for single pass high quality low emittance beams for uses such as Free Electron Lasers. The main purpose of these studies was to identify sources of dark current emission within the gun, by examining the dark current distribution and patterns on scintillating screens. It is shown that the features of the patterns can be reproduced qualitatively, and to some extent quantitatively, by finite element simulations. Thus, certain surfaces within the gun and cathode apparatus which contribute most significantly to problematic dark current can be identified, and further development and preparation of the guns and their cathodes can be informed to minimise dark current."
https://arxiv.org/abs/2403.00699,2024-03-01,Shaping an evanescent focus of light for high spatial resolution optogenetic activations in live cells,"['Marc Grosjean', 'Alexei Grichine', 'Mylene Pezet', 'Olivier Destaing', 'Antoine Delon', 'IrÃ¨ne Wang']","Confining light illumination in the three dimensions of space is a challenge for various applications. Among these, optogenetic methods developed for live experiments in cell biology would benefit from such a localized illumination as it would improve the spatial resolution of diffusive photosensitive proteins leading to spatially constrained biological responses in specific subcellular organelles. Here, we describe a method to create and move a focused evanescent spot across the field of view of a high numerical aperture microscope objective, using a digital micro-mirror device (DMD). We show that, after correcting the optical aberrations, light is confined within a spot of sub-micron lateral size and $\sim$100~nm axial depth, resulting in a volume of illumination drastically smaller than the one generated by a standard propagative focus. This evanescent focus is sufficient to induce a more intense and localized recruitment compared to a propagative focus on the optogenetic system CRY2-CIBN, improving the resolution of its pattern of activation."
https://arxiv.org/abs/2403.00698,2024-03-01,Path Tracking using Echoes in an Unknown Environment: the Issue of Symmetries and How to Break Them,"['Mireille Boutin', 'Gregor Kemper']","This paper deals with the problem of reconstructing the path of a vehicle in an unknown environment consisting of planar structures using sound. Many systems in the literature do this by using a loudspeaker and microphones mounted on a vehicle. Symmetries in the environment lead to solution ambiguities for such systems. We propose to resolve this issue by placing the loudspeaker at a fixed location in the environment rather than on the vehicle. The question of whether this will remove ambiguities regardless of the environment geometry leads to a question about breaking symmetries that can be phrased in purely mathematical terms. We solve this question in the affirmative if the geometry is in dimension three or bigger, and give counterexamples in dimension two. Excluding the rare situations where the counterexamples arise, we also give an affirmative answer in dimension two. Our results lead to a simple path reconstruction algorithm for a vehicle carrying four microphones navigating within an environment in which a loudspeaker at a fixed position emits short bursts of sounds. This algorithm could be combined with other methods from the literature to construct a path tracking system for vehicles navigating within a potentially symmetric environment."
https://arxiv.org/abs/2403.00697,2024-03-01,The Ricci-flatness that lurks in weight,['Diego Conti'],"We introduce two constructions to obtain left-invariant Ricci-flat pseudo-Riemannian metrics on nilpotent Lie groups, one based on gradings, the other on filtrations, both depending on the combinatorics of the set of weights."
https://arxiv.org/abs/2403.00696,2024-03-01,Self-Consistent Decoding for More Factual Open Responses,"['Christopher Malon', 'Xiaodan Zhu']","Self-consistency has emerged as a powerful method for improving the accuracy of short answers generated by large language models. As previously defined, it only concerns the accuracy of a final answer parsed from generated text. In this work, we extend the idea to open response generation, by integrating voting into the decoding method. Each output sentence is selected from among multiple samples, conditioning on the previous selections, based on a simple token overlap score. We compare this ""Sample & Select"" method to greedy decoding, beam search, nucleus sampling, and the recently introduced hallucination avoiding decoders of DoLA, P-CRR, and S-CRR. We show that Sample & Select improves factuality by a 30% relative margin against these decoders in NLI-based evaluation on the subsets of CNN/DM and XSum used in the FRANK benchmark, while maintaining comparable ROUGE-1 F1 scores against reference summaries. We collect human verifications of the generated summaries, confirming the factual superiority of our method."
https://arxiv.org/abs/2403.00695,2024-03-01,Generation time for biexact functors and Koszul objects in triangulated categories,"['Janina C. Letz', 'Marc Stephan']","This paper concerns the generation time that measures the number of cones necessary to obtain an object in a triangulated category from another object. This invariant is called level. We establish level inequalities for enhanced triangulated categories: One inequality concerns biexact functors of topological triangulated categories, another Koszul objects. In particular, this extends inequalities for the derived tensor product from commutative algebra to enhanced tensor triangulated categories. We include many examples."
https://arxiv.org/abs/2403.00694,2024-03-01,Defining Expertise: Applications to Treatment Effect Estimation,"['Alihan HÃ¼yÃ¼k', 'Qiyao Wei', 'Alicia Curth', 'Mihaela van der Schaar']","Decision-makers are often experts of their domain and take actions based on their domain knowledge. Doctors, for instance, may prescribe treatments by predicting the likely outcome of each available treatment. Actions of an expert thus naturally encode part of their domain knowledge, and can help make inferences within the same domain: Knowing doctors try to prescribe the best treatment for their patients, we can tell treatments prescribed more frequently are likely to be more effective. Yet in machine learning, the fact that most decision-makers are experts is often overlooked, and ""expertise"" is seldom leveraged as an inductive bias. This is especially true for the literature on treatment effect estimation, where often the only assumption made about actions is that of overlap. In this paper, we argue that expertise - particularly the type of expertise the decision-makers of a domain are likely to have - can be informative in designing and selecting methods for treatment effect estimation. We formally define two types of expertise, predictive and prognostic, and demonstrate empirically that: (i) the prominent type of expertise in a domain significantly influences the performance of different methods in treatment effect estimation, and (ii) it is possible to predict the type of expertise present in a dataset, which can provide a quantitative basis for model selection."
https://arxiv.org/abs/2403.00693,2024-03-01,Equicontractive weak separation property on the line does not imply convex finite type condition,['Kevin G. Hare'],"Let $\{S_1, S_2, \dots, S_n\}$ be an iterated function system on $\mathbb{R}$ with attractor $K$. It is known that if the iterated function system satisfies the weak separation property and $K = [0,1]$ then the iterated function system also satisfies the convex finite type condition. We show that the condition $K = [0,1]$ is necessary. That is, we give two examples of iterated function systems on $\mathbb{R}$ satisfying weak separation condition, and $0< \dim_H(K) < 1$ such that the IFS does not satisfy the convex finite type condition."
https://arxiv.org/abs/2403.00692,2024-03-01,Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks,"['Guillem Casadesus-Vila', 'Joan-Adria Ruiz-de-Azua', 'Eduard Alarcon']","The upcoming landscape of Earth Observation missions will defined by networked heterogeneous nanosatellite constellations required to meet strict mission requirements, such as revisit times and spatial resolution. However, scheduling satellite communications in these satellite networks through efficiently creating a global satellite Contact Plan (CP) is a complex task, with current solutions requiring ground-based coordination or being limited by onboard computational resources. The paper proposes a novel approach to overcome these challenges by modeling the constellations and CP as dynamic networks and employing graph-based techniques. The proposed method utilizes a state-of-the-art dynamic graph neural network to evaluate the performance of a given CP and update it using a heuristic algorithm based on simulated annealing. The trained neural network can predict the network delay with a mean absolute error of 3.6 minutes. Simulation results show that the proposed method can successfully design a contact plan for large satellite networks, improving the delay by 29.1%, similar to a traditional approach, while performing the objective evaluations 20x faster."
https://arxiv.org/abs/2403.00691,2024-03-01,Tri-Modal Motion Retrieval by Learning a Joint Embedding Space,"['Kangning Yin', 'Shihao Zou', 'Yuxuan Ge', 'Zheng Tian']","Information retrieval is an ever-evolving and crucial research domain. The substantial demand for high-quality human motion data especially in online acquirement has led to a surge in human motion research works. Prior works have mainly concentrated on dual-modality learning, such as text and motion tasks, but three-modality learning has been rarely explored. Intuitively, an extra introduced modality can enrich a model's application scenario, and more importantly, an adequate choice of the extra modality can also act as an intermediary and enhance the alignment between the other two disparate modalities. In this work, we introduce LAVIMO (LAnguage-VIdeo-MOtion alignment), a novel framework for three-modality learning integrating human-centric videos as an additional modality, thereby effectively bridging the gap between text and motion. Moreover, our approach leverages a specially designed attention mechanism to foster enhanced alignment and synergistic effects among text, video, and motion modalities. Empirically, our results on the HumanML3D and KIT-ML datasets show that LAVIMO achieves state-of-the-art performance in various motion-related cross-modal retrieval tasks, including text-to-motion, motion-to-text, video-to-motion and motion-to-video."
https://arxiv.org/abs/2403.00690,2024-03-01,Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents,"['Dominik Jeurissen', 'Diego Perez-Liebana', 'Jeremy Gow', 'Duygu Cakmak', 'James Kwan']","Large Language Models (LLMs) have shown great success as high-level planners for zero-shot game-playing agents. However, these agents are primarily evaluated on Minecraft, where long-term planning is relatively straightforward. In contrast, agents tested in dynamic robot environments face limitations due to simplistic environments with only a few objects and interactions. To fill this gap in the literature, we present NetPlay, the first LLM-powered zero-shot agent for the challenging roguelike NetHack. NetHack is a particularly challenging environment due to its diverse set of items and monsters, complex interactions, and many ways to die."
https://arxiv.org/abs/2403.00689,2024-03-01,Hydra: Computer Vision for Data Quality Monitoring,"['Thomas Britton', 'Torri Jeske', 'David Lawrence', 'Kishansingh Rajput']","Hydra is a system which utilizes computer vision to perform near real time data quality management, initially developed for Hall-D in 2019. Since then, it has been deployed across all experimental halls at Jefferson Lab, with the CLAS12 collaboration in Hall-B being the first outside of GlueX to fully utilize Hydra. The system comprises back end processes that manage the models, their inferences, and the data flow. The front-end components, accessible via web pages, allow detector experts and shift crews to view and interact with the system. This talk will give an overview of the Hydra system as well as highlight significant developments in Hydra's feature set, acute challenges with operating Hydra in all halls, and lessons learned along the way."
https://arxiv.org/abs/2403.00688,2024-03-01,Degradation-Invariant Music Indexing,"['RÃ©mi Mignot', 'Geoffroy Peeters']","For music indexing robust to sound degradations and scalable for big music catalogs, this scientific report presents an approach based on audio descriptors relevant to the music content and invariant to sound transformations (noise addition, distortion, lossy coding, pitch/time transformations, or filtering e.g.). To achieve this task, one of the key point of the proposed method is the definition of high-dimensional audio prints, which are intrinsically (by design) robust to some sound degradations. The high dimensionality of this first representation is then used to learn a linear projection to a sub-space significantly smaller, which reduces again the sensibility to sound degradations using a series of discriminant analyses. Finally, anchoring the analysis times on local maxima of a selected onset function, an approximative hashing is done to provide a better tolerance to bit corruptions, and in the same time to make easier the scaling of the method."
https://arxiv.org/abs/2403.00687,2024-03-01,Structurally Aware Robust Model Selection for Mixtures,"['Jiawei Li', 'Jonathan H. Huggins']","Mixture models are often used to identify meaningful subpopulations (i.e., clusters) in observed data such that the subpopulations have a real-world interpretation (e.g., as cell types). However, when used for subpopulation discovery, mixture model inference is usually ill-defined a priori because the assumed observation model is only an approximation to the true data-generating process. Thus, as the number of observations increases, rather than obtaining better inferences, the opposite occurs: the data is explained by adding spurious subpopulations that compensate for the shortcomings of the observation model. However, there are two important sources of prior knowledge that we can exploit to obtain well-defined results no matter the dataset size: known causal structure (e.g., knowing that the latent subpopulations cause the observed signal but not vice-versa) and a rough sense of how wrong the observation model is (e.g., based on small amounts of expert-labeled data or some understanding of the data-generating process). We propose a new model selection criteria that, while model-based, uses this available knowledge to obtain mixture model inferences that are robust to misspecification of the observation model. We provide theoretical support for our approach by proving a first-of-its-kind consistency result under intuitive assumptions. Simulation studies and an application to flow cytometry data demonstrate our model selection criteria consistently finds the correct number of subpopulations."
https://arxiv.org/abs/2403.00686,2024-03-01,A Bit of a Problem: Measurement Disparities in Dataset Sizes Across Languages,"['Catherine Arnett', 'Tyler A. Chang', 'Benjamin K. Bergen']","How should text dataset sizes be compared across languages? Even for content-matched (parallel) corpora, UTF-8 encoded text can require a dramatically different number of bytes for different languages. In our work, we define the byte premium between two languages as the ratio of bytes used to encode content-matched text in those languages. We compute byte premiums for 1155 languages, and we use linear regressions to estimate byte premiums for other languages. We release a tool to obtain byte premiums for any two languages, enabling comparisons of dataset sizes across languages for more equitable multilingual model development and data practices."
https://arxiv.org/abs/2403.00685,2024-03-01,Know your exceptions: Towards an Ontology of Exceptions in Knowledge Representation,"['Gabriele Sacco', 'Loris Bozzato', 'Oliver Kutz']","Defeasible reasoning is a kind of reasoning where some generalisations may not be valid in all circumstances, that is general conclusions may fail in some cases. Various formalisms have been developed to model this kind of reasoning, which is characteristic of common-sense contexts. However, it is not easy for a modeller to choose among these systems the one that better fits its domain from an ontological point of view. In this paper we first propose a framework based on the notions of exceptionality and defeasibility in order to be able to compare formalisms and reveal their ontological commitments. Then, we apply this framework to compare four systems, showing the differences that may occur from an ontological perspective."
https://arxiv.org/abs/2403.00684,2024-03-01,Otto cycles with a quantum planar rotor,"['Michael Gaida', 'Stefan Nimmrichter']","We present two realizations of an Otto cycle with a quantum planar rotor as the working medium controlled by means of external fields. By comparing the quantum and the classical description of the working medium, we single out genuine quantum effects with regards to the performance and the engine and refrigerator modes of the Otto cycle. The first example is a rotating electric dipole subjected to a controlled electric field, equivalent to a quantum pendulum. Here we find a systematic disadvantage of the quantum rotor compared to its classical counterpart. In contrast, a genuine quantum advantage can be observed with a charged rotor generating a magnetic moment that is subjected to a controlled magnetic field. Here, we prove that the classical rotor is inoperable as a working medium for any choice of parameters, whereas the quantum rotor supports an engine and a refrigerator mode, exploiting the quantum statistics during the cold strokes of the cycle."
https://arxiv.org/abs/2403.00683,2024-03-01,Lessons learned from NASA's DART impact about disrupting rubble-pile asteroids,"['S. D. Raducan', 'M. Jutzi', 'C. C. Merrill', 'P. Michel', 'Y. Zhang', 'M. Hirabayashi', 'A. Mainzer']","We present a series of numerical simulations using a shock physics smoothed particle hydrodynamics (SPH) code, investigating energetic impacts on small celestial bodies characterised by diverse internal structures, ranging from weak and homogeneous compositions to rubble-pile structures with varying boulder volume packing. Our findings reveal that the internal structure of these rubble-pile bodies significantly influences the impact outcomes. Specifically, we observe that the same impact energy can either catastrophically disrupt a target with a low boulder packing (<30 vol%), or result in the ejection of only a small fraction of material from a target with the same mass but high boulder packing (>40 vol%). This finding highlights the pivotal role played by the rubble-pile structure, effectively acting as a bulk shear strength, which governs the size and behaviour of the resulting impact. Consequently, understanding and characterising the internal structure of asteroids will be of paramount importance for any future efforts to deflect or disrupt an asteroid on a collision course with Earth."
https://arxiv.org/abs/2403.00682,2024-03-01,An iterative method for the solution of Laplace-like equations in high and very high space dimensions,['Harry Yserentant'],"This paper deals with the equation $-Îu+Î¼u=f$ on high-dimensional spaces $\mathbb{R}^m$, where the right-hand side $f(x)=F(Tx)$ is composed of a separable function $F$ with an integrable Fourier transform on a space of a dimension $n>m$ and a linear mapping given by a matrix $T$ of full rank and $Î¼\geq 0$ is a constant. For example, the right-hand side can explicitly depend on differences $x_i-x_j$ of components of $x$. Following our publication [Numer. Math. (2020) 146:219--238], we show that the solution of this equation can be expanded into sums of functions of the same structure and develop in this framework an equally simple and fast iterative method for its computation. The method is based on the observation that in almost all cases and for large problem classes the expression $\|T^ty\|^2$ deviates on the unit sphere $\|y\|=1$ the less from its mean value the higher the dimension $m$ is, a concentration of measure effect. The higher the dimension $m$, the faster the iteration converges."
https://arxiv.org/abs/2403.00681,2024-03-01,Impact of Diffusion on synchronization pattern of epidemics in nonidentical metapopulation networks,"['Anika Roy', 'Ujjwal Shekhar', 'Aditi Bose', 'Subrata Ghosh', 'Santosh Nannuru', 'Syamal Kumar Dana', 'Chittaranjan Hens']","In a prior study, a novel deterministic compartmental model known as the SEIHRK model was introduced, shedding light on the pivotal role of test kits as an intervention strategy for mitigating epidemics. Particularly in heterogeneous networks, it was empirically demonstrated that strategically distributing a limited number of test kits among nodes with higher degrees substantially diminishes the outbreak size. The network's dynamics were explored under varying values of infection rate. In this research, we expand upon these findings to investigate the influence of migration on infection dynamics within distinct communities of the network. Notably, we observe that nodes equipped with test kits and those without tend to segregate into two separate clusters when coupling strength is low, but beyond a critical threshold coupling coefficient, they coalesce into a unified cluster. Building on this clustering phenomenon, we develop a reduced equation model and rigorously validate its accuracy through comprehensive simulations. We show that this property is observed in both complete and random graphs."
https://arxiv.org/abs/2403.00680,2024-03-01,Scalable Learning of Item Response Theory Models,"['Susanne Frick', 'Amer KrivoÅ¡ija', 'Alexander Munteanu']","Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using small weighted subsets called coresets. We develop coresets for their use in alternating IRT training algorithms, facilitating scalable learning from large data."
https://arxiv.org/abs/2403.00679,2024-03-01,Optimal Control of Underdamped Systems: An Analytic Approach,"['Julia Sanders', 'Marco Baldovin', 'Paolo Muratore-Ginanneschi']","Optimal control theory deals with finding protocols to steer a system between assigned initial and final states, such that a trajectory-dependent cost function is minimized. The application of optimal control to stochastic systems is an open and challenging research frontier, with a spectrum of applications ranging from stochastic thermodynamics, to biophysics and data science. Among these, the design of nanoscale electronic components motivates the study of underdamped dynamics, leading to practical and conceptual difficulties."
https://arxiv.org/abs/2403.00678,2024-03-01,Controlled creation of point defects in 3D colloidal crystals,"['Max P. M. Schelling', 'Janne-Mieke Meijer']","Crystal defects crucially influence the properties of crystalline materials and have been extensively studied. Even for the simplest type of defect - the point defect - however, basic properties such as their diffusive behavior, and their interactions, remain elusive on the atomic scale. Here we demonstrate in-situ control over the creation of isolated point defects in a 3D colloidal crystal allowing insight on a single particle level. Our system consists of thermoresponsive microgel particles embedded in a crystal of non-responsive colloids. Heating this mixed particle system triggers the shrinking of the embedded microgels, which then vacate their lattice positions creating vacancy-interstitial pairs. We use temperature-controlled confocal laser scanning microscopy to verify and visualize the formation of the point defects. In addition, by re-swelling the microgels we quantify the local lattice distortion around an interstitial defect. Our experimental model system provides a unique opportunity to shed new light on the interplay between point defects, on the mechanisms of their diffusion, on their interactions, and on collective dynamics."
https://arxiv.org/abs/2403.00677,2024-03-01,Haar wavelet characterization of dyadic Lipschitz regularity,"['Hugo Aimar', 'Carlos Exequiel Arias', 'Ivana GÃ³mez']","We obtain a necessary and sufficient condition on the Haar coefficients of a real function $f$ defined on $\mathbb{R}^+$ for the Lipschitz $Î±$ regularity of $f$ with respect to the ultrametric $Î´(x,y)=\inf \{|I|: x, y\in I; I\in\mathcal{D}\}$, where $\mathcal{D}$ is the family of all dyadic intervals in $\mathbb{R}^+$ and $Î±$ is positive. Precisely, $f\in \textrm{Lip}_Î´(Î±)$ if and only if $\left\vert\left<f,h^j_k\right>\right\vert\leq C 2^{-(Î±+ \tfrac{1}{2})j}$, for some constant $C$, every $j\in\mathbb{Z}$ and every $k=0,1,2,\ldots$ Here, as usual $h^j_k(x)= 2^{j/2}h(2^jx-k)$ and $h(x)=\mathcal{X}_{[0,1/2)}(x)-\mathcal{X}_{[1/2,1)}(x)$."
https://arxiv.org/abs/2403.00676,2024-03-01,Transiting exoplanets with the Mid-InfraRed Instrument on board the James Webb Space Telescope: From simulations to observations,"['AchrÃ¨ne Dyrek', 'Elsa Ducrot', 'Pierre-Olivier Lagage', 'Pascal Tremblin', 'Sarah Kendrew', 'Jeroen Bouwman', 'RÃ©mi Bouffet']","The James Webb Space Telescope (JWST) has now started its exploration of exoplanetary worlds. In particular, the Mid-InfraRed Instrument (MIRI) with its Low-Resolution Spectrometer (LRS) carries out transit, eclipse, and phase-curve spectroscopy of exoplanetary atmospheres with unprecedented precision in a so far almost uncharted wavelength range. The precision and significance in the detection of molecules in exoplanetary atmospheres rely on a thorough understanding of the instrument itself and accurate data reduction methods. This paper aims to provide a clear description of the instrumental systematics that affect observations of transiting exoplanets through the use of simulations. We carried out realistic simulations of transiting-exoplanet observations with the MIRI LRS instrument that included the model of the exoplanet system, the optical path of the telescope, the MIRI detector performances, and instrumental systematics and drifts that could alter the atmospheric features we are meant to detect in the data. After introducing our pipeline, we show its performance on the transit of L168-9b, a super-Earth-sized exoplanet observed during the commissioning of the MIRI instrument. This paper provides a better understanding of the data themselves and of the best practices in terms of reduction and analysis through comparisons between simulations and real data. We show that simulations validate the current data-analysis methods. Simulations also highlight instrumental effects that impact the accuracy of our current spectral extraction techniques. These simulations are proven to be essential in the preparation of JWST observation programs and help us assess the detectability of various atmospheric and surface scenarios."
https://arxiv.org/abs/2403.00675,2024-03-01,Reusing Historical Trajectories in Natural Policy Gradient via Importance Sampling: Convergence and Convergence Rate,"['Yifan Lin', 'Yuhao Wang', 'Enlu Zhou']","Reinforcement learning provides a mathematical framework for learning-based control, whose success largely depends on the amount of data it can utilize. The efficient utilization of historical trajectories obtained from previous policies is essential for expediting policy optimization. Empirical evidence has shown that policy gradient methods based on importance sampling work well. However, existing literature often neglect the interdependence between trajectories from different iterations, and the good empirical performance lacks a rigorous theoretical justification. In this paper, we study a variant of the natural policy gradient method with reusing historical trajectories via importance sampling. We show that the bias of the proposed estimator of the gradient is asymptotically negligible, the resultant algorithm is convergent, and reusing past trajectories helps improve the convergence rate. We further apply the proposed estimator to popular policy optimization algorithms such as trust region policy optimization. Our theoretical results are verified on classical benchmarks."
https://arxiv.org/abs/2403.00674,2024-03-01,Cell-Free Massive MIMO with Multi-Antenna Users and Phase Misalignments: A Novel Partially Coherent Transmission Framework,"['Unnikrishnan Kunnath Ganesan', 'Tung Thanh Vu', 'Erik G. Larsson']","Cell-free massive multiple-input multiple-output (MIMO) is a promising technology for next-generation communication systems. This work proposes a novel partially coherent (PC) transmission framework to cope with the challenge of phase misalignment among the access points (APs), which is important for unlocking the full potential of cell-free massive MIMO technology. With the PC operation, the APs are only required to be phase-aligned within clusters. Each cluster transmits the same data stream towards each user equipment (UE), while different clusters send different data streams. We first propose a novel algorithm to group APs into clusters such that the distance between two APs is always smaller than a reference distance ensuring the phase alignment of these APs. Then, we propose new algorithms that optimize the combining at UEs and precoding at APs to maximize the downlink sum data rates. We also propose a novel algorithm for data stream allocation to further improve the sum data rate of the PC operation. Numerical results show that the PC operation using the proposed framework with a sufficiently small reference distance can offer a sum rate close to the sum rate of the ideal fully coherent (FC) operation that requires network-wide phase alignment. This demonstrates the potential of PC operation in practical deployments of cell-free massive MIMO networks."
https://arxiv.org/abs/2403.00673,2024-03-01,Snapshot Reinforcement Learning: Leveraging Prior Trajectories for Efficiency,"['Yanxiao Zhao', 'Yangge Qian', 'Tianyi Wang', 'Jingyang Shan', 'Xiaolin Qin']","Deep reinforcement learning (DRL) algorithms require substantial samples and computational resources to achieve higher performance, which restricts their practical application and poses challenges for further development. Given the constraint of limited resources, it is essential to leverage existing computational work (e.g., learned policies, samples) to enhance sample efficiency and reduce the computational resource consumption of DRL algorithms. Previous works to leverage existing computational work require intrusive modifications to existing algorithms and models, designed specifically for specific algorithms, lacking flexibility and universality. In this paper, we present the Snapshot Reinforcement Learning (SnapshotRL) framework, which enhances sample efficiency by simply altering environments, without making any modifications to algorithms and models. By allowing student agents to choose states in teacher trajectories as the initial state to sample, SnapshotRL can effectively utilize teacher trajectories to assist student agents in training, allowing student agents to explore a larger state space at the early training phase. We propose a simple and effective SnapshotRL baseline algorithm, S3RL, which integrates well with existing DRL algorithms. Our experiments demonstrate that integrating S3RL with TD3, SAC, and PPO algorithms on the MuJoCo benchmark significantly improves sample efficiency and average return, without extra samples and additional computational resources."
https://arxiv.org/abs/2403.00672,2024-03-01,Multi-particle interpolating operators in quantum field theories with cubic symmetry,"['William Detmold', 'William I. Jay', 'Gurtej Kanwar', 'Phiala E. Shanahan', 'Michael L. Wagman']","Numerical studies of lattice quantum field theories are conducted in finite spatial volumes, typically with cubic symmetry in the spatial coordinates. Motivated by these studies, this work presents a general algorithm to construct multi-particle interpolating operators for quantum field theories with cubic symmetry. The algorithm automates the block diagonalization required to combine multiple operators of definite linear momentum into irreducible representations of the appropriate little group. Examples are given for distinguishable and indistinguishable particles including cases with both zero and non-zero spin. An implementation of the algorithm is publicly available at https://github.com/latticeqcdtools/mhi."
https://arxiv.org/abs/2403.00671,2024-03-01,Asymmetric Feature Fusion for Image Retrieval,"['Hui Wu', 'Min Wang', 'Wengang Zhou', 'Zhenbo Lu', 'Houqiang Li']","In asymmetric retrieval systems, models with different capacities are deployed on platforms with different computational and storage resources. Despite the great progress, existing approaches still suffer from a dilemma between retrieval efficiency and asymmetric accuracy due to the limited capacity of the lightweight query model. In this work, we propose an Asymmetric Feature Fusion (AFF) paradigm, which advances existing asymmetric retrieval systems by considering the complementarity among different features just at the gallery side. Specifically, it first embeds each gallery image into various features, e.g., local features and global features. Then, a dynamic mixer is introduced to aggregate these features into compact embedding for efficient search. On the query side, only a single lightweight model is deployed for feature extraction. The query model and dynamic mixer are jointly trained by sharing a momentum-updated classifier. Notably, the proposed paradigm boosts the accuracy of asymmetric retrieval without introducing any extra overhead to the query side. Exhaustive experiments on various landmark retrieval datasets demonstrate the superiority of our paradigm."
https://arxiv.org/abs/2403.00670,2024-03-01,On the Maximum of the Potential of a General Two-Dimensional Coulomb Gas,['Luke Peilen'],"We determine the leading order of the maximum of the random potential associated to a two-dimensional Coulomb gas for general $Î²$ and general confinement potential, extending the recent result of Lambert-LeblÃ©-Zeitouni. In the case $Î²=2$, this corresponds to the (centered) log-characteristic polynomial of either the Ginibre random matrix ensemble for $V(x)=\frac{|x|^2}{2}$ or a more general normal matrix ensemble. The result on the leading order asymptotics for the maximum of the log-characteristic polynomial is new for random normal matrices. We rely on connections with the classical obstacle problem and the theory of Gaussian Multiplicative Chaos. We make use of a new concentration result for fluctuations of $C^{1,1}$ linear statistics which may be of independent interest."
https://arxiv.org/abs/2403.00669,2024-03-01,Advancing Additive Manufacturing through Deep Learning: A Comprehensive Review of Current Progress and Future Challenges,"['Amirul Islam Saimon', 'Emmanuel Yangue', 'Xiaowei Yue', ' Zhenyu', ' Kong', 'Chenang Liu']","Additive manufacturing (AM) has already proved itself to be the potential alternative to widely-used subtractive manufacturing due to its extraordinary capacity of manufacturing highly customized products with minimum material wastage. Nevertheless, it is still not being considered as the primary choice for the industry due to some of its major inherent challenges, including complex and dynamic process interactions, which are sometimes difficult to fully understand even with traditional machine learning because of the involvement of high-dimensional data such as images, point clouds, and voxels. However, the recent emergence of deep learning (DL) is showing great promise in overcoming many of these challenges as DL can automatically capture complex relationships from high-dimensional data without hand-crafted feature extraction. Therefore, the volume of research in the intersection of AM and DL is exponentially growing each year which makes it difficult for the researchers to keep track of the trend and future potential directions. Furthermore, to the best of our knowledge, there is no comprehensive review paper in this research track summarizing the recent studies. Therefore, this paper reviews the recent studies that apply DL for making the AM process better with a high-level summary of their contributions and limitations. Finally, it summarizes the current challenges and recommends some of the promising opportunities in this domain for further investigation with a special focus on generalizing DL models for wide-range of geometry types, managing uncertainties both in AM data and DL models, overcoming limited and noisy AM data issues by incorporating generative models, and unveiling the potential of interpretable DL for AM."
https://arxiv.org/abs/2403.00668,2024-03-01,Exploring Upper-6GHz and mmWave in Real-World 5G Networks: A Direct on-Field Comparison,"['Marcello Morini', 'Eugenio Moro', 'Ilario Filippini', 'Antonio Capone', 'Danilo De Donno']","The spectrum crunch challenge poses a vital threat to the progress of cellular networks and recently prompted the inclusion of millimeter wave (mmWave) and Upper 6GHz (U6G) in the 3GPP standards. These two bands promise to unlock a large portion of untapped spectrum, but the harsh propagation due to the increased carrier frequency might negatively impact the performance of urban Radio Access Network (RAN) deployments. Within the span of a year, two co-located 5G networks operating in these frequency bands were deployed at Politecnico di Milano, Milan, Italy, entirely dedicated to the dense urban performance assessment of the two systems. This paper presents an in-depth analysis of the measurement campaigns conducted on them, with the U6G campaign representing the first of its kind. A benchmark is provided by ray-tracing simulations. The results suggest that networks operating in these frequency bands provide good indoor and outdoor coverage and throughput in urban scenarios, even when deployed in the macro base station setup common to lower frequencies. In addition, a comparative performance analysis of these two key technologies is provided, offering insights on their relative strengths, weaknesses and improvement margins and informing on which bands is better suited for urban macro coverage."
https://arxiv.org/abs/2403.00667,2024-03-01,Physical properties of asteroid Dimorphos as derived from the DART impact,"['S. D. Raducan', 'M. Jutzi', 'A. F. Cheng', 'Y. Zhang', 'O. Barnouin', 'G. S. Collins', 'R. T. Daly', 'T. M. Davison', 'C. M. Ernst', 'T. L. Farnham', 'F. Ferrari', 'M. Hirabayashi', 'K. M. Kumamoto', 'P. Michel', 'N. Murdoch', 'R. Nakano', 'M. Pajola', 'A. Rossi', 'H. F. Agrusa', 'B. W. Barbee', 'M. Bruck Syal', 'N. L. Chabot', 'E. Dotto', 'E. G. Fahnestock', 'P. H. Hasselmann']","On September 26, 2022, NASA's Double Asteroid Redirection Test (DART) mission successfully impacted Dimorphos, the natural satellite of the binary near-Earth asteroid (65803) Didymos. Numerical simulations of the impact provide a means to explore target surface material properties and structures, consistent with the observed momentum deflection efficiency, ejecta cone geometry, and ejected mass. Our simulation, which best matches observations, indicates that Dimorphos is weak, with a cohesive strength of less than a few pascals (Pa), similar to asteroids (162173) Ryugu and (101955) Bennu. We find that a bulk density of Dimorphos, rhoB, lower than 2400 kg/m3, and a low volume fraction of boulders (<40 vol%) on the surface and in the shallow subsurface, are consistent with measured data from the DART experiment. These findings suggest Dimorphos is a rubble pile that might have formed through rotational mass shedding and re-accumulation from Didymos. Our simulations indicate that the DART impact caused global deformation and resurfacing of Dimorphos. ESA's upcoming Hera mission may find a re-shaped asteroid, rather than a well-defined crater."
https://arxiv.org/abs/2403.00666,2024-03-01,Sharp bounds for the max-sliced Wasserstein distance,['March T. Boedihardjo'],We obtain sharp upper and lower bounds for the expected max-sliced 1-Wasserstein distance between a probability measure on a separable Hilbert space and its empirical distribution from $n$ samples. A version of this result for probability measures on Banach spaces is also obtained.
https://arxiv.org/abs/2403.00665,2024-03-01,Complex-Valued Neural Network based Federated Learning for Multi-user Indoor Positioning Performance Optimization,"['Hanzhi Yu', 'Mingzhe Chen', 'Yuchen Liu']","In this article, the use of channel state information (CSI) for indoor positioning is studied. In the considered model, a server equipped with several antennas sends pilot signals to users, while each user uses the received pilot signals to estimate channel states for user positioning. To this end, we formulate the positioning problem as an optimization problem aiming to minimize the gap between the estimated positions and the ground truth positions of users. To solve this problem, we design a complex-valued neural network (CVNN) model based federated learning (FL) algorithm. Compared to standard real-valued centralized machine learning (ML) methods, our proposed algorithm has two main advantages. First, our proposed algorithm can directly process complex-valued CSI data without data transformation. Second, our proposed algorithm is a distributed ML method that does not require users to send their CSI data to the server. Since the output of our proposed algorithm is complex-valued which consists of the real and imaginary parts, we study the use of the CVNN to implement two learning tasks. First, the proposed algorithm directly outputs the estimated positions of a user. Here, the real and imaginary parts of an output neuron represent the 2D coordinates of the user. Second, the proposed method can output two CSI features (i.e., line-of-sight/non-line-of-sight transmission link classification and time of arrival (TOA) prediction) which can be used in traditional positioning algorithms. Simulation results demonstrate that our designed CVNN based FL can reduce the mean positioning error between the estimated position and the actual position by up to 36\%, compared to a RVNN based FL which requires to transform CSI data into real-valued data."
https://arxiv.org/abs/2403.00664,2024-03-01,Nonperturbative Collins-Soper Kernel from Chiral Quarks with Physical Masses,"['Dennis Bollweg', 'Xiang Gao', 'Swagato Mukherjee', 'Yong Zhao']","We present a lattice QCD calculation of the rapidity anomalous dimension of quark transverse-momentum-dependent distributions, i.e., the Collins-Soper (CS) kernel, up to transverse separations of about 1 fm. This unitary lattice calculation is conducted, for the first time, employing the chiral-symmetry-preserving domain wall fermion discretization and physical values of light and strange quark masses. The CS kernel is extracted from the ratios of pion quasi-transverse-momentum-dependent wave functions (quasi-TMDWFs) at next-to-leading logarithmic perturbative accuracy. Also for the first time, we utilize the recently proposed Coulomb-gauge-fixed quasi-TMDWF correlator without a Wilson line. We observe significantly slower signal decay with increasing quark separations compared to the established gauge-invariant method with a staple-shaped Wilson line. This enables us to determine the CS kernel at large nonperturbative transverse separations and find its near-linear dependence on the latter. Our result is consistent with the recent lattice calculation using gauge-invariant quasi-TMDWFs, and agrees with various recent phenomenological parametrizations of experimental data."
https://arxiv.org/abs/2403.00663,2024-03-01,COLON: The largest COlonoscopy LONg sequence public database,"['Lina Ruiz', 'Franklin Sierra-Jerez', 'Jair Ruiz', 'Fabio Martinez']","Colorectal cancer is the third most aggressive cancer worldwide. Polyps, as the main biomarker of the disease, are detected, localized, and characterized through colonoscopy procedures. Nonetheless, during the examination, up to 25% of polyps are missed, because of challenging conditions (camera movements, lighting changes), and the close similarity of polyps and intestinal folds. Besides, there is a remarked subjectivity and expert dependency to observe and detect abnormal regions along the intestinal tract. Currently, publicly available polyp datasets have allowed significant advances in computational strategies dedicated to characterizing non-parametric polyp shapes. These computational strategies have achieved remarkable scores of up to 90% in segmentation tasks. Nonetheless, these strategies operate on cropped and expert-selected frames that always observe polyps. In consequence, these computational approximations are far from clinical scenarios and real applications, where colonoscopies are redundant on intestinal background with high textural variability. In fact, the polyps typically represent less than 1% of total observations in a complete colonoscopy record. This work introduces COLON: the largest COlonoscopy LONg sequence dataset with around of 30 thousand polyp labeled frames and 400 thousand background frames. The dataset was collected from a total of 30 complete colonoscopies with polyps at different stages, variations in preparation procedures, and some cases the observation of surgical instrumentation. Additionally, 10 full intestinal background video control colonoscopies were integrated in order to achieve a robust polyp-background frame differentiation. The COLON dataset is open to the scientific community to bring new scenarios to propose computational tools dedicated to polyp detection and segmentation over long sequences, being closer to real colonoscopy scenarios."
https://arxiv.org/abs/2403.00662,2024-03-01,Modeling the Quality of Dialogical Explanations,"['Milad Alshomary', 'Felix Lange', 'Meisam Booshehri', 'Meghdut Sengupta', 'Philipp Cimiano', 'Henning Wachsmuth']","Explanations are pervasive in our lives. Mostly, they occur in dialogical form where an {\em explainer} discusses a concept or phenomenon of interest with an {\em explainee}. Leaving the explainee with a clear understanding is not straightforward due to the knowledge gap between the two participants. Previous research looked at the interaction of explanation moves, dialogue acts, and topics in successful dialogues with expert explainers. However, daily-life explanations often fail, raising the question of what makes a dialogue successful. In this work, we study explanation dialogues in terms of the interactions between the explainer and explainee and how they correlate with the quality of explanations in terms of a successful understanding on the explainee's side. In particular, we first construct a corpus of 399 dialogues from the Reddit forum {\em Explain Like I am Five} and annotate it for interaction flows and explanation quality. We then analyze the interaction flows, comparing them to those appearing in expert dialogues. Finally, we encode the interaction flows using two language models that can handle long inputs, and we provide empirical evidence for the effectiveness boost gained through the encoding in predicting the success of explanation dialogues."
https://arxiv.org/abs/2403.00661,2024-03-01,A Floquet-Lyapunov Theory for nonautonomous linear periodic differential equations with piecewise constant deviating arguments,['Ricardo Torres'],"We present a version of the classical Floquet-Lyapunov theorem for $Ï-$periodic nonautonomous linear (impulsive and non-impulsive) differential equations with piecewise constant arguments of generalized type (in short, IDEPCAG or DEPCAG). We have proven that the nonautonomous linear IDEPCAG is kinematically similar to an autonomous linear ordinary differential equation. We have also provided some examples to demonstrate the effectiveness of our results."
https://arxiv.org/abs/2403.00660,2024-03-01,New probe of non-Gaussianities with primordial black hole induced gravitational waves,"['Theodoros Papanikolaou', 'Xin-Chen He', 'Xiao-Han Ma', 'Yi-Fu Cai', 'Emmanuel N. Saridakis', 'Misao Sasaki']","We propose a new probe of primordial non-Gaussianities (NGs) through the observation of gravitational waves (GWs) induced by ultra-light ($M_{\text{PBH}}< 10^{9}\rm{g}$) primordial black holes (PBHs). Interestingly enough, the existence of primordial NG can leave imprints on the clustering properties of PBHs and the spectral shape of induced GW signals. Focusing on a scale-dependent local-type NG, we identify a distinct double-peaked GW energy spectrum that, contingent upon $M_{\text{PBH}}$ and the abundance of PBHs at the time of formation, denoted as $Î©_\mathrm{PBH,f}$, may fall into the frequency bands of upcoming GW observatories, including LISA, ET, SKA, and BBO. Thus, such a signal can serve as a novel portal for probing primordial NGs. Intriguingly, combining BBN bounds on the GW amplitude, we find for the first time the joint limit on the product of the effective non-linearity parameter for the primordial tri-spectrum, denoted by $\barÏ_\mathrm{NL}$, and the primordial curvature perturbation power spectrum $\mathcal{P}_{\cal R}(k)$, which reads as $\barÏ_\mathrm{NL} \mathcal{P}_{\cal R}(k) < 4\times 10^{-20} Î©^{-17/9}_\mathrm{PBH,f} \left( \frac{M_{\rm PBH}}{10^4\mathrm{g}} \right)^{-17/9}$."
https://arxiv.org/abs/2403.00659,2024-03-01,Proof mining and probability theory,"['Morenikeji Neri', 'Nicholas Pischke']","We extend the theoretical framework of proof mining by establishing general logical metatheorems that allow for the extraction of the computational content of theorems with prima facie ""non-computational"" proofs from probability theory, thereby unlocking a major branch of mathematics as a new area of application for these methods. Concretely, we devise proof-theoretically tame logical systems that, for one, allow for the formalization of proofs involving algebras of sets together with probability contents as well as associated Lebesgue integrals on them and which, for another, are amenable to proof-theoretic metatheorems in the style of proof mining that guarantee the extractability of effective and tame bounds from larges classes of ineffective existence proofs in probability theory. Moreover, these extractable bounds are guaranteed to be highly uniform in the sense that they will be independent of all parameters relating to the underlying probability space, particularly regarding events or measures of them. As such, these results, in particular, provide the first logical explanation for the success and the observed uniformities of the previous ad hoc case studies of proof mining in these areas and further illustrate their extent. Beyond these systems, we provide extensions for the proof-theoretically tame treatment of $Ï$-algebras and associated probability measures using an intensional approach to infinite unions. Lastly, we establish a general proof-theoretic transfer principle that allows for the lift of quantitative information on a relationship between different modes of convergence for sequences of real numbers to sequences of random variables."
https://arxiv.org/abs/2403.00658,2024-03-01,The solar cycle 25 multi-spacecraft solar energetic particle event catalog of the SERPENTINE project,"['N. Dresing', 'A. Yli-Laurila', 'S. Valkila', 'J. Gieseler', 'D. E. Morosan', 'G. U. Farwa', 'Y. Kartavykh', 'C. Palmroos', 'I. Jebaraj', 'S. Jensen', 'P. KÃ¼hl', 'B. Heber', 'F. Espinosa', 'R. GÃ³mez-Herrero', 'E. Kilpua', 'V. -V. Linho', 'P. Oleynik', 'L. A. Hayes', 'A. Warmuth', 'F. Schuller', 'H. Collier', 'H. Xiao', 'E. Asvestari', 'D. Trotta', 'J. G. Mitchell']","The Solar energetic particle analysis platform for the inner heliosphere (SERPENTINE) project presents it's new multi-spacecraft SEP event catalog for events observed in solar cycle 25. Observations from five different viewpoints are utilized, provided by Solar Orbiter, Parker Solar Probe, STEREO A, BepiColombo, and the near-Earth spacecraft Wind and SOHO. The catalog contains key SEP parameters for 25-40 MeV protons, 1 MeV electrons, and 100 keV electrons. Furthermore, basic parameters of the associated flare and type-II radio burst are listed, as well as the coordinates of the observer and solar source locations. SEP onset times are determined using the Poisson-CUSUM method. SEP peak times and intensities refer to the global intensity maximum. If different viewing directions are available, we use the one with the earliest onset for the onset determination and the one with the highest peak intensity for the peak identification. Associated flares are identified using observations from near Earth and Solar Orbiter. Associated type II radio bursts are determined from ground-based observations in the metric frequency range and from spacecraft observations in the decametric range. The current version of the catalog contains 45 multi-spacecraft events observed in the period from Nov 2020 until May 2023, of which 13 were widespread events and four were classified as narrow-spread events. Using X-ray observations by GOES/XRS and Solar Orbiter/STIX, we were able to identify the associated flare in all but four events. Using ground-based and space-borne radio observations, we found an associated type-II radio burst for 40 events. In total, the catalog contains 142 single event observations, of which 20 (45) have been observed at radial distances below 0.6 AU (0.8 AU)."
https://arxiv.org/abs/2403.00657,2024-03-01,Constraints on anomalous Higgs boson couplings from its production and decay using the WW channel in proton-proton collisions at $\sqrt{s}$ = 13 TeV,[' CMS Collaboration'],"A study of the anomalous couplings of the Higgs boson to vector bosons, including $CP$-violation effects, has been conducted using its production and decay in the WW channel. This analysis is performed on proton-proton collision data collected with the CMS detector at the CERN LHC during 2016-2018 at a center-of-mass energy of 13 TeV, and corresponds to an integrated luminosity of 138 fb$^{-1}$. The different-flavor dilepton (e$Î¼$) final state is analyzed, with dedicated categories targeting gluon fusion, electroweak vector boson fusion, and associated production with a W or Z boson. Kinematic information from associated jets is combined using matrix element techniques to increase the sensitivity to anomalous effects at the production vertex. A simultaneous measurement of four Higgs boson couplings to electroweak vector bosons is performed in the framework of a standard model effective field theory. All measurements are consistent with the expectations for the standard model Higgs boson and constraints are set on the fractional contribution of the anomalous couplings to the Higgs boson production cross section."
https://arxiv.org/abs/2403.00656,2024-03-01,When should PIC simulations be applied to atmospheric pressure plasmas? Impact of correlation heating,"['M. Acciarri', 'C. Moore', 'L. P. Beving', 'S. D. Baalrud']","Molecular dynamics simulations are used to test when the particle-in-cell (PIC) method applies to atmospheric pressure plasmas. It is found that PIC applies only when the plasma density and macroparticle weight are sufficiently small because of two effects associated with correlation heating. The first is the physical effect of disorder-induced heating (DIH). This occurs if the plasma density is large enough that a species (typically ions) is strongly correlated in the sense that the Coulomb coupling parameter exceeds one. In this situation, DIH causes ions to rapidly heat following ionization. PIC is not well suited to capture DIH because doing so requires using a macroparticle weight of one and a grid that well resolves the physical interparticle spacing. These criteria render PIC intractable for macroscale domains. The second effect is a numerical error due to Artificial Correlation Heating (ACH). ACH is like DIH in that it is caused by the Coulomb repulsion between particles, but differs in that it is a numerical effect caused by a macroparticle weight larger than one. Like DIH, it is associated with strong correlations. However, here the macroparticle coupling strength is found to scale as $Îw^{2/3}$, where $Î$ is the physical coupling strength and $w$ is the macroparticle weight. So even if the physical coupling strength of a species is small, as is expected for electrons in atmospheric pressure plasmas, a sufficiently large macroparticle weight can cause the macroparticles to be strongly coupled and therefore heat due to ACH. Furthermore, it is shown that simulations in reduced dimensions exacerbate these issues."
https://arxiv.org/abs/2403.00655,2024-03-01,Extremal decompositions of tropical varieties and relations with rigidity theory,"['Farhad Babaee', 'Sean Dewar', 'James Maxwell']","Extremality and irreducibility constitute fundamental concepts in mathematics, particularly within tropical geometry. While extremal decomposition is typically computationally hard, this article presents a fast algorithm for identifying the extremal decomposition of tropical varieties with rational balanced weightings. Additionally, we explore connections and applications related to rigidity theory. In particular, we prove that a tropical hypersurface is extremal if and only if it has a unique reciprocal diagram up to homothety."
https://arxiv.org/abs/2403.00654,2024-03-01,On $Î´\mathbb{P}$-approximation Spaces,"['Huda Mohsin', 'Faik Mayah']","In order to deal with imprecision, ambiguity, and uncertainty in data analysis, Pawlak introduced rough set theory in 1982. This paper aims to expand the scope of basic set theory developed by presenting the notions of $Î´\mathbb{P}$-upper and $Î´\mathbb{P}$-lower approximations, that are based on the notion of $Î´\mathbb{P}$-open sets, we additionally examine a few of their fundamental characteristics."
https://arxiv.org/abs/2403.00653,2024-03-01,Modelling Global Fossil CO2 Emissions with a Lognormal Distribution: A Climate Policy Tool,"['Faustino Prieto', 'Catalina B. GarcÃ­a-GarcÃ­a', 'RomÃ¡n SalmerÃ³n GÃ³mez']","Carbon dioxide (CO2) emissions have emerged as a critical issue with profound impacts on the environment, human health, and the global economy. The steady increase in atmospheric CO2 levels, largely due to human activities such as burning fossil fuels and deforestation, has become a major contributor to climate change and its associated catastrophic effects. To tackle this pressing challenge, a coordinated global effort is needed, which necessitates a deep understanding of emissions patterns and trends. In this paper, we explore the use of statistical modelling, specifically the lognormal distribution, as a framework for comprehending and predicting CO2 emissions. We build on prior research that suggests a complex distribution of emissions and seek to test the hypothesis that a simpler distribution can still offer meaningful insights for policy-makers. We utilize data from three comprehensive databases and analyse six candidate distributions (exponential, Fisk, gamma, lognormal, Lomax, Weibull) to identify a suitable model for global fossil CO2 emissions. Our findings highlight the adequacy of the lognormal distribution in characterizing emissions across all countries and years studied. Furthermore, to provide additional support for this distribution, we provide statistical evidence supporting the applicability of Gibrat's law to those CO2 emissions. Finally, we employ the lognormal model to predict emission parameters for the coming years and propose two policies for reducing total fossil CO2 emissions. Our research aims to provide policy-makers with accurate and detailed information to support effective climate change mitigation strategies."
https://arxiv.org/abs/2403.00652,2024-03-01,On Hoffman polynomials of $Î»$-doubly stochastic irreducible matrices and commutative association schemes,"['Giusy Monzillo', 'Safet PenjiÄ']","Let $Î$ denote a finite (strongly) connected regular (di)graph with adjacency matrix $A$. The {\em Hoffman polynomial} $h(t)$ of $Î=Î(A)$ is the unique polynomial of smallest degree satisfying $h(A)=J$, where $J$ denotes the all-ones matrix. Let $X$ denote a nonempty finite set. A nonnegative matrix $B\in{\mbox{Mat}}_X({\mathbb R})$ is called {\em $Î»$-doubly stochastic} if $\sum_{z\in X} (B)_{yz}=\sum_{z\in X} (B)_{zy}=Î»$ for each $y\in X$. In this paper we first show that there exists a polynomial $h(t)$ such that $h(B)=J$ if and only if $B$ is a $Î»$-doubly stochastic irreducible matrix. This result allows us to define the Hoffman polynomial of a $Î»$-doubly stochastic irreducible matrix."
https://arxiv.org/abs/2403.00651,2024-03-01,Regularities for solutions to the $L_p$ dual Minkowski problem for unbounded closed sets,"['Li Chen', 'Qiang Tu']","Recently, the dual Minkowski problem for unbounded closed convex sets in a pointed closed convex cone was proposed and a weak solution to the corresponding Monge-AmpÃ¨re equation is provided. In this paper, we consider the regularities of solutions to this problem. More generally, we consider the $L_p$ dual Minkowski problem for unbounded closed convex sets which amounts to solving a Dirichlet problem for a class of Monge-AmpÃ¨re type equations. Our main purpose is to show the existence, regularity and uniqueness of solution to this problem in case $p\geq 1$ by studying variational properties for a family of Monge-AmpÃ¨re functinals. We also discuss the existence and optimal global HÃ¶lder regularity in case $p<1$ and $q\geq n$."
https://arxiv.org/abs/2403.00650,2024-03-01,Finite Time Stability Analysis for Fractional Stochastic Neutral Delay Differential Equations,"['Javad A. Asadzade', 'Nazim I. Mahmudov']","In this manuscript, we delve into the study of a stochastic differential equation with a fractional order and a time delay, encompassing deterministic and stochastic components. Our primary aim is to rigorously establish the existence of a unique solution that follows specified initial conditions, achieved through mathematical analysis. Moreover, we extend our research to investigate the finite-time stability of the system, analyzing trajectory behavior within a specific time frame. Employing advanced mathematical techniques, we systematically verify the finite-time stability, providing insights into convergence and stability within this defined interval. By employing illustrative examples, we strengthen this all-encompassing investigation into the intricate dynamics and stability properties that exist in fractionally ordered stochastic systems with time delays."
https://arxiv.org/abs/2403.00649,2024-03-01,X marks the spot: accurate energies from intersecting extrapolations of continuum quantum Monte Carlo data,"['Seyed Mohammadreza Hosseini', 'Ali Alavi', 'Pablo Lopez Rios']","We explore the application of an extrapolative method that yields very accurate total and relative energies from variational and diffusion quantum Monte Carlo (VMC and DMC) results. For a trial wave function consisting of a small configuration interaction (CI) wave function obtained from full CI quantum Monte Carlo and reoptimized in the presence of a Jastrow factor and an optional backflow transformation, we find that the VMC and DMC energies are smooth functions of the sum of the squared coefficients of the initial CI wave function, and that quadratic extrapolations of the non-backflow VMC and backflow DMC energies intersect within uncertainty of the exact total energy. With adequate statistical treatment of quasi-random fluctuations, the extrapolate and intersect with polynomials of order two (XSPOT) method is shown to yield results in agreement with benchmark-quality total and relative energies for the C2, N2, CO2, and H2O molecules, as well as for the C2 molecule in its first electronic singlet excited state, using only small CI expansion sizes."
https://arxiv.org/abs/2403.00648,2024-03-01,Structure Similarity Preservation Learning for Asymmetric Image Retrieval,"['Hui Wu', 'Min Wang', 'Wengang Zhou', 'Houqiang Li']","Asymmetric image retrieval is a task that seeks to balance retrieval accuracy and efficiency by leveraging lightweight and large models for the query and gallery sides, respectively. The key to asymmetric image retrieval is realizing feature compatibility between different models. Despite the great progress, most existing approaches either rely on classifiers inherited from gallery models or simply impose constraints at the instance level, ignoring the structure of embedding space. In this work, we propose a simple yet effective structure similarity preserving method to achieve feature compatibility between query and gallery models. Specifically, we first train a product quantizer offline with the image features embedded by the gallery model. The centroid vectors in the quantizer serve as anchor points in the embedding space of the gallery model to characterize its structure. During the training of the query model, anchor points are shared by the query and gallery models. The relationships between image features and centroid vectors are considered as structure similarities and constrained to be consistent. Moreover, our approach makes no assumption about the existence of any labeled training data and thus can be extended to an unlimited amount of data. Comprehensive experiments on large-scale landmark retrieval demonstrate the effectiveness of our approach. Our code is released at: https://github.com/MCC-WH/SSP."
https://arxiv.org/abs/2403.00647,2024-03-01,Resolved ALMA observations of water in the inner astronomical units of the HL Tau disk,"['Stefano Facchini', 'Leonardo Testi', 'Elizabeth Humphreys', 'Mathieu Vander Donckt', 'Andrea Isella', 'Ramon Wrzosek', 'Alain Baudry', 'Malcom D. Gray', 'Anita M. S. Richards', 'Wouter Vlemmmings']","The water molecule is a key ingredient in the formation of planetary systems, with the water snowline being a favourable location for the growth of massive planetary cores. Here we present Atacama Large Millimeter/ submillimeter Array data of the ringed protoplanetary disk orbiting the young star HL Tauri that show centrally peaked, bright emission arising from three distinct transitions of the main water isotopologue. The spatially and spectrally resolved water content probes gas in a thermal range down to the water sublimation temperature. Our analysis implies a stringent lower limit of 3.7 Earth oceans of water vapour available within the inner 17 astronomical units of the system. We show that our observations are limited to probing the water content in the atmosphere of the disk, due to the high dust column density and absorption, and indicate that the main water isotopologue is the best tracer to spatially resolve water vapour in protoplanetary disks."
https://arxiv.org/abs/2403.00646,2024-03-01,Stability-Certified Learning of Control Systems with Quadratic Nonlinearities,"['Igor Pontes Duff', 'Pawan Goyal', 'Peter Benner']","This work primarily focuses on an operator inference methodology aimed at constructing low-dimensional dynamical models based on a priori hypotheses about their structure, often informed by established physics or expert insights. Stability is a fundamental attribute of dynamical systems, yet it is not always assured in models derived through inference. Our main objective is to develop a method that facilitates the inference of quadratic control dynamical systems with inherent stability guarantees. To this aim, we investigate the stability characteristics of control systems with energy-preserving nonlinearities, thereby identifying conditions under which such systems are bounded-input bounded-state stable. These insights are subsequently applied to the learning process, yielding inferred models that are inherently stable by design. The efficacy of our proposed framework is demonstrated through a couple of numerical examples."
https://arxiv.org/abs/2403.00645,2024-03-01,Event-Triggered Robust Cooperative Output Regulation for a Class of Linear Multi-Agent Systems with an Unknown Exosystem,"['Yangyang Qian', 'Lu Liu']","This paper investigates the robust cooperative output regulation problem for a class of heterogeneous uncertain linear multi-agent systems with an unknown exosystem via event-triggered control (ETC). By utilizing the internal model approach and the adaptive control technique, a distributed adaptive internal model is constructed for each agent. Then, based on this internal model, a fully distributed ETC strategy composed of a distributed event-triggered adaptive output feedback control law and a distributed dynamic event-triggering mechanism is proposed, in which each agent updates its control input at its own triggering time instants. It is shown that under the proposed ETC strategy, the robust cooperative output regulation problem can be solved without requiring either the global information associated with the communication topology or the bounds of the uncertain or unknown parameters in each agent and the exosystem. A numerical example is provided to illustrate the effectiveness of the proposed control strategy."
https://arxiv.org/abs/2403.00644,2024-03-01,Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks,"['Yuhao Liu', 'Fang Liu', 'Zhanghan Ke', 'Nanxuan Zhao', 'Rynson W. H. Lau']","Diffusion models trained on large-scale datasets have achieved remarkable progress in image synthesis. However, due to the randomness in the diffusion process, they often struggle with handling diverse low-level tasks that require details preservation. To overcome this limitation, we present a new Diff-Plugin framework to enable a single pre-trained diffusion model to generate high-fidelity results across a variety of low-level tasks. Specifically, we first propose a lightweight Task-Plugin module with a dual branch design to provide task-specific priors, guiding the diffusion process in preserving image content. We then propose a Plugin-Selector that can automatically select different Task-Plugins based on the text instruction, allowing users to edit images by indicating multiple low-level tasks with natural language. We conduct extensive experiments on 8 low-level vision tasks. The results demonstrate the superiority of Diff-Plugin over existing methods, particularly in real-world scenarios. Our ablations further validate that Diff-Plugin is stable, schedulable, and supports robust training across different dataset sizes."
https://arxiv.org/abs/2403.00643,2024-03-01,"Undercomplete Decomposition of Symmetric Tensors in Linear Time, and Smoothed Analysis of the Condition Number","['Pascal Koiran', 'Subhayan Saha']","We study symmetric tensor decompositions, i.e., decompositions of the form $T = \sum_{i=1}^r u_i^{\otimes 3}$ where $T$ is a symmetric tensor of order 3 and $u_i \in \mathbb{C}^n$.In order to obtain efficient decomposition algorithms, it is necessary to require additional properties from $u_i$. In this paper we assume that the $u_i$ are linearly independent. This implies $r \leq n$,that is, the decomposition of T is undercomplete."
https://arxiv.org/abs/2403.00642,2024-03-01,Rethinking The Uniformity Metric in Self-Supervised Learning,"['Xianghong Fang', 'Jian Li', 'Qiang Sun', 'Benyou Wang']","Uniformity plays a crucial role in the assessment of learned representations, contributing to a deeper comprehension of self-supervised learning. The seminal work by \citet{Wang2020UnderstandingCR} introduced a uniformity metric that quantitatively measures the collapse degree of learned representations. Directly optimizing this metric together with alignment proves to be effective in preventing constant collapse. However, we present both theoretical and empirical evidence revealing that this metric lacks sensitivity to dimensional collapse, highlighting its limitations. To address this limitation and design a more effective uniformity metric, this paper identifies five fundamental properties, some of which the existing uniformity metric fails to meet. We subsequently introduce a novel uniformity metric that satisfies all of these desiderata and exhibits sensitivity to dimensional collapse. When applied as an auxiliary loss in various established self-supervised methods, our proposed uniformity metric consistently enhances their performance in downstream tasks.Our code was released at https://github.com/sunset-clouds/WassersteinUniformityMetric."
https://arxiv.org/abs/2403.00641,2024-03-01,Robust Online Epistemic Replanning of Multi-Robot Missions,"['Lauren Bramblett', 'Branko Miloradovic', 'Patrick Sherman', 'Alessandro V. Papadopoulos', 'Nicola Bezzo']","As Multi-Robot Systems (MRS) become more affordable and computing capabilities grow, they provide significant advantages for complex applications such as environmental monitoring, underwater inspections, or space exploration. However, accounting for potential communication loss or the unavailability of communication infrastructures in these application domains remains an open problem. Much of the applicable MRS research assumes that the system can sustain communication through proximity regulations and formation control or by devising a framework for separating and adhering to a predetermined plan for extended periods of disconnection. The latter technique enables an MRS to be more efficient, but breakdowns and environmental uncertainties can have a domino effect throughout the system, particularly when the mission goal is intricate or time-sensitive. To deal with this problem, our proposed framework has two main phases: i) a centralized planner to allocate mission tasks by rewarding intermittent rendezvous between robots to mitigate the effects of the unforeseen events during mission execution, and ii) a decentralized replanning scheme leveraging epistemic planning to formalize belief propagation and a Monte Carlo tree search for policy optimization given distributed rational belief updates. The proposed framework outperforms a baseline heuristic and is validated using simulations and experiments with aerial vehicles."
https://arxiv.org/abs/2403.00640,2024-03-01,J/psi-pair production at NLL in TMD factorisation at the LHC,"['Alice Colpani Serri', 'Jelle Bor', 'Daniel Boer', 'Jean-Philippe Lansberg']","J/psi-pair production at the LHC is currently one of the few tools available to probe gluon transverse momentum distributions (TMDs). In this context, data from LHCb in the collider mode have the potential to probe the evolution of the unpolarised-gluon TMDs and to measure the distribution of the linearly-polarised gluon in unpolarised protons for the first time. In this proceedings contribution, improved predictions obtained for the LHC (at sqrt(s) = 13 TeV) up to next-to-leading logarithm (NLL) in TMD factorisation are presented. We show the obtained predictions of transverse-momentum distributions at different invariant masses and rapidities computed in the LHCb acceptance along with PDF uncertainty. We predict the azimuthal modulations of the cross section that arise from linearly-polarised gluons."
https://arxiv.org/abs/2403.00639,2024-03-01,Hierarchical Bayesian Models to Mitigate Systematic Disparities in Prediction with Proxy Outcomes,"['Jonas Mikhaeil', 'Andrew Gelman', 'Philip Greengard']","Label bias occurs when the outcome of interest is not directly observable and instead modeling is performed with proxy labels. When the difference between the true outcome and the proxy label is correlated with predictors, this can yield systematic disparities in predictions for different groups of interest. We propose Bayesian hierarchical measurement models to address these issues. Through practical examples, we demonstrate how our approach improves accuracy and helps with algorithmic fairness."
https://arxiv.org/abs/2403.00638,2024-03-01,Performance optimization for a scintillating glass electromagnetic calorimeter at the EIC,"['J. Crafts', 'R. Fatemi', 'T. Horn', 'D. Kalinkin']","The successful realization of the EIC scientific program requires the design and construction of high-performance particle detectors. Recent developments in the field of scientific computing and increased availability of high performance computing resources have made it possible to perform optimization of multi-parameter designs, even when the latter require longer computational times (for example simulations of particle interactions with matter). Procedures involving machine-assisted techniques used to inform the design decision have seen a considerable growth in popularity among the EIC detector community. Having already been realized for tracking and RICH PID detectors, it has a potential application in calorimetry designs. A SciGlass barrel calorimeter originally designed for EIC Detector-1 has a semi-projective geometry that allows for non-trivial performance gains, but also poses special challenges in the way of effective exploration of the design space while satisfying the available space and the cell dimension constraints together with the full detector acceptance requirement. This talk will cover specific approaches taken to perform this detector design optimization."
https://arxiv.org/abs/2403.00637,2024-03-01,On the complexity of strong approximation of stochastic differential equations with a non-Lipschitz drift coefficient,"['T. MÃ¼ller-Gronbach', 'L. Yaroslavtseva']","We survey recent developments in the field of complexity of pathwise approximation in $p$-th mean of the solution of a stochastic differential equation at the final time based on finitely many evaluations of the driving Brownian motion. First, we briefly review the case of equations with globally Lipschitz continuous coefficients, for which an error rate of at least $1/2$ in terms of the number of evaluations of the driving Brownian motion is always guaranteed by using the equidistant Euler-Maruyama scheme. Then we illustrate that giving up the global Lipschitz continuity of the coefficients may lead to a non-polynomial decay of the error for the Euler-Maruyama scheme or even to an arbitrary slow decay of the smallest possible error that can be achieved on the basis of finitely many evaluations of the driving Brownian motion. Finally, we turn to recent positive results for equations with a drift coefficient that is not globally Lipschitz continuous. Here we focus on scalar equations with a Lipschitz continuous diffusion coefficient and a drift coefficient that satisfies piecewise smoothness assumptions or has fractional Sobolev regularity and we present corresponding complexity results."
https://arxiv.org/abs/2403.00636,2024-03-01,Graph Theory and GNNs to Unravel the Topographical Organization of Brain Lesions in Variants of Alzheimer's Disease Progression,"['Leopold Hebert-Stevens', 'Gabriel Jimenez', 'Benoit Delatour', 'Lev Stimmer', 'Daniel Racoceanu']","This study utilizes graph theory and deep learning to assess variations in Alzheimer's disease (AD) neuropathologies, focusing on classic (cAD) and rapid (rpAD) progression forms. It analyses the distribution of amyloid plaques and tau tangles in postmortem brain tissues. Histopathological images are converted into tau-pathology-based graphs, and derived metrics are used for statistical analysis and in machine learning classifiers. These classifiers incorporate SHAP value explainability to differentiate between cAD and rpAD. Graph neural networks (GNNs) demonstrate greater efficiency than traditional CNN methods in analyzing this data, preserving spatial pathology context. Additionally, GNNs provide significant insights through explainable AI techniques. The analysis shows denser networks in rpAD and a distinctive impact on brain cortical layers: rpAD predominantly affects middle layers, whereas cAD influences both superficial and deep layers of the same cortical regions. These results suggest a unique neuropathological network organization for each AD variant."
https://arxiv.org/abs/2403.00635,2024-03-01,On the asymptotic behavior for partitions separated by parity,"['Kathrin Bringmann', 'William Craig', 'Caner Nazaroglu']","The study of partitions with parts separated by parity was initiated by Andrews in connection with Ramanujan's mock theta functions, and his variations on this theme have produced generating functions with a large variety of different modular properties. In this paper, we use Ingham's Tauberian theorem to compute the asymptotic main term for each of the eight functions studied by Andrews."
https://arxiv.org/abs/2403.00634,2024-03-01,"Atmospheric entry and fragmentation of small asteroid 2024 BX1: Bolide trajectory, orbit, dynamics, light curve, and spectrum","['P. Spurny', 'J. Borovicka', 'L. Shrbeny', 'M. Hankey', 'R. Neubert']","Asteroid 2024 BX1 was the eighth asteroid discovered shortly before colliding with the Earth.The associated bolide was recorded by dedicated instruments of the European Fireball Network and the AllSky7 network on January 21, 2024 at 0:32:38-44 UT. Here we report a comprehensive analysis of this instrumentally observed meteorite fall, which occurred as predicted west of Berlin, Germany. The atmospheric trajectory was quite steep with an average slope to the Earth's surface 75.6 degrees. The entry speed was 15.20 km/s. The heliocentric orbit calculated from the bolide data agrees very well with the asteroid data. However, the bolide was fainter than expected for a reportedly meter-sized asteroid. The absolute magnitude reached -14.4 and the entry mass was estimated to 140 kg. The recorded bolide spectrum was low in iron from what an enstatite-rich meteorite was expected. Indeed, the recovered meteorites, called Ribbeck, were classified as aubrites. The high albedo of enstatite (E-type) asteroids can explain the size discrepancy. The asteroid was likely smaller than 0.5 meter and should be rather called a meteoroid. During the atmospheric entry, the meteoroid severely fragmented into much smaller pieces already at a height of 55 km under the aerodynamic pressure of 0.12 MPa. The primary fragments were then breaking-up again, most frequently at heights 39-29 km (0.9-2.2 MPa). Numerous small meteorites and up to four stones larger than 100g were expected to land. Within a few days of publishing the strewn field dozens of meteorites were found in the area we predicted."
https://arxiv.org/abs/2403.00633,2024-03-01,Informed and Assessable Observability Design Decisions in Cloud-native Microservice Applications,"['Maria C. Borges', 'Joshua Bauer', 'Sebastian Werner', 'Michael Gebauer', 'Stefan Tai']","Observability is important to ensure the reliability of microservice applications. These applications are often prone to failures, since they have many independent services deployed on heterogeneous environments. When employed ""correctly"", observability can help developers identify and troubleshoot faults quickly. However, instrumenting and configuring the observability of a microservice application is not trivial but tool-dependent and tied to costs. Architects need to understand observability-related trade-offs in order to weigh between different observability design alternatives. Still, these architectural design decisions are not supported by systematic methods and typically just rely on ""professional intuition"". In this paper, we argue for a systematic method to arrive at informed and continuously assessable observability design decisions. Specifically, we focus on fault observability of cloud-native microservice applications, and turn this into a testable and quantifiable property. Towards our goal, we first model the scale and scope of observability design decisions across the cloud-native stack. Then, we propose observability metrics which can be determined for any microservice application through so-called observability experiments. We present a proof-of-concept implementation of our experiment tool OXN. OXN is able to inject arbitrary faults into an application, similar to Chaos Engineering, but also possesses the unique capability to modify the observability configuration, allowing for the assessment of design decisions that were previously left unexplored. We demonstrate our approach using a popular open source microservice application and show the trade-offs involved in different observability design decisions."
https://arxiv.org/abs/2403.00632,2024-03-01,"Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling","['Qian Wan', 'Xin Feng', 'Yining Bei', 'Zhiqi Gao', 'Zhicong Lu']","Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way."
https://arxiv.org/abs/2403.00631,2024-03-01,Transforming Design Spaces Using Pareto-Laplace Filters,"['Hazhir Aliahmadi', 'Ruben Perez', 'Greg van Anders']","Optimization is a critical tool for addressing a broad range of human and technical problems. However, the paradox of advanced optimization techniques is that they have maximum utility for problems in which the relationship between the structure of the problem and the ultimate solution is the most obscure. The existence of solution with limited insight contrasts with techniques that have been developed for a broad range of engineering problems where integral transform techniques yield solutions and insight in tandem. Here, we present a ``Pareto-Laplace'' integral transform framework that can be applied to problems typically studied via optimization. We show that the framework admits related geometric, statistical, and physical representations that provide new forms of insight into relationships between objectives and outcomes. We argue that some known approaches are special cases of this framework, and point to a broad range of problems for further application."
https://arxiv.org/abs/2403.00630,2024-03-01,Harnessing the superconducting diode effect through inhomogeneous magnetic fields,"['Leonardo Rodrigues Cadorim', 'Edson Sardella', 'ClÃ©cio Clemente de Souza Silva']","We propose a superconducting diode device comprising a central superconducting film flanked by two wires carrying an applied DC bias, suitably chosen so as to generate different asymmetric field profiles. Through numerical simulations of the coupled Ginzburg-Landau and heat-diffusion equations, we show that this design is capable of efficiently breaking the reciprocity of the critical current in the central superconductor, thus promoting the diode effect in response to an applied AC current. By adjusting the DC bias in the wires, we find the optimum inhomogeneous field profile that facilitates the entrance of vortices and antivortices in a given polarity of the applied AC current and impede their entrance in the other polarity. This way, the system behaves as an ideal superconducting half-wave rectifier, with diode efficiencies surpassing 70%. Furthermore, we detail the behavior and diode efficiency of the system under different experimental conditions, such as the substrate heat transfer coefficient and the sweep rate of the external current."
https://arxiv.org/abs/2403.00629,2024-03-01,Pseudoscalar Mesons and Emergent Mass,"['K. Raya', 'A. Bashir', 'D. Binosi', 'C. D. Roberts', 'J. RodrÃ­guez-Quintero']","Despite its role in the continuing evolution of the Universe, only a small fraction of the mass of visible material can be attributed to the Higgs boson alone. The overwhelmingly dominant share may/should arise from the strong interactions that act in the heart of nuclear matter; namely, those described by quantum chromodynamics. This contribution describes how studying and explaining the attributes of pseudoscalar mesons can open an insightful window onto understanding the origin of mass in the Standard Model and how these insights inform our knowledge of hadron structure. The survey ranges over distribution amplitudes and functions, electromagnetic and gravitational form factors, light-front wave functions, and generalized parton distributions. Advances made using continuum Schwinger function methods and their relevance for experimental efforts are highlighted."
https://arxiv.org/abs/2403.00628,2024-03-01,Region-Adaptive Transform with Segmentation Prior for Image Compression,"['Yuxi Liu', 'Wenhan Yang', 'Huihui Bai', 'Yunchao Wei', 'Yao Zhao']","Learned Image Compression (LIC) has shown remarkable progress in recent years. Existing works commonly employ CNN-based or self-attention-based modules as transform methods for compression. However, there is no prior research on neural transform that focuses on specific regions. In response, we introduce the class-agnostic segmentation masks (i.e. semantic masks without category labels) for extracting region-adaptive contextual information. Our proposed module, Region-Adaptive Transform, applies adaptive convolutions on different regions guided by the masks. Additionally, we introduce a plug-and-play module named Scale Affine Layer to incorporate rich contexts from various regions. While there have been prior image compression efforts that involve segmentation masks as additional intermediate inputs, our approach differs significantly from them. Our advantages lie in that, to avoid extra bitrate overhead, we treat these masks as privilege information, which is accessible during the model training stage but not required during the inference phase. To the best of our knowledge, we are the first to employ class-agnostic masks as privilege information and achieve superior performance in pixel-fidelity metrics, such as Peak Signal to Noise Ratio (PSNR). The experimental results demonstrate our improvement compared to previously well-performing methods, with about 8.2% bitrate saving compared to VTM-17.0. The code will be released at https://github.com/GityuxiLiu/Region-Adaptive-Transform-with-Segmentation-Prior-for-Image-Compression."
https://arxiv.org/abs/2403.00627,2024-03-01,Considerations on the time resolution of single pixel irradiated 3D devices up to 1017 n$_{eq}$/cm$^{2}$ at 120 GeV SPS pion beams,"['Evangelos-Leonidas Gkougkousis', 'Edgar Lemos Cid', 'Viktor Coco']","The proven radiation hardness of silicon 3D devices up to fluences of $1 {\times} 10^{17}$ $n_{eq}/cm^{2}$ makes them an excellent choice for next generation trackers, providing < 10 $Î¼m$ position resolution at a high multiplicity environment. The anticipated pile-up increase at HL-LHC conditions and beyond, requires the addition of < 50 ps per hit timing information to successfully resolve displaced and primary vertices. In this study, the timing performance, uniformity and efficiency of neutron and proton irradiated single pixel 3D devices is discussed. Fluences up to $1 {\times} 10^{17}$ $n_{eq}/cm^{2}$ in three different geometrical implementations are evaluated using 120 GeV SPS pion beams. A MIMOSA-26 type telescope is used to provide detailed tracking information with a ~ 5 $Î¼m$ position resolution. Productions with single- and double-sided processes, yielding active thicknesses of 130 and 230 $Î¼m$ respectively, are examined with varied pixel sizes from $55 {\times} 55$ $Î¼m^{2}$ to $25 {\times} 100$ $Î¼m^{2}$ and a comparative study of field uniformity is presented with respect to electrode geometry. The question of electronics bandwidth is extensively addressed with respect to achievable time resolution, efficiency and collected charge, forming a 3D phase space to which an appropriate operating point can be selected depending on the application requirements."
https://arxiv.org/abs/2403.00626,2024-03-01,The First Spatially-resolved Detection of $^{13}$CN in a Protoplanetary Disk and Evidence for Complex Carbon Isotope Fractionation,"['Tomohiro C. Yoshida', 'Hideko Nomura', 'Kenji Furuya', 'Richard Teague', 'Charles J. Law', 'Takashi Tsukagoshi', 'Seokho Lee', 'Christian Rab', 'Karin I. Ãberg', 'Ryan A. Loomis']","Recent measurements of carbon isotope ratios in both protoplanetary disks and exoplanet atmospheres have suggested a possible transfer of significant carbon isotope fractionation from disks to planets. For a clearer understanding of the isotopic link between disks and planets, it is important to measure the carbon isotope ratios in various species. In this paper, we present a detection of the $^{13}$CN $N=2-1$ hyperfine lines in the TW Hya disk with the Atacama Large Millimeter/submillimeter Array. This is the first spatially-resolved detection of $^{13}$CN in disks, which enables us to measure the spatially resolved $^{12}$CN/$^{13}$CN ratio for the first time. We conducted non-local thermal equilibrium modeling of the $^{13}$CN lines in conjunction with previously observed $^{12}$CN lines to derive the kinetic temperature, ${\rm H_2}$ volume density, and column densities of $^{12}$CN and $^{13}$CN. The ${\rm H_2}$ volume density is found to range between $ (4 - 10)\times10^7 \ {\rm cm^{-3}}$, suggesting that CN molecules mainly reside in the disk upper layer. The $^{12}$CN/$^{13}$CN ratio is measured to be $ 70^{+9}_{-6}$ at $30 < r < 80$ au from the central star, which is similar to the $\rm ^{12}C/^{13}C$ ratio in the interstellar medium. However, this value differs from the previously reported values found for other carbon-bearing molecules (CO and HCN) in the TW Hya disk. This could be self-consistently explained by different emission layer heights for different molecules combined with preferential sequestration of $\rm ^{12}C$ into the solid phase towards the disk midplane. This study reveals the complexity of the carbon isotope fractionation operating in disks."
https://arxiv.org/abs/2403.00625,2024-03-01,Bias Mitigation in Fine-tuning Pre-trained Models for Enhanced Fairness and Efficiency,"['Yixuan Zhang', 'Feng Zhou']","Fine-tuning pre-trained models is a widely employed technique in numerous real-world applications. However, fine-tuning these models on new tasks can lead to unfair outcomes. This is due to the absence of generalization guarantees for fairness properties, regardless of whether the original pre-trained model was developed with fairness considerations. To tackle this issue, we introduce an efficient and robust fine-tuning framework specifically designed to mitigate biases in new tasks. Our empirical analysis shows that the parameters in the pre-trained model that affect predictions for different demographic groups are different, so based on this observation, we employ a transfer learning strategy that neutralizes the importance of these influential weights, determined using Fisher information across demographic groups. Additionally, we integrate this weight importance neutralization strategy with a matrix factorization technique, which provides a low-rank approximation of the weight matrix using fewer parameters, reducing the computational demands. Experiments on multiple pre-trained models and new tasks demonstrate the effectiveness of our method."
https://arxiv.org/abs/2403.00624,2024-03-01,Hadron momentum spectra from analytical solutions of relativistic hydrodynamics,"['Mahammad Sabir Ali', 'Deeptak Biswas', 'Amaresh Jaiswal', 'Sushant K. Singh']","We present analytical solution of relativistic hydrodynamics for a system having cylindrical symmetry with boost-invariant longitudinal expansion and Hubble-like transverse expansion. We also consider analytical solution for Hubble-like spherically expanding system. For these two cases, we calculate analytical expression for transverse momentum spectra of hadrons, at constant temperature freeze-out hypersurface using Cooper-Frye prescription. We compare our results for transverse momentum spectra with experimental results from Large Hadron Collider and CERN SPS where one expects cylindrical and spherical geometry of the fireball, respectively. In the case of low-energy collisions with spherical geometry, we calculate rapidity spectra and compare with the results from CERN SPS."
https://arxiv.org/abs/2403.00623,2024-03-01,Analysis of the particle relaxation method for generating uniform particle distributions in smoothed particle hydrodynamics,"['Yu Fan', 'Xiaoliang Li', 'Shuoguo Zhang', 'Xiangyu Hu', 'Nikolaus A. Adams']","We establish a theoretical framework of the particle relaxation method for uniform particle generation of Smoothed Particle Hydrodynamics. We achieve this by reformulating the particle relaxation as an optimization problem. The objective function is an integral difference between discrete particle-based and smoothed-analytical volume fractions. The analysis demonstrates that the particle relaxation method in the domain interior is essentially equivalent to employing a gradient descent approach to solve this optimization problem, and we can extend such an equivalence to the bounded domain by introducing a proper boundary term. Additionally, each periodic particle distribution has a spatially uniform particle volume, denoted as characteristic volume. The relaxed particle distribution has the largest characteristic volume, and the kernel cut-off radius determines this volume. This insight enables us to control the relaxed particle distribution by selecting the target kernel cut-off radius for a given kernel function."
https://arxiv.org/abs/2403.00622,2024-03-01,Shortened Polar Codes under Automorphism Ensemble Decoding,"['Charles Pillet', 'Ilshat Sagitov', 'Valerio Bioglio', 'Pascal Giard']","In this paper, we propose a low-latency decoding solution of shortened polar codes based on their automorphism groups. The automorphism group of shortened polar codes, designed according to two existing shortening patterns, are shown to be limited but non-empty, making the Automorphism Ensemble (AE) decoding of shortened polar codes possible. Extensive simulation results for shortened polar codes under AE are provided and are compared to the SC-List (SCL) algorithm. The block-error rate of shortened polar codes under AE matches or beats SCL while lowering the decoding latency."
https://arxiv.org/abs/2403.00621,2024-03-01,AdaBoost-Based Efficient Channel Estimation and Data Detection in One-Bit Massive MIMO,"['Majdoddin Esfandiari', 'Sergiy A. Vorobyov', 'Robert W. Heath Jr']","The use of one-bit analog-to-digital converter (ADC) has been considered as a viable alternative to high resolution counterparts in realizing and commercializing massive multiple-input multiple-output (MIMO) systems. However, the issue of discarding the amplitude information by one-bit quantizers has to be compensated. Thus, carefully tailored methods need to be developed for one-bit channel estimation and data detection as the conventional ones cannot be used. To address these issues, the problems of one-bit channel estimation and data detection for MIMO orthogonal frequency division multiplexing (OFDM) system that operates over uncorrelated frequency selective channels are investigated here. We first develop channel estimators that exploit Gaussian discriminant analysis (GDA) classifier and approximated versions of it as the so-called weak classifiers in an adaptive boosting (AdaBoost) approach. Particularly, the combination of the approximated GDA classifiers with AdaBoost offers the benefit of scalability with the linear order of computations, which is critical in massive MIMO-OFDM systems. We then take advantage of the same idea for proposing the data detectors. Numerical results validate the efficiency of the proposed channel estimators and data detectors compared to other methods. They show comparable/better performance to that of the state-of-the-art methods, but require dramatically lower computational complexities and run times."
https://arxiv.org/abs/2403.00620,2024-03-01,Properties of Lipschitz smoothing heat semigroups,"['NicolÃ² De Ponti', 'Giorgio Stefani']","We prove several functional and geometric inequalities only assuming the linearity and a quantitative $\mathrm{L}^\infty$-to-Lipschitz smoothing of the heat semigroup in metric-measure spaces. Our results comprise a Buser inequality, a lower bound on the size of the nodal set of a Laplacian eigenfunction, and different estimates involving the Wasserstein distance. The approach works in large variety settings, including Riemannian manifolds with a variable Kato-type lower bound on the Ricci curvature tensor, $\mathsf{RCD}(K,\infty)$ spaces, and some sub-Riemannian structures, such as Carnot groups, the Grushin plane and the $\mathbb{SU}(2)$ group."
https://arxiv.org/abs/2403.00619,2024-03-01,Stationary entrance chains and applications to random walks,"['Aleksandar Mijatovic', 'Vladislav Vysotsky']","For a Markov chain $Y$ with values in a Polish space, consider the entrance chain obtained by sampling $Y$ at the moments when it enters a fixed set $A$ from its complement $A^c$. Similarly, consider the exit chain, obtained by sampling $Y$ at the exit times from $A^c$ to $A$. We use the method of inducing from ergodic theory to study invariant measures of these two types of Markov chains in the case when the initial chain $Y$ has a known invariant measure. We give explicit formulas for invariant measures of the entrance and exit chains under certain recurrence-type assumptions on $A$ and $A^c$, which apply even for transient chains. Then we study uniqueness and ergodicity of these invariant measures assuming that $Y$ is topologically recurrent, topologically irreducible, and weak Feller."
https://arxiv.org/abs/2403.00618,2024-03-01,Energy extracted from Hartle-Thorne strange stars,"['Alpha O. Djalo', 'Felipe A. Asenjo']","It is discussed how Penrose process can be used in a strange star, described by the Hartle-Thorne metric, to extract its rotational energy. This metric has an ergosphere region that depends only on its angular momentum. It is shown that massive particles with negative energy can exist in this ergosphere, exploring the conditions on the radial distance and on angular momentum for this to occur. It is also calculated the total amount of rotational energy that can be extracted from the strange star, and how these conditions cannot be fulfilled by a star with regular matter."
https://arxiv.org/abs/2403.00617,2024-03-01,Distortion in Correspondence Analysis and in Taxicab Correspondence Analysis: A Comparison,['Vartan Choulakian'],"Distortion is a fundamental well-studied topic in dimension reduction papers, and intimately related with the underlying intrinsic dimension of a mapping of a high dimensional data set onto a lower dimension. In this paper, we study embedding distortions produced by Correspondence Analysis and its robust l1 variant Taxicab Correspondence analysis, which are visualization methods for contingency tables. For high dimensional data, distortions in Correspondence Analysis are contractions; while distortions in Taxicab Correspondence Analysis could be contractions or stretchings. This shows that Euclidean geometry is quite rigid, because of the orthogonality property; while Taxicab geometry is quite flexible, because the orthogonality property is replaced by the conjugacy property."
https://arxiv.org/abs/2403.00616,2024-03-01,Gate-set evaluation metrics for closed-loop optimal control on nitrogen-vacancy center ensembles in diamond,"['Philipp J. Vetter', 'Thomas Reisser', 'Maximilian G. Hirsch', 'Tommaso Calarco', 'Felix Motzoi', 'Fedor Jelezko', 'Matthias M. MÃ¼ller']","A recurring challenge in quantum science and technology is the precise control of their underlying dynamics that lead to the desired quantum operations, often described by a set of quantum gates. These gates can be subject to application-specific errors, leading to a dependence of their controls on the chosen circuit, the quality measure and the gate-set itself. A natural solution would be to apply quantum optimal control in an application-oriented fashion. In turn, this requires the definition of a meaningful measure of the contextual gate-set performance. Therefore, we explore and compare the applicability of quantum process tomography, linear inversion gate-set tomography, randomized linear gate-set tomography, and randomized benchmarking as measures for closed-loop quantum optimal control experiments, using a macroscopic ensemble of nitrogen-vacancy centers in diamond as a test-bed. Our work demonstrates the relative trade-offs between those measures and how to significantly enhance the gate-set performance, leading to an improvement across all investigated methods."
https://arxiv.org/abs/2403.00615,2024-03-01,Superconductivity Mediated by Nematic Fluctuations in Tetragonal $\textrm{Fe}\textrm{Se}_{1-x}\textrm{S}_{x}$,"['Pranab Kumar Nag', 'Kirsty Scott', 'Vanuildo S. de Carvalho', 'Journey K. Byland', 'Xinze Yang', 'Morgan Walker', 'Aaron G. Greenberg', 'Peter Klavins', 'Eduardo Miranda', 'Adrian Gozar', 'Valentin Taufour', 'Rafael M. Fernandes', 'Eduardo H. da Silva Neto']","Nematic phases, where electrons in a solid spontaneously break rotational symmetry while preserving the translational symmetry, exist in several families of unconventional superconductors [1, 2]. Although superconductivity mediated by nematic fluctuations is well established theoretically [3-7], it has yet to be unambiguously identified experimentally [8, 9]. A major challenge is that nematicity is often intertwined with other degrees of freedom, such as magnetism and charge order. The FeSe$_{1-x}$S$_x$ family of iron based superconductors provides a unique opportunity to explore this concept, as it features an isolated nematic phase that can be suppressed by sulfur substitution at a quantum critical point (QCP) near $x_c = 0.17$, where nematic fluctuations are the largest [10-12]. Here, we performed scanning tunneling spectroscopy measurements to visualize Boguliubov quasiparticle interference patterns, from which we determined the momentum structure of the superconducting gap near the Brillouin zone $Î$ point of FeSe$_{0.81}$S$_{0.19}$. The results reveal an anisotropic, near nodal gap with minima that are $45^\circ$ rotated with respect to the Fe-Fe direction, characteristic of a nematic pairing interaction, contrary to the usual isotropic gaps due to spin mediated pairing in other tetragonal Fe-based superconductors. The results are also in contrast with pristine FeSe, where the pairing is mediated by spin fluctuations and the gap minima are aligned with the Fe-Fe direction. Therefore, the measured gap structure demonstrates not only a fundamental change of the pairing mechanism across the phase diagram of FeSe$_{1-x}$S$_x$, but it also indicates the existence of superconductivity mediated by nematic fluctuations in FeSe$_{0.81}$S$_{0.19}$."
https://arxiv.org/abs/2403.00614,2024-03-01,A Light-Front Model for the Transition Distribution Amplitudes for Backward Timelike Compton Scattering,"['B. Pasquini', 'A. Schiavi']","To access information on the internal structure of the nucleon, data from a variety of scattering experiments can be analyzed, in regimes where the information factorizes from an otherwise known scattering amplitude. A recent development, promising new insight, is the study of exclusive reactions in the backward kinematical region, where the information can be encoded in Transition Distribution Amplitudes (TDAs). We model the photon-to-nucleon TDAs, entering the factorized description of backward Timelike Compton Scattering, using techniques of light-front dynamics to integrate information from a quark model for the photon and the nucleon. We include the results of numerical predictions that could inform further experiments at Jefferson Lab and the future Electron--Ion Collider."
https://arxiv.org/abs/2403.00613,2024-03-01,Complete and Near-Optimal Robotic Crack Coverage and Filling in Civil Infrastructure,"['Vishnu Veeraraghavan', 'Kyle Hunte', 'Jingang Yi', 'Kaiyan Yu']","We present a simultaneous sensor-based inspection and footprint coverage (SIFC) planning and control design with applications to autonomous robotic crack mapping and filling. The main challenge of the SIFC problem lies in the coupling of complete sensing (for mapping) and robotic footprint (for filling) coverage tasks. Initially, we assume known target information (e.g., crack) and employ classic cell decomposition methods to achieve complete sensing coverage of the workspace and complete robotic footprint coverage using the least-cost route. Subsequently, we generalize the algorithm to handle unknown target information, allowing the robot to scan and incrementally construct the target graph online while conducting robotic footprint coverage. The online polynomial-time SIFC planning algorithm minimizes the total robot traveling distance, guarantees complete sensing coverage of the entire workspace, and achieves near-optimal robotic footprint coverage, as demonstrated through empirical experiments. For the demonstrated application, we design coordinated nozzle motion control with the planned robot trajectory to efficiently fill all cracks within the robot's footprint. Experimental results are presented to illustrate the algorithm's design, performance, and comparisons. The SIFC algorithm offers a high-efficiency motion planning solution for various robotic applications requiring simultaneous sensing and actuation coverage."
https://arxiv.org/abs/2403.00612,2024-03-01,Advancing dermatological diagnosis: Development of a hyperspectral dermatoscope for enhanced skin imaging,"['Martin J. Hetz', 'Carina Nogueira Garcia', 'Sarah HaggenmÃ¼ller', 'Titus J. Brinker']","Clinical dermatology necessitates precision and innovation for efficient diagnosis and treatment of various skin conditions. This paper introduces the development of a cutting-edge hyperspectral dermatoscope (the Hyperscope) tailored for human skin analysis. We detail the requirements to such a device and the design considerations, from optical configurations to sensor selection, necessary to capture a wide spectral range with high fidelity. Preliminary results from 15 individuals and 160 recorded skin images demonstrate the potential of the Hyperscope in identifying and characterizing various skin conditions, offering a promising avenue for non-invasive skin evaluation and a platform for future research in dermatology-related hyperspectral imaging."
https://arxiv.org/abs/2403.00611,2024-03-01,Probabilistic positioning via ray tracing with noisy angle of arrival measurements,"['Vincent Corlay', 'Viet-Hoa Nguyen', 'Nicolas Gresset']","This paper investigates the problems of interference prediction and sensing for efficient spectrum access and link adaptation. The considered approach for interference prediction relies on a parametric model. However, we assume that the number of observations available to learn theses parameters is limited. This implies that they should be treated as random variables rather than fixed values. We show how this can impact the spectrum access and link adaptation strategies. We also introduce the notion of ""interferer-coherence time"" to establish the number of independent interferer state realizations experienced by a codeword. We explain how it can be computed taking into account the model uncertainty and how this impacts the link adaptation."
https://arxiv.org/abs/2403.00610,2024-03-01,Electrochemical Evaluation of Mg and a Mg-Al 5%Zn Metal Rich Primers for Protection of Al-Zn-Mg-Cu Alloy in NaCl,"['A. Korjenic', 'L. Blohm', 'J. R. Scully']","High purity magnesium and a Mg-Al 5wt% Zn metal rich primer (MRP) were compared for their ability to suppress intergranular corrosion (IGC) and intergranular stress corrosion cracking (IG-SCC) in peak aged AA 7075-T651 by sacrificial anode-based cathodic prevention. Tests were conducted in 0.6 M NaCl solution under full immersion. These evaluations considered the ability of the primer to attain an intermediate negative open circuit potential (OCP) such that the galvanic couple potential with bare aluminum alloy (AA) 7075-T651 resided below a range of potentials where IGC is prevalent. The ability of the primer to achieve an OCP negative enough that the AA 7075-T651 could be protected by sacrificial anode-based cathodic prevention and the ability to sustain this function over time were evaluated as a first step by utilizing a NaCl solution. The primers consisted of epoxy resins embedded with either (1) Mg flake pigments (MgRP) or (2) Mg flake pigments and spherical Al-5 wt.% Zn together as a composite (MgAlRP). MgRP was an effective coating for cathodic protection but dispensed less anodic charge than the composite MgAlRP. Cross-sectional analysis demonstrated that some Mg flakes dissolved while uniform surface oxidation occurred on the remaining Mg flakes which led to impaired activation. The composite MgAlRP maintained a suitably negative OCP over time, remained activated, dispensed high anodic charge, and remained an anode in zero resistance ammeter testing. Chemical stability modeling and zero resistance ammeter testing suggest that Mg corrosion elevates the pH which dissolved aluminum oxides and hydroxide thereby activates the Al-5wt.% Zn pigments, thereby providing a primary (i.e. Mg corrosion) and secondary process to enable superior (activation of Al-5wt%Zn) sacrificial anode-based cathodic protection."
https://arxiv.org/abs/2403.00609,2024-03-01,Rotating spirals for three-component competition systems,"['Zaizheng Li', 'Susanna Terracini']",We investigate the existence of rotating spirals for three-component competition-diffusion systems in $B_1\subset \mathbb{R}^2$:
https://arxiv.org/abs/2403.00608,2024-03-01,LV: A HeI survey of close-in giant planets hosted by M-K dwarf stars with GIANO-B,"['G. Guilluy', ""M. C. D'Arpa"", 'A. S. Bonomo', 'R. Spinelli', 'F. Biassoni', 'L. Fossati', 'A. Maggio', 'P. Giacobbe', 'A. F. Lanza', 'A. Sozzetti', 'F. Borsa', 'M. Rainer', 'G. Micela', 'L. Affer', 'G. Andreuzzi', 'A. Bignamini', 'W. Boschin', 'I. Carleo', 'M. Cecconi', 'S. Desidera', 'V. Fardella', 'A. Ghedina', 'G. Mantovan', 'L. Mancini', 'V. Nascimbeni']","Atmospheric escape plays a fundamental role in shaping the properties of exoplanets. The metastable near-infrared helium triplet at 1083.3 nm (HeI) is a powerful proxy of extended and evaporating atmospheres. We used the GIARPS (GIANO-B+HARPS-N) observing mode of the Telescopio Nazionale Galileo to search for HeI absorption in the upper atmosphere of five close-in giant planets hosted by the K and M dwarf stars of our sample, namely WASP-69b, WASP-107b, HAT-P-11b, GJ436b, and GJ3470b. We focused our analysis on the HeI triplet by performing high-resolution transmission spectroscopy. When nightly variability in the HeI absorption signal was identified, we investigated the potential influence of stellar magnetic activity by searching for variations in the H$Î±$. We spectrally resolve the HeI triplet and confirm the published detections for WASP-69b (3.91$\pm$0.22%, 17.6$Ï$), WASP-107b (8.17$^{+0.80}_{-0.76}$%, 10.5$Ï$), HAT-P-11b (1.36$\pm$0.17%, 8.0$Ï$), and GJ3470b (1.75$^{+0.39}_{-0.36}$%, 4.7$Ï$). We do not find evidence of extra absorption for GJ436b. We observe night-to-night variations in the HeI absorption signal for WASP-69b, associated with variability in H$Î±$, which likely indicates the influence of stellar activity. Additionally, we find that the HeI signal of GJ3470b originates from a single transit, thereby corroborating the discrepancies in the existing literature. An inspection of the H$Î±$ reveals an absorption signal during the same transit. By combining our findings with previous analyses of GIANO-B HeI measurements of planets around K dwarfs, we explore potential trends with planetary/stellar parameters that are thought to affect the HeI absorption. Our analysis is unable to identify clear patterns, emphasising the need for further measurements and the exploration of additional potential parameters that might influence HeI absorption."
https://arxiv.org/abs/2403.00607,2024-03-01,Dynamic Operational Planning in Warfare: A Stochastic Game Approach to Military Campaigns,"['Joseph E. McCarthy', 'Mathieu Dahan', 'Chelsea C. White III']","We study a two-player discounted zero-sum stochastic game model for dynamic operational planning in military campaigns. At each stage, the players manage multiple commanders who order military actions on objectives that have an open line of control. When a battle over the control of an objective occurs, its stochastic outcome depends on the actions and the enabling support provided by the control of other objectives. Each player aims to maximize the cumulative number of objectives they control, weighted by their criticality. To solve this large-scale stochastic game, we derive properties of its Markov perfect equilibria by leveraging the logistics and military operational command and control structure. We show the consequential isotonicity of the optimal value function with respect to the partially ordered state space, which in turn leads to a significant reduction of the state and action spaces. We also accelerate Shapley's value iteration algorithm by eliminating dominated actions and investigating pure equilibria of the matrix game solved at each iteration. We demonstrate the computational value of our equilibrium results on a case study that reflects representative operational-level military campaigns with geopolitical implications. Our analysis reveals a complex interplay between the game's parameters and dynamics in equilibrium, resulting in new military insights for campaign analysts."
https://arxiv.org/abs/2403.00606,2024-03-01,Flattening Singular Values of Factorized Convolution for Medical Images,"['Zexin Feng', 'Na Zeng', 'Jiansheng Fang', 'Xingyue Wang', 'Xiaoxi Lu', 'Heng Meng', 'Jiang Liu']","Convolutional neural networks (CNNs) have long been the paradigm of choice for robust medical image processing (MIP). Therefore, it is crucial to effectively and efficiently deploy CNNs on devices with different computing capabilities to support computer-aided diagnosis. Many methods employ factorized convolutional layers to alleviate the burden of limited computational resources at the expense of expressiveness. To this end, given weak medical image-driven CNN model optimization, a Singular value equalization generalizer-induced Factorized Convolution (SFConv) is proposed to improve the expressive power of factorized convolutions in MIP models. We first decompose the weight matrix of convolutional filters into two low-rank matrices to achieve model reduction. Then minimize the KL divergence between the two low-rank weight matrices and the uniform distribution, thereby reducing the number of singular value directions with significant variance. Extensive experiments on fundus and OCTA datasets demonstrate that our SFConv yields competitive expressiveness over vanilla convolutions while reducing complexity."
https://arxiv.org/abs/2403.00605,2024-03-01,Channel Measurements and Modeling for Dynamic Vehicular ISAC Scenarios at 28 GHz,"['Zhengyu Zhang', 'Ruisi He', 'Bo Ai', 'Mi Yang', 'Xuejian Zhang', 'Ziyi Qi', 'Yuan Yuan']","Integrated sensing and communication (ISAC) is a promising technology for 6G, with the goal of providing end-to-end information processing and inherent perception capabilities for future communication systems. Within ISAC emerging application scenarios, vehicular ISAC technologies have the potential to enhance traffic efficiency and safety through integration of communication and synchronized perception abilities. To establish a foundational theoretical support for vehicular ISAC system design and standardization, it is necessary to conduct channel measurements, and modeling to obtain a deep understanding of the radio propagation. In this paper, a dynamic statistical channel model is proposed for vehicular ISAC scenarios, incorporating Sensing Multipath Components (S-MPCs) and Clutter Multipath Components (C-MPCs), which are identified by the proposed tracking algorithm. Based on actual vehicular ISAC channel measurements at 28 GHz, time-varying sensing characteristics in front, left, and right directions are investigated. To model the dynamic evolution process of channel, number of new S-MPCs, lifetimes, initial power and delay positions, dynamic variations within their lifetimes, clustering, power decay, and fading of C-MPCs are statistically characterized. Finally, the paper provides implementation of dynamic vehicular ISAC model and validates it by comparing key simulation statistics between measurements and simulations."
https://arxiv.org/abs/2403.00604,2024-03-01,ODVista: An Omnidirectional Video Dataset for super-resolution and Quality Enhancement Tasks,"['Ahmed Telili', 'Ibrahim Farhat', 'Wassim Hamidouche', 'Hadi Amirpour']","Omnidirectional or 360-degree video is being increasingly deployed, largely due to the latest advancements in immersive virtual reality (VR) and extended reality (XR) technology. However, the adoption of these videos in streaming encounters challenges related to bandwidth and latency, particularly in mobility conditions such as with unmanned aerial vehicles (UAVs). Adaptive resolution and compression aim to preserve quality while maintaining low latency under these constraints, yet downscaling and encoding can still degrade quality and introduce artifacts. Machine learning (ML)-based super-resolution (SR) and quality enhancement techniques offer a promising solution by enhancing detail recovery and reducing compression artifacts. However, current publicly available 360-degree video SR datasets lack compression artifacts, which limit research in this field. To bridge this gap, this paper introduces omnidirectional video streaming dataset (ODVista), which comprises 200 high-resolution and high quality videos downscaled and encoded at four bitrate ranges using the high-efficiency video coding (HEVC)/H.265 standard. Evaluations show that the dataset not only features a wide variety of scenes but also spans different levels of content complexity, which is crucial for robust solutions that perform well in real-world scenarios and generalize across diverse visual environments. Additionally, we evaluate the performance, considering both quality enhancement and runtime, of two handcrafted and two ML-based SR models on the validation and testing sets of ODVista."
https://arxiv.org/abs/2403.00603,2024-03-01,Modeling of obstacle avoidance by a dense crowd as a Mean-Field Game,"['Matteo Butano', 'Thibault Bonnemain', 'CÃ©cile Appert-Rolland', 'Alexandre Nicolas', 'Denis Ullmo']","In this paper we use a minimal model based on Mean-Field Games (a mathematical framework apt to describe situations where a large number of agents compete strategically) to simulate the scenario where a static dense human crowd is crossed by a cylindrical intruder. After a brief explanation of the mathematics behind it, we compare our model directly against the empirical data collected during a controlled experiment replicating the aforementioned situation. We then summarize the features that make the model adhere so well to the experiment and clarify the anticipation time in this framework."
https://arxiv.org/abs/2403.00602,2024-03-01,Equilibrium Model with Anisotropy for Model-Based Reconstruction in Magnetic Particle Imaging,"['Marco Maass', 'Tobias Kluth', 'Christine Droigk', 'Hannes Albers', 'Konrad Scheffler', 'Alfred Mertins', 'Tobias Knopp']","Magnetic particle imaging is a tracer-based tomographic imaging technique that allows the concentration of magnetic nanoparticles to be determined with high spatio-temporal resolution. To reconstruct an image of the tracer concentration, the magnetization dynamics of the particles must be accurately modeled. A popular ensemble model is based on solving the Fokker-Plank equation, taking into account either Brownian or NÃ©el dynamics. The disadvantage of this model is that it is computationally expensive due to an underlying stiff differential equation. A simplified model is the equilibrium model, which can be evaluated directly but in most relevant cases it suffers from a non-negligible modeling error. In the present work, we investigate an extended version of the equilibrium model that can account for particle anisotropy. We show that this model can be expressed as a series of Bessel functions, which can be truncated based on a predefined accuracy, leading to very short computation times, which are about three orders of magnitude lower than equivalent Fokker-Planck computation times. We investigate the accuracy of the model for 2D Lissajous MPI sequences and show that the difference between the Fokker-Planck and the equilibrium model with anisotropy is sufficiently small so that the latter model can be used for image reconstruction on experimental data with only marginal loss of image quality, even compared to a system matrix-based reconstruction."
https://arxiv.org/abs/2403.00601,2024-03-01,Large spin shuttling oscillations enabling high-fidelity single qubit gates,"['Akshay Menon Pazhedath', 'Alessandro David', 'Max OberlÃ¤nder', 'Matthias M. MÃ¼ller', 'Tommaso Calarco', 'Hendrik Bluhm', 'Felix Motzoi']","Semiconductor quantum dots have shown impressive breakthroughs in the last years, with single and two qubit gate fidelities matching other leading platforms and scalability still remaining a relative strength. However, due to qubit wiring considerations, mobile electron architectures have been proposed to facilitate upward scaling. In this work, we examine and demonstrate the possibility of significantly outperforming static EDSR-type single-qubit pulsing by taking advantage of the larger spatial mobility to achieve larger Rabi frequencies and reduce the effect of charge noise. Our theoretical results indicate that fidelities are ultimately bottlenecked by spin-valley physics, which can be suppressed through the use of quantum optimal control, and we demonstrate that, across different potential regimes and competing physical models, shuttling based single-qubit gates retain significant advantage over existing alternatives."
https://arxiv.org/abs/2403.00600,2024-03-01,Random Interval Distillation for Detecting Multiple Changes in General Dependent Data,"['Xinyuan Fan', 'Weichi Wu']","We propose a new and generic approach for detecting multiple change-points in general dependent data, termed random interval distillation (RID). By collecting random intervals with sufficient strength of signals and reassembling them into a sequence of informative short intervals, our new approach captures the shifts in signal characteristics across diverse dependent data forms including locally stationary high-dimensional time series and dynamic networks with Markov formation. We further propose a range of secondary refinements tailored to various data types to enhance the localization precision. Notably, for univariate time series and low-rank autoregressive networks, our methods achieve the minimax optimality as their independent counterparts. For practical applications, we introduce a clustering-based and data-driven procedure to determine the optimal threshold for signal strength, which is adaptable to a wide array of dependent data scenarios utilizing the connection between RID and clustering. Additionally, our method has been extended to identify kinks and changes in signals characterized by piecewise polynomial trends. We examine the effectiveness and usefulness of our methodology via extensive simulation studies and a real data example, implementing it in the R-package rid."
https://arxiv.org/abs/2403.00599,2024-03-01,A hands-on introduction to Physics-Informed Neural Networks for solving partial differential equations with benchmark tests taken from astrophysics and plasma physics,['Hubert Baty'],"I provide an introduction to the application of deep learning and neural networks for solving partial differential equations (PDEs). The approach, known as physics-informed neural networks (PINNs), involves minimizing the residual of the equation evaluated at various points within the domain. Boundary conditions are incorporated either by introducing soft constraints with corresponding boundary data values in the minimization process or by strictly enforcing the solution with hard constraints. PINNs are tested on diverse PDEs extracted from two-dimensional physical/astrophysical problems. Specifically, we explore Grad-Shafranov-like equations that capture magnetohydrodynamic equilibria in magnetically dominated plasmas. Lane-Emden equations that model internal structure of stars in sef-gravitating hydrostatic equilibrium are also considered. The flexibility of the method to handle various boundary conditions is illustrated through various examples, as well as its ease in solving parametric and inverse problems. The corresponding Python codes based on PyTorch/TensorFlow libraries are made available."
https://arxiv.org/abs/2403.00598,2024-03-01,Popularity and Perfectness in One-sided Matching Markets with Capacities,['Gergely CsÃ¡ji'],"We consider many-to-one matching problems, where one side corresponds to applicants who have preferences and the other side to houses who do not have preferences. We consider two different types of this market: one, where the applicants have capacities, and one where the houses do. First, we answer an open question by Manlove and Sng (2006) (partly solved Paluch (2014) for preferences with ties), that is, we show that deciding if a popular matching exists in the house allocation problem, where agents have capacities is NP-hard for previously studied versions of popularity. Then, we consider the other version, where the houses have capacities. We study how to optimally increase the capacities of the houses to obtain a matching satisfying multiple optimality criteria, like popularity, Pareto-optimality and perfectness. We consider two common optimality criteria, one aiming to minimize the sum of capacity increases of all houses and the other aiming to minimize the maximum capacity increase of any school. We obtain a complete picture in terms of computational complexity and some algorithms."
https://arxiv.org/abs/2403.00597,2024-03-01,Chiral Spin Liquid on a Shastry-Sutherland Heisenberg Antiferromagnet,"['Jian-Wei Yang', 'Wei-Wei Luo', 'W. Zhu', 'L. Wang', 'Bo Yang', 'Pinaki Sengupta']","We demonstrate the existence of a topological chiral spin liquid in the frustrated Shastry-Sutherland Heisenberg model with an additional spin chirality interaction, using numerically unbiased exact diagonalization and density matrix renormalization group methods. We establish a quantum phase diagram where conventional phases, including dimer singlet, plaquette singlet, N{\' e}el and collinear phase, can be clearly identified by suitable local order parameters. Among them a $SU(2)_1$ chiral spin liquid emerges in the highly frustrated region, which is unambiguously identified by two topologically degenerate ground states, modular matrix, and characteristic level counting in entanglement spectrum, featuring the same topological order of $Î½=1/2$ bosonic Laughlin state. The phase boundaries among the different orders are determined by the energy level crossing analysis and wave function fidelity susceptibility."
https://arxiv.org/abs/2403.00596,2024-03-01,Quantum spin representation for the Navier-Stokes equation,"['Zhaoyuan Meng', 'Yue Yang']","We develop a quantum representation for Newtonian viscous fluid flows by establishing a mapping between the Navier-Stokes equation (NSE) and the SchrÃ¶dinger-Pauli equation (SPE). The proposed nonlinear SPE incorporates the two-component wave function and the imaginary diffusion. Consequently, classical fluid flow can be interpreted as a non-Hermitian quantum spin system. Using the SPE-based numerical simulation of viscous flows, we demonstrate the quantum/wave-like behavior in flow dynamics. Furthermore, the SPE equivalent to the NSE can facilitate the quantum simulation of fluid dynamics."
https://arxiv.org/abs/2403.00595,2024-03-01,Connected Domination in Plane Triangulations,"['Felicity Bryant', 'Elena Pavelescu']","A set of vertices of a graph $G$ such that each vertex of $G$ is either in the set or is adjacent to a vertex in the set is called a dominating set of $G$. If additionally, the set of vertices induces a connected subgraph of $G$ then the set is a connected dominating set of $G$. The domination number $Î³(G)$ of $G$ is the smallest number of vertices in a dominating set of $G$, and the connected domination number $Î³_c(G)$ of $G$ is the smallest number of vertices in a connected dominating set of $G$. We find the connected domination numbers for all triangulations of up to thirteen vertices. For $n\ge 15$, $n\equiv 0$ (mod 3), we find graphs of order $n$ and $Î³_c=\frac{n}{3}$. We also show that the difference $Î³_c(G)-Î³(G)$ can be arbitrarily large."
https://arxiv.org/abs/2403.00594,2024-03-01,Discrete minimizers of the interaction energy in collective behavior: a brief numerical and analytic review,"['JosÃ© A. CaÃ±izo', 'Alejandro Ramos-Lora']","We consider minimizers of the N-particle interaction potential energy and briefly review numerical methods used to calculate them. We consider simple pair potentials which are attractive at short distances and repulsive at long distances, focusing on examples which are sums of two powers. The range of powers we look at includes the well-known case of the Lennard-Jones potential, but we are also interested in less singular potentials which are relevant in collective behavior models. We report on results using the software GMIN developed by Wales and collaborators for problems in chemistry. For all cases, this algorithm gives good candidates for the minimizers for relatively low values of the particle number N. This is well-known for potentials similar to Lennard-Jones, but not for the range which is of interest in collective behavior. Standard minimization procedures have been used in the literature in this range, but they are likely to yield stationary states which are not minimizers. We illustrate numerically some properties of the minimizers in 2D, such as lattice structure, Wulff shapes, and the continuous large-N limit for locally integrable (that is, less singular) potentials."
https://arxiv.org/abs/2403.00593,2024-03-01,Neutrino phenomenology in the modular $S_3$ seesaw model,"['Mitesh Kumar Behera', 'Pawin Ittisamai', 'Chakrit Pongkitivanichkul', 'Patipan Uttayarat']","We have studied neutrino phenomenology in the supersymmetric type-I seesaw model endowed with the $Î_2 \simeq S_3$ modular symmetry. We have identified different realizations of the $S_3$ modular symmetry, referred to as models A, B, C, and D. The 4 models are compatible with neutrino mass being inverted ordering (IO). Moreover, models A, B, and D can also accommodate normal ordering (NO) neutrino masses. We identify parameter space for each model compatible with neutrino oscillation at the 2-$Ï$ level. We then proceed to study the neutrino phenomenology of each model. We find that the lightest neutrino mass can be as light as 0.64 meV in the case of NO in model A and 50 meV in the case of IO in model D. The smallest effective electron neutrino mass attainable in our analysis is 8.8 meV in the case of NO (model A), and 50 meV for IO (model D). Finally, we note that the effective Majorana mass can be as small as 0.33 meV in the case of NO (model A) and 22 meV for IO (model D)."
https://arxiv.org/abs/2403.00592,2024-03-01,Rethinking Few-shot 3D Point Cloud Semantic Segmentation,"['Zhaochong An', 'Guolei Sun', 'Yun Liu', 'Fayao Liu', 'Zongwei Wu', 'Dan Wang', 'Luc Van Gool', 'Serge Belongie']","This paper revisits few-shot 3D point cloud semantic segmentation (FS-PCS), with a focus on two significant issues in the state-of-the-art: foreground leakage and sparse point distribution. The former arises from non-uniform point sampling, allowing models to distinguish the density disparities between foreground and background for easier segmentation. The latter results from sampling only 2,048 points, limiting semantic information and deviating from the real-world practice. To address these issues, we introduce a standardized FS-PCS setting, upon which a new benchmark is built. Moreover, we propose a novel FS-PCS model. While previous methods are based on feature optimization by mainly refining support features to enhance prototypes, our method is based on correlation optimization, referred to as Correlation Optimization Segmentation (COSeg). Specifically, we compute Class-specific Multi-prototypical Correlation (CMC) for each query point, representing its correlations to category prototypes. Then, we propose the Hyper Correlation Augmentation (HCA) module to enhance CMC. Furthermore, tackling the inherent property of few-shot training to incur base susceptibility for models, we propose to learn non-parametric prototypes for the base classes during training. The learned base prototypes are used to calibrate correlations for the background class through a Base Prototypes Calibration (BPC) module. Experiments on popular datasets demonstrate the superiority of COSeg over existing methods. The code is available at: https://github.com/ZhaochongAn/COSeg"
https://arxiv.org/abs/2403.00591,2024-03-01,Learning Causal Features for Incremental Object Detection,"['Zhenwei He', 'Lei Zhang']","Object detection limits its recognizable categories during the training phase, in which it can not cover all objects of interest for users. To satisfy the practical necessity, the incremental learning ability of the detector becomes a critical factor for real-world applications. Unfortunately, neural networks unavoidably meet catastrophic forgetting problem when it is implemented on a new task. To this end, many incremental object detection models preserve the knowledge of previous tasks by replaying samples or distillation from previous models. However, they ignore an important factor that the performance of the model mostly depends on its feature. These models try to rouse the memory of the neural network with previous samples but not to prevent forgetting. To this end, in this paper, we propose an incremental causal object detection (ICOD) model by learning causal features, which can adapt to more tasks. Traditional object detection models, unavoidably depend on the data-bias or data-specific features to get the detection results, which can not adapt to the new task. When the model meets the requirements of incremental learning, the data-bias information is not beneficial to the new task, and the incremental learning may eliminate these features and lead to forgetting. To this end, our ICOD is introduced to learn the causal features, rather than the data-bias features when training the detector. Thus, when the model is implemented to a new task, the causal features of the old task can aid the incremental learning process to alleviate the catastrophic forgetting problem. We conduct our model on several experiments, which shows a causal feature without data-bias can make the model adapt to new tasks better. \keywords{Object detection, incremental learning, causal feature."
https://arxiv.org/abs/2403.00590,2024-03-01,Hercules: Heterogeneous Requirements Congestion Control Protocol,"['Neta Rozen-Schiff', 'Itzcak Pechtalt', 'Amit Navon', 'Leon Bruckman']","Today's networks are struggling to scale and satisfy the high number and high variety of co-existing network requirements. While existing congestion control (CC) protocols are designed to handle strict classification of network flows into one or few priorities, a more granular and dynamic congestion control is needed."
https://arxiv.org/abs/2403.00589,2024-03-01,Resonant wavelengths of whispering gallery modes with a variable refractive index,"['L. VelÃ¡zquez-Ibarra', 'J. Barranco']","In this work we compute the resonant wavelength of whispering gallery modes for bulk-fused silica microspheres including chromatic dispersion. This is done following two methods: by solving the exact characteristic equation and, on the other hand, by solving the nonlinear equations that result for a variable refractive index in the asymptotic approximations. Similar results with both methods are obtained with differences below $1\%$ . Nevertheless, important differences are found with respect to the resonant wavelengths computed with a constant index and with a variable index. We compute the free spectral range and the quality factor, and make a comparison between the variable index and the constant index cases. The differences are of significant relevance for the free spectral range, while for the quality factor, the constant case is insensitive to the chromatic dispersion. Our work could be useful as a pathway for designing microspheres for different applications."
https://arxiv.org/abs/2403.00588,2024-03-01,The Honest Embedding Dimension of a Numerical Semigroup,['Richard Montgomery'],"Attached to a singular analytic curve germ in $d$-space is a numerical semigroup: a subset $S$ of the non-negative integers which is closed under addition and whose complement isfinite. Conversely, associated to any numerical semigroup $S$ is a canonical mononial curve in $e$-space where $e$ is the number of minimal generators of the semigroup. It may happen that $d < e = e(S)$ where $S$ is the semigroup of the curve in $d$-space. Define the minimal (or `honest') embedding of a numerical semigroup to be the smallest $d$ such that $S$ is realized by a curve in $d$-space. Problem: characterize the numerical semigroups having minimal embedding dimension $d$. The answer is known for the case $d=2$ of planar curves and reviewed in an Appendix to this paper. The case $d =3$ of the problem is open. Our main result is a characterization of the multiplicity $4$ numerical semigroups whose minimal embedding dimension is $3$. See figure 1. The motivation for this work came from thinking about Legendrian curve singularities."
https://arxiv.org/abs/2403.00587,2024-03-01,Improving Explicit Spatial Relationships in Text-to-Image Generation through an Automatically Derived Dataset,"['Ander Salaberria', 'Gorka Azkune', 'Oier Lopez de Lacalle', 'Aitor Soroa', 'Eneko Agirre', 'Frank Keller']","Existing work has observed that current text-to-image systems do not accurately reflect explicit spatial relations between objects such as 'left of' or 'below'. We hypothesize that this is because explicit spatial relations rarely appear in the image captions used to train these models. We propose an automatic method that, given existing images, generates synthetic captions that contain 14 explicit spatial relations. We introduce the Spatial Relation for Generation (SR4G) dataset, which contains 9.9 millions image-caption pairs for training, and more than 60 thousand captions for evaluation. In order to test generalization we also provide an 'unseen' split, where the set of objects in the train and test captions are disjoint. SR4G is the first dataset that can be used to spatially fine-tune text-to-image systems. We show that fine-tuning two different Stable Diffusion models (denoted as SD$_{SR4G}$) yields up to 9 points improvements in the VISOR metric. The improvement holds in the 'unseen' split, showing that SD$_{SR4G}$ is able to generalize to unseen objects. SD$_{SR4G}$ improves the state-of-the-art with fewer parameters, and avoids complex architectures. Our analysis shows that improvement is consistent for all relations. The dataset and the code will be publicly available."
https://arxiv.org/abs/2403.00586,2024-03-01,Open Assistant Toolkit -- version 2,"['Sophie Fischer', 'Federico Rossetto', 'Carlos Gemmell', 'Andrew Ramsay', 'Iain Mackie', 'Philip Zubel', 'Niklas Tecklenburg', 'Jeffrey Dalton']","We present the second version of the Open Assistant Toolkit (OAT-v2), an open-source task-oriented conversational system for composing generative neural models. OAT-v2 is a scalable and flexible assistant platform supporting multiple domains and modalities of user interaction. It splits processing a user utterance into modular system components, including submodules such as action code generation, multimodal content retrieval, and knowledge-augmented response generation. Developed over multiple years of the Alexa TaskBot challenge, OAT-v2 is a proven system that enables scalable and robust experimentation in experimental and real-world deployment. OAT-v2 provides open models and software for research and commercial applications to enable the future of multimodal virtual assistants across diverse applications and types of rich interaction."
https://arxiv.org/abs/2403.00585,2024-03-01,Decentralized Uncoded Storage Elastic Computing with Heterogeneous Computation Speeds,"['Wenbo Huang', 'Xudong You', 'Kai Wan', 'Robert Caiming Qiu', 'Mingyue Ji']","Elasticity plays an important role in modern cloud computing systems. Elastic computing allows virtual machines (i.e., computing nodes) to be preempted when high-priority jobs arise, and also allows new virtual machines to participate in the computation. In 2018, Yang et al. introduced Coded Storage Elastic Computing (CSEC) to address the elasticity using coding technology, with lower storage and computation load requirements. However, CSEC is limited to certain types of computations (e.g., linear) due to the coded data storage based on linear coding. Then Centralized Uncoded Storage Elastic Computing (CUSEC) with heterogeneous computation speeds was proposed, which directly copies parts of data into the virtual machines. In all existing works in elastic computing, the storage assignment is centralized, meaning that the number and identity of all virtual machines possible used in the whole computation process are known during the storage assignment. In this paper, we consider Decentralized Uncoded Storage Elastic Computing (DUSEC) with heterogeneous computation speeds, where any available virtual machine can join the computation which is not predicted and thus coordination among different virtual machines' storage assignments is not allowed. Under a decentralized storage assignment originally proposed in coded caching by Maddah-Ali and Niesen, we propose a computing scheme with closed-form optimal computation time. We also run experiments over MNIST dataset with Softmax regression model through the Tencent cloud platform, and the experiment results demonstrate that the proposed DUSEC system approaches the state-of-art best storage assignment in the CUSEC system in computation time."
https://arxiv.org/abs/2403.00584,2024-03-01,Generalized User Representations for Transfer Learning,"['Ghazal Fazelnia', 'Sanket Gupta', 'Claire Keum', 'Mark Koh', 'Ian Anderson', 'Mounia Lalmas']","We present a novel framework for user representation in large-scale recommender systems, aiming at effectively representing diverse user taste in a generalized manner. Our approach employs a two-stage methodology combining representation learning and transfer learning. The representation learning model uses an autoencoder that compresses various user features into a representation space. In the second stage, downstream task-specific models leverage user representations via transfer learning instead of curating user features individually. We further augment this methodology on the representation's input features to increase flexibility and enable reaction to user events, including new user experiences, in Near-Real Time. Additionally, we propose a novel solution to manage deployment of this framework in production models, allowing downstream models to work independently. We validate the performance of our framework through rigorous offline and online experiments within a large-scale system, showcasing its remarkable efficacy across multiple evaluation tasks. Finally, we show how the proposed framework can significantly reduce infrastructure costs compared to alternative approaches."
https://arxiv.org/abs/2403.00583,2024-03-01,Determining hypercentral Hall subgroups in finite groups,['VÃ­ctor Sotomayor'],"Let $G$ be a finite group, and let $Ï$ be a set of primes. The aim of this paper is to obtain some results concerning how much information about the $Ï$-structure of $G$ can be gathered from the knowledge of the lengths of conjugacy classes of its $Ï$-elements and of their multiplicities. Among other results, we prove that this multiset of class lengths determine whether $G$ has a hypercentral Hall $Ï$-subgroup."
https://arxiv.org/abs/2403.00582,2024-03-01,To Trust or Distrust Trust Measures: Validating Questionnaires for Trust in AI,"['Nicolas Scharowski', 'Sebastian A. C. Perrig', 'Lena Fanya Aeschbach', 'Nick von Felten', 'Klaus Opwis', 'Philipp Wintersberger', 'Florian BrÃ¼hlmann']","Despite the importance of trust in human-AI interactions, researchers must adopt questionnaires from other disciplines that lack validation in the AI context. Motivated by the need for reliable and valid measures, we investigated the psychometric quality of two trust questionnaires, the Trust between People and Automation scale (TPA) by Jian et al. (2000) and the Trust Scale for the AI Context (TAI) by Hoffman et al. (2023). In a pre-registered online experiment (N = 1485), participants observed interactions with trustworthy and untrustworthy AI (autonomous vehicle and chatbot). Results support the psychometric quality of the TAI while revealing opportunities to improve the TPA, which we outline in our recommendations for using the two questionnaires. Furthermore, our findings provide additional empirical evidence of trust and distrust as two distinct constructs that may coexist independently. Building on our findings, we highlight the opportunities and added value of measuring both trust and distrust in human-AI research and advocate for further work on both constructs."
https://arxiv.org/abs/2403.00581,2024-03-01,Enhancement of bubble transport in porous electrodes and catalysts,"['Thomas Scheel', 'Paolo Malgaretti', 'Jens Harting']","We investigate the formation and transport of gas bubbles across a model porous catalyst/electrode using lattice Boltzmann simulations. This approach enables us to systematically examine the influence of a wide range of morphologies, flow velocities, and reaction rates on the efficiency of gas production. By exploring these parameters, we identify critical parameter combinations that significantly contribute to an enhanced yield of gas output. Our simulations reveal the existence of an optimal pore geometry for which the product output is maximized. Intriguingly, we also observe that lower flow velocities improve gas production by leveraging on coalescence-induced bubble detachment from the catalyst."
https://arxiv.org/abs/2403.00580,2024-03-01,"X-Shaped Radio Galaxies: Probing Jet Evolution, Ambient Medium Dynamics, and Their Intricate Interconnection","['Gourab Giri', 'Christian Fendt', 'Kshitij Thorat', 'Gianluigi Bodo', 'Paola Rossi']","This review explores the field of X-shaped radio galaxies (XRGs), a distinctive subset of winged radio sources that are identified by two pairs of jetted lobes which aligned by a significant angle, resulting in an inversion-symmetric structure. These lobes, encompassing active (primary) and passive (secondary) phases, exhibit a diverse range of properties across the multiple frequency bands, posing challenges in discerning their formation mechanism. The proposed mechanisms can broadly be categorized into those related either to a triaxial ambient medium, into which the jet propagates, or to a complex, central AGN mechanism, where the jet is generated. The observed characteristics of XRGs as discovered in the most substantial sample to date, challenge the idea that there is universal process at work that produces the individual sources of XRGs. Instead, the observational and numerical results rather imply the absence of an universal model and infer that distinct mechanisms may be at play for the specific sources. By scrutinizing salient and confounding properties, this review intends to propose the potential direction for future research to constrain and constrict individual models applicable to XRGs."
https://arxiv.org/abs/2403.00579,2024-03-01,NeuPIMs: A NPU-PIM Heterogeneous Acceleration for Batched Inference of Large Language Model,"['Guseul Heo', 'Sangyeop Lee', 'Jaehong Cho', 'Hyunmin Choi', 'Sanghyeon Lee', 'Hyungkyu Ham', 'Gwangsun Kim', 'Divya Mahajan', 'Jongse Park']","Modern transformer-based Large Language Models (LLMs) are constructed with a series of decoder blocks. Each block comprises three key components: (1) QKV generation, (2) multi-head attention, and (3) feed-forward networks. In batched processing, QKV generation and feed-forward networks involve compute-intensive matrix-matrix multiplications (GEMM), while multi-head attention requires bandwidth-heavy matrix-vector multiplications (GEMV). Machine learning accelerators like TPUs or NPUs are proficient in handling GEMM but are less efficient for GEMV computations. Conversely, Processing-in-Memory (PIM) technology is tailored for efficient GEMV computation, while it lacks the computational power to effectively handle GEMM. Inspired by this insight, we propose NeuPIMs, a heterogeneous accelerator-based system that jointly exploits a conventional GEMM-focused NPU and GEMV-optimized PIM devices. The main challenge in efficiently integrating NPU and PIM lies in enabling concurrent operations on both platforms, each addressing a specific kernel type. First, existing PIMs typically operate in a ""blocked"" mode, allowing only either NPU or PIM to be active at any given time. Second, the inherent dependencies between GEMM and GEMV in LLMs restrict their parallel processing. To tackle these challenges, NeuPIMs is equipped with dual row buffers in each bank, facilitating the simultaneous management of memory read/write operations and PIM commands. Further, NeuPIMs employs a runtime sub-batch interleaving technique to maximize concurrent execution, leveraging batch parallelism to allow two independent sub-batches to be pipelined within a single NeuPIMs node. Our evaluation demonstrates that compared to an NPU-only approach and a naÃ¯ve NPU-PIM integrated system, NeuPIMs achieves 2.3$\times$ and 1.6$\times$ throughput improvement, respectively."
https://arxiv.org/abs/2403.00578,2024-03-01,SINDy vs Hard Nonlinearities and Hidden Dynamics: a Benchmarking Study,"['Aurelio Raffa Ugolini', 'Valentina Breschi', 'Andrea Manzoni', 'Mara Tanelli']","In this work we analyze the effectiveness of the Sparse Identification of Nonlinear Dynamics (SINDy) technique on three benchmark datasets for nonlinear identification, to provide a better understanding of its suitability when tackling real dynamical systems. While SINDy can be an appealing strategy for pursuing physics-based learning, our analysis highlights difficulties in dealing with unobserved states and non-smooth dynamics. Due to the ubiquity of these features in real systems in general, and control applications in particular, we complement our analysis with hands-on approaches to tackle these issues in order to exploit SINDy also in these challenging contexts."
https://arxiv.org/abs/2403.00577,2024-03-01,Single vibronic level fluorescence spectra from Hagedorn wavepacket dynamics,"['Zhan Tong Zhang', 'JiÅÃ­ J. L. VanÃ­Äek']","In single vibronic level (SVL) fluorescence experiments, the electronically excited initial state is also excited in one or several vibrational modes. Whereas the time-independent approach of computing all contributing Franck-Condon factors becomes impractical in large systems, a time-dependent formalism has not been applied to simulate emission from arbitrary initial vibrational levels. Here, we apply Hagedorn functions, which are products of a Gaussian and carefully generated polynomials, to represent SVL initial states. Under an at most quadratic potential, the Hagedorn functions are exact solutions to the time-dependent SchrÃ¶dinger equation and can be propagated using the same equations of motion as a simple Gaussian wavepacket. Having developed an efficient recursive algorithm to compute the overlaps between two Hagedorn wavepackets, we can now evaluate emission spectra from arbitrary vibronic levels using a single trajectory. Here, we use two-dimensional global harmonic models to validate the method by comparing it with quantum split-operator calculations and to demonstrate the effects of displacement, distortion (squeezing), and Duschinsky rotation on SVL spectra. Additionally, we show the practicality of the Hagedorn approach in a high-dimensional system on a displaced, distorted, and Duschinsky-rotated harmonic model with 100 degrees of freedom."
https://arxiv.org/abs/2403.00576,2024-03-01,Quantum Time-Frequency Analysis and Pseudodifferential Operators,"['Franz Luef', 'Henry McNulty']","We introduce Quantum Time-Frequency Analysis, which expands the approach of Quantum Harmonic Analysis to include modulations of operators in addition to translations. This is done by a projective representation of double-phase space, and we consider the associated matrix coefficients and integrated representation. This leads to the polarised Cohen's class, which is an isomorphism from Hilbert-Schmidt operators to a reproducing kernel Hilbert space, and has orthogonality relations similar to many objects in classical time-frequency analysis. By considering a class of windows for the polarised Cohen's class that is smaller than the class of Hilbert-Schmidt operators, then we find spaces of modulation spaces of operators, and we consider the properties of these spaces, including discretisation results and mapping properties between function modulation spaces. We also compare modulation spaces of operators to known symbol classes for pseudodifferential operators. In many cases, using rank-one examples of operators, we recover familiar objects and results from classical time-frequency analysis and the theory of pseudodifferential operators."
https://arxiv.org/abs/2403.00575,2024-03-01,Equivariant Spectral Flow for Families of Dirac-type Operators,"['Peter Hochs', 'Aquerman Yanes']","In the setting of a proper, cocompact action by a locally compact, unimodular group $G$ on a Riemannian manifold, we construct equivariant spectral flow of paths of Dirac-type operators. This takes values in the $K$-theory of the group $C^*$-algebra of $G$. In the case where $G$ is the fundamental group of a compact manifold, the summation map maps equivariant spectral flow on the universal cover to classical spectral flow on the base manifold. We obtain ""index equals spectral flow"" results. In the setting of a smooth path of $G$-invariant Riemannian metrics on a $G$-spin manifold, we show that the equivariant spectral flow of the corresponding path of spin Dirac operators relates delocalised $Î·$-invariants and $Ï$-invariants for different positive scalar curvature metrics to each other."
https://arxiv.org/abs/2403.00574,2024-03-01,Beyond Single-Model Views for Deep Learning: Optimization versus Generalizability of Stochastic Optimization Algorithms,"['Toki Tahmid Inan', 'Mingrui Liu', 'Amarda Shehu']","Despite an extensive body of literature on deep learning optimization, our current understanding of what makes an optimization algorithm effective is fragmented. In particular, we do not understand well whether enhanced optimization translates to improved generalizability. Current research overlooks the inherent stochastic nature of stochastic gradient descent (SGD) and its variants, resulting in a lack of comprehensive benchmarking and insight into their statistical performance. This paper aims to address this gap by adopting a novel approach. Rather than solely evaluating the endpoint of individual optimization trajectories, we draw from an ensemble of trajectories to estimate the stationary distribution of stochastic optimizers. Our investigation encompasses a wide array of techniques, including SGD and its variants, flat-minima optimizers, and new algorithms we propose under the Basin Hopping framework. Through our evaluation, which encompasses synthetic functions with known minima and real-world problems in computer vision and natural language processing, we emphasize fair benchmarking under a statistical framework, comparing stationary distributions and establishing statistical significance. Our study uncovers several key findings regarding the relationship between training loss and hold-out accuracy, as well as the comparable performance of SGD, noise-enabled variants, and novel optimizers utilizing the BH framework. Notably, these algorithms demonstrate performance on par with flat-minima optimizers like SAM, albeit with half the gradient evaluations. We anticipate that our work will catalyze further exploration in deep learning optimization, encouraging a shift away from single-model approaches towards methodologies that acknowledge and leverage the stochastic nature of optimizers."
https://arxiv.org/abs/2403.00573,2024-03-01,IDTrust: Deep Identity Document Quality Detection with Bandpass Filtering,"['Musab Al-Ghadi', 'Joris Voerman', 'Souhail Bakkali', 'MickaÃ«l Coustaty', 'Nicolas Sidere', 'Xavier St-Georges']","The increasing use of digital technologies and mobile-based registration procedures highlights the vital role of personal identity documents (IDs) in verifying users and safeguarding sensitive information. However, the rise in counterfeit ID production poses a significant challenge, necessitating the development of reliable and efficient automated verification methods. This paper introduces IDTrust, a deep-learning framework for assessing the quality of IDs. IDTrust is a system that enhances the quality of identification documents by using a deep learning-based approach. This method eliminates the need for relying on original document patterns for quality checks and pre-processing steps for alignment. As a result, it offers significant improvements in terms of dataset applicability. By utilizing a bandpass filtering-based method, the system aims to effectively detect and differentiate ID quality. Comprehensive experiments on the MIDV-2020 and L3i-ID datasets identify optimal parameters, significantly improving discrimination performance and effectively distinguishing between original and scanned ID documents."
https://arxiv.org/abs/2403.00572,2024-03-01,Broadband spectral and temporal study of Ton 599 during the brightest January 2023 flare,"['Aaqib Manzoor', 'Zahir Shah', 'Sunder Sahayanathan', 'Naseer Iqbal', 'Athar A. Dar']","In this work, we provide a detailed analysis of the broadband temporal and spectral properties of the blazar Ton\,599 by using the observations from \emph{Fermi}-LAT and \emph{Swift}-XRT/UVOT telescopes, during its brightest $Î³$-ray flaring. The one-day bin $Î³$-ray light curve exhibits multiple substructures with asymmetric and symmetric profiles. Notably, the $Î³$-ray light curve shows a maximum flux of $\rm 3.63 \times 10^{-6}\, ph \,cm^{-2}\,s^{-1}$ on MJD\,59954.50, which is the highest flux ever observed from this source. The correlation between the $Î³$-ray flux and $Î³$-ray spectral indices suggests a moderate harder when the brighter trend. Taking $Î³$-ray light curve as the reference, a strong correlation is observed with X-ray, optical, and UV energies. Additionally, the $Î³$-rays and optical/UV emissions exhibit higher variability compared to X-rays. To understand the parameter variation during the active state of the source, we conducted a statistical broadband spectral modelling of the source in 10 flux intervals of equal duration. A one-zone leptonic model involving synchrotron, synchrotron-self-Compton, and external-Compton processes successfully reproduces the broadband SED in each of these flux intervals. We observed that the flux variation during the active state is mainly associated with the variation in the magnetic field and the particle spectral indices."
https://arxiv.org/abs/2403.00571,2024-03-01,Computational homogenization for aerogel-like polydisperse open-porous materials using neural network--based surrogate models on the microscale,"['Axel Klawonn', 'Martin Lanser', 'Lucas Mager', 'Ameya Rege']","The morphology of nanostructured materials exhibiting a polydisperse porous space, such as aerogels, is very open porous and fine grained. Therefore, a simulation of the deformation of a large aerogel structure resolving the nanostructure would be extremely expensive. Thus, multi-scale or homogenization approaches have to be considered. Here, a computational scale bridging approach based on the FE$^2$ method is suggested, where the macroscopic scale is discretized using finite elements while the microstructure of the open-porous material is resolved as a network of Euler-Bernoulli beams. Here, the beam frame based RVEs (representative volume elements) have pores whose size distribution follows the measured values for a specific material. This is a well-known approach to model aerogel structures. For the computational homogenization, an approach to average the first Piola-Kirchhoff stresses in a beam frame by neglecting rotational moments is suggested. To further overcome the computationally most expensive part in the homogenization method, that is, solving the RVEs and averaging their stress fields, a surrogate model is introduced based on neural networks. The networks input is the localized deformation gradient on the macroscopic scale and its output is the averaged stress for the specific material. It is trained on data generated by the beam frame based approach. The effiency and robustness of both homogenization approaches is shown numerically, the approximation properties of the surrogate model is verified for different macroscopic problems and discretizations. Different (Quasi-)Newton solvers are considered on the macroscopic scale and compared with respect to their convergence properties."
https://arxiv.org/abs/2403.00570,2024-03-01,Rethinking cluster-conditioned diffusion models,"['Nikolas Adaloglou', 'Tim Kaiser', 'Felix Michels', 'Markus Kollmann']","We present a comprehensive experimental study on image-level conditioning for diffusion models using cluster assignments. We elucidate how individual components regarding image clustering impact image synthesis across three datasets. By combining recent advancements from image clustering and diffusion models, we show that, given the optimal cluster granularity with respect to image synthesis (visual groups), cluster-conditioning can achieve state-of-the-art FID (i.e. 1.67, 2.17 on CIFAR10 and CIFAR100 respectively), while attaining a strong training sample efficiency. Finally, we propose a novel method to derive an upper cluster bound that reduces the search space of the visual groups using solely feature-based clustering. Unlike existing approaches, we find no significant connection between clustering and cluster-conditional image generation. The code and cluster assignments will be released."
https://arxiv.org/abs/2403.00569,2024-03-01,Characterization of Wireless Channel Semantics: A New Paradigm,"['Zhengyu Zhang', 'Ruisi He', 'Mi Yang', 'Xuejian Zhang', 'Ziyi Qi', 'Yuan Yuan', 'Bo Ai']","Recently, deep learning enabled semantic communications have been developed to understand transmission content from semantic level, which realize effective and accurate information transfer. Aiming to the vision of sixth generation (6G) networks, wireless devices are expected to have native perception and intelligent capabilities, which associate wireless channel with surrounding environments from physical propagation dimension to semantic information dimension. Inspired by these, we aim to provide a new paradigm on wireless channel from semantic level. A channel semantic model and its characterization framework are proposed in this paper. Specifically, a channel semantic model composes of status semantics, behavior semantics and event semantics. Based on actual channel measurement at 28 GHz, as well as multi-mode data, example results of channel semantic characterization are provided and analyzed, which exhibits reasonable and interpretable semantic information."
https://arxiv.org/abs/2403.00568,2024-03-01,User Localization with HRIS and Backscatter Modulation for Next-Generation Networks,"['Mattia Piana', 'Stefano Tomasin']","Hybrid reflective intelligent surfaces (HRISs) can support localization in sixth-generation (6G) networks thanks to their ability to generate narrow beams and at the same time receive and process locally the impinging signals. In this paper, we propose a novel protocol for user localization in a network with an HRIS. The protocol includes two steps. In the first step, the HRIS operates in full absorption mode and the user equipment (UE) transmits a signal that is locally processed at the HRIS to estimate the angle of arrival (AoA). In the second step, the base station transmits a downlink reference signal to the UE, and the HRIS superimposes a message by a backscatter modulation. The message contains information on the previously estimated AoA. Lastly, the UE, knowing the position of the HRIS, estimates the time of flight (ToF) from the signal of the second step and demodulates the information on the AoA to obtain an estimate of its location. Numerical results confirm the effectiveness of the proposed solution, also in comparison with the CramÃ©r Rao lower bound on the estimated quantities.nd on the estimated quantities."
https://arxiv.org/abs/2403.00567,2024-03-01,Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning,"['Yixiong Zou', 'Yicong Liu', 'Yiman Hu', 'Yuhua Li', 'Ruixuan Li']","Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited training data in the target domain by leveraging prior knowledge transferred from source domains with abundant training samples. CDFSL faces challenges in transferring knowledge across dissimilar domains and fine-tuning models with limited training data. To address these challenges, we initially extend the analysis of loss landscapes from the parameter space to the representation space, which allows us to simultaneously interpret the transferring and fine-tuning difficulties of CDFSL models. We observe that sharp minima in the loss landscapes of the representation space result in representations that are hard to transfer and fine-tune. Moreover, existing flatness-based methods have limited generalization ability due to their short-range flatness. To enhance the transferability and facilitate fine-tuning, we introduce a simple yet effective approach to achieve long-range flattening of the minima in the loss landscape. This approach considers representations that are differently normalized as minima in the loss landscape and flattens the high-loss region in the middle by randomly sampling interpolated representations. We implement this method as a new normalization layer that replaces the original one in both CNNs and ViTs. This layer is simple and lightweight, introducing only a minimal number of additional parameters. Experimental results on 8 datasets demonstrate that our approach outperforms state-of-the-art methods in terms of average accuracy. Moreover, our method achieves performance improvements of up to 9\% compared to the current best approaches on individual datasets. Our code will be released."
https://arxiv.org/abs/2403.00566,2024-03-01,Lincoln's Annotated Spatio-Temporal Strawberry Dataset (LAST-Straw),"['Katherine Margaret Frances James', 'Karoline Heiwolt', 'Daniel James Sargent', 'Grzegorz Cielniak']","Automated phenotyping of plants for breeding and plant studies promises to provide quantitative metrics on plant traits at a previously unattainable observation frequency. Developers of tools for performing high-throughput phenotyping are, however, constrained by the availability of relevant datasets on which to perform validation. To this end, we present a spatio-temporal dataset of 3D point clouds of strawberry plants for two varieties, totalling 84 individual point clouds. We focus on the end use of such tools - the extraction of biologically relevant phenotypes - and demonstrate a phenotyping pipeline on the dataset. This comprises of the steps, including; segmentation, skeletonisation and tracking, and we detail how each stage facilitates the extraction of different phenotypes or provision of data insights. We particularly note that assessment is focused on the validation of phenotypes, extracted from the representations acquired at each step of the pipeline, rather than singularly focusing on assessing the representation itself. Therefore, where possible, we provide \textit{in silico} ground truth baselines for the phenotypes extracted at each step and introduce methodology for the quantitative assessment of skeletonisation and the length trait extracted thereof. This dataset contributes to the corpus of freely available agricultural/horticultural spatio-temporal data for the development of next-generation phenotyping tools, increasing the number of plant varieties available for research in this field and providing a basis for genuine comparison of new phenotyping methodology."
https://arxiv.org/abs/2403.00565,2024-03-01,Predicting UAV Type: An Exploration of Sampling and Data Augmentation for Time Series Classification,"['Tarik Crnovrsanin', 'Calvin Yu', 'Dane Hankamer', 'Cody Dunne']","Unmanned aerial vehicles are becoming common and have many productive uses. However, their increased prevalence raises safety concerns -- how can we protect restricted airspace? Knowing the type of unmanned aerial vehicle can go a long way in determining any potential risks it carries. For instance, fixed-wing craft can carry more weight over longer distances, thus potentially posing a more significant threat. This paper presents a machine learning model for classifying unmanned aerial vehicles as quadrotor, hexarotor, or fixed-wing. Our approach effectively applies a Long-Short Term Memory (LSTM) neural network for the purpose of time series classification. We performed experiments to test the effects of changing the timestamp sampling method and addressing the imbalance in the class distribution. Through these experiments, we identified the top-performing sampling and class imbalance fixing methods. Averaging the macro f-scores across 10 folds of data, we found that the majority quadrotor class was predicted well (98.16%), and, despite an extreme class imbalance, the model could also predicted a majority of fixed-wing flights correctly (73.15%). Hexarotor instances were often misclassified as quadrotors due to the similarity of multirotors in general (42.15%). However, results remained relatively stable across certain methods, which prompted us to analyze and report on their tradeoffs. The supplemental material for this paper, including the code and data for running all the experiments and generating the results tables, is available at https://osf.io/mnsgk/."
https://arxiv.org/abs/2403.00564,2024-03-01,EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data,"['Shengjie Wang', 'Shaohuai Liu', 'Weirui Ye', 'Jiacheng You', 'Yang Gao']","Sample efficiency remains a crucial challenge in applying Reinforcement Learning (RL) to real-world tasks. While recent algorithms have made significant strides in improving sample efficiency, none have achieved consistently superior performance across diverse domains. In this paper, we introduce EfficientZero V2, a general framework designed for sample-efficient RL algorithms. We have expanded the performance of EfficientZero to multiple domains, encompassing both continuous and discrete actions, as well as visual and low-dimensional inputs. With a series of improvements we propose, EfficientZero V2 outperforms the current state-of-the-art (SOTA) by a significant margin in diverse tasks under the limited data setting. EfficientZero V2 exhibits a notable advancement over the prevailing general algorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks across diverse benchmarks, such as Atari 100k, Proprio Control, and Vision Control."
https://arxiv.org/abs/2403.00563,2024-03-01,Indirectly Parameterized Concrete Autoencoders,"['Alfred Nilsson', 'Klas Wijk', 'Sai bharath chandra Gutha', 'Erik Englesson', 'Alexandra Hotti', 'Carlo Saccardi', 'Oskar Kviman', 'Jens Lagergren', 'Ricardo Vinuesa', 'Hossein Azizpour']","Feature selection is a crucial task in settings where data is high-dimensional or acquiring the full set of features is costly. Recent developments in neural network-based embedded feature selection show promising results across a wide range of applications. Concrete Autoencoders (CAEs), considered state-of-the-art in embedded feature selection, may struggle to achieve stable joint optimization, hurting their training time and generalization. In this work, we identify that this instability is correlated with the CAE learning duplicate selections. To remedy this, we propose a simple and effective improvement: Indirectly Parameterized CAEs (IP-CAEs). IP-CAEs learn an embedding and a mapping from it to the Gumbel-Softmax distributions' parameters. Despite being simple to implement, IP-CAE exhibits significant and consistent improvements over CAE in both generalization and training time across several datasets for reconstruction and classification. Unlike CAE, IP-CAE effectively leverages non-linear relationships and does not require retraining the jointly optimized decoder. Furthermore, our approach is, in principle, generalizable to Gumbel-Softmax distributions beyond feature selection."
https://arxiv.org/abs/2403.00562,2024-03-01,"Comment on ""Controlled Bond Expansion for Density Matrix Renormalization Group Ground State Search at Single-Site Costs"" (Extended Version)","['Ian P McCulloch', 'Jesse Osborne']","In a recent Letter [Phys. Rev. Lett. 130, 246402 (2023)], Gleis, Li, and von Delft present an algorithm for expanding the bond dimension of a Matrix Product State wave function, giving accuracy similar to 2-site DMRG, but computationally more efficient, closer to the performance of 1-site DMRG. The Controlled Bond Expansion (CBE) algorithm uses the Hamiltonian projected onto two sites, and then further projected onto the two-site tangent space, to extract a set of $k$ vectors that are used to expand the basis between the two sites. CBE achieves this with a complicated sequence of five singular value decompositions (SVDs), in order to project onto the 2-site tangent space and reduce the bond dimension of the tensor network such that the contraction can be done in time $O(dwD^3)$. In this Comment, we show that (1) the projection onto the 2-site tangent space is unnecessary, and is generally not helpful; (2) the sequence of 5 SVDs can be replaced by a single $QR$ decomposition (optionally with one SVD as well), making use of the randomized SVD (RSVD) with high accuracy and significantly improved efficiency, scaling as $O(dwkD^2)$ i.e., the most expensive operations are only quadratic in the bond dimension $D$ and linear in the number of expansion vectors $k$; (3) several statements about the variational properties of the CBE algorithm are incorrect, and the variational properties are essentially identical to existing algorithms including 2-site DMRG and single-site subspace expansion (3S); (4) a similar RSVD approach can be applied to the 3S algorithm, which leads to many advantages over CBE, especially in systems with long range interactions. We also make some comments on the benchmarking MPS algorithms, and the overall computational efficiency with respect to the accuracy of the calculation."
https://arxiv.org/abs/2403.00561,2024-03-01,Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face Attribute Estimation,"['Huaqing Yuan', 'Yi He', 'Peng Du', 'Lu Song']","Face images contain a wide variety of attribute information. In this paper, we propose a generalized framework for joint estimation of ordinal and nominal attributes based on information sharing. We tackle the correlation problem between heterogeneous attributes using hard parameter sharing of shallow features, and trade-off multiple loss functions by considering homoskedastic uncertainty for each attribute estimation task. This leads to optimal estimation of multiple attributes of the face and reduces the training cost of multitask learning. Experimental results on benchmarks with multiple face attributes show that the proposed approach has superior performance compared to state of the art. Finally, we discuss the bias issues arising from the proposed approach in face attribute estimation and validate its feasibility on edge systems."
https://arxiv.org/abs/2403.00560,2024-03-01,Implementation of tunable frequency-dependent stiffness elements via integrated shunted piezoelectric stacks,"['Bart Van Damme', 'Rico Weber', 'Jascha U Schmied', 'Adriaan Spierings', 'Andrea Bergamini']","Piezoelectric transducers applied on or integrated in structures, combined with appropriate circuits have been extensively investigated as a smart approach to the mitigation of resonant vibrations with high relative amplitudes. Using an approach that is traceable to the use of tuned mass absorbers and dampers, widely used in mechanical and civil engineering, resonantly shunted piezoelectric transducers can be configured to target specific eigenmodes of a structure, if appropriately placed and tuned. By re-framing the function of resonantly shunted piezoelectric transducers as frequency dependent variable stiffness elements, it is of great interest to investigate their capabilities to realize frequency dependent topologies (in the sense of the mechanical connectivity) in the frame of lattice metamaterials, where the load path within a lattice can be interrupted at will for specific frequencies by intercalating null-stiffness components realized with resonantly shunted piezoelectrics. Here, we offer the numerical and experimental verification of this idea, using the example of a potential unit cell of such an adaptive lattice metamaterial. Its realization as additively manufactured component points to the feasibility of such metamaterials in real life."
https://arxiv.org/abs/2403.00559,2024-03-01,A new Wolfenstein-like expansion of lepton flavor mixing towards understanding its fine structure,['Zhi-zhong Xing'],"Taking the tri-bimaximal flavor mixing pattern as a particular basis, we propose a new way to expand the $3\times 3$ unitary Pontecorvo-Maki-Nakagawa-Sakata (PMNS) lepton flavor mixing matrix $U$ in powers of the magnitude of its smallest element $Î¾\equiv \left|U^{}_{e 3}\right| \simeq 0.149$. Such a Wolfenstein-like parametrization of $U$ allows us to easily describe the salient features and fine structures of flavor mixing and CP violation, both in vacuum and in matter."
https://arxiv.org/abs/2403.00558,2024-03-01,Rational Linkages: From Poses to 3D-printed Prototypes,"['Daniel Huczala', 'Johannes Siegele', 'Daren A. Thimm', 'Martin Pfurner', 'Hans-Peter SchrÃ¶cker']","In this paper, a set of tools is introduced that simplifies the synthesis and rapid-prototyping of single-loop rational kinematic chains. It allows the user to perform rational motion interpolation of up to four given poses and yields the design parameters of a linkage that can execute this motion. The package also provides a visualization of the output and performs a self-collision analysis with the possibility to adapt the design parameters. The results can be imported into CAD-systems for fast 3D printing."
https://arxiv.org/abs/2403.00557,2024-03-01,Non-stationarity Characteristics in Dynamic Vehicular ISAC Channels at 28 GHz,"['Zhengyu Zhang', 'Ruisi He', 'Mi Yang', 'Xuejian Zhang', 'Ziyi Qi', 'Hang Mi', 'Guiqi Sun', 'Jingya Yang', 'Bo Ai']","Integrated sensing and communications (ISAC) is a potential technology of 6G, aiming to enable end-to-end information processing ability and native perception capability for future communication systems. As an important part of the ISAC application scenarios, ISAC aided vehicle-to-everything (V2X) can improve the traffic efficiency and safety through intercommunication and synchronous perception. It is necessary to carry out measurement, characterization, and modeling for vehicular ISAC channels as the basic theoretical support for system design. In this paper, dynamic vehicular ISAC channel measurements at 28 GHz are carried out and provide data for the characterization of non-stationarity characteristics. Based on the actual measurements, this paper analyzes the time-varying PDPs, RMSDS and non-stationarity characteristics of front, lower front, left and right perception directions in a complicated V2X scenarios. The research in this paper can enrich the investigation of vehicular ISAC channels and enable the analysis and design of vehicular ISAC systems."
https://arxiv.org/abs/2403.00556,2024-03-01,Nearest-Neighbours Estimators for Conditional Mutual Information,"['Jake Witter', 'Conor Houghton']","The conditional mutual information quantifies the conditional dependence of two random variables. It has numerous applications; it forms, for example, part of the definition of transfer entropy, a common measure of the causal relationship between time series. It does, however, require a lot of data to estimate accurately and suffers the curse of dimensionality, limiting its application in machine learning and data science. However, the Kozachenko-Leonenko approach can address this problem: it is possible, in this approach to define a nearest-neighbour estimator which depends only on the distance between data points and not on the dimension of the data. Furthermore, the bias can be calculated analytically for this estimator. Here this estimator is described and is tested on simulated data."
https://arxiv.org/abs/2403.00555,2024-03-01,Global solutions of the 3D incompressible inhomogeneous viscoelastic system,"['Chengfei Ai', 'Yong Wang']","In this paper, we prove the global existence of strong solutions for the 3D incompressible inhomogeneous viscoelastic system. We do not assume the ""initial state"" assumption and the ""div-curl"" structure inspired by the works [59,61]. It is a key to transform the original system into a suitable dissipative system by introducing a new effective tensor, which is useful to establish a series of energy estimates with appropriate time weights."
https://arxiv.org/abs/2403.00554,2024-03-01,Distributed MPC for autonomous ships on inland waterways with collaborative collision avoidance,"['Hoang Anh Tran', 'Tor Arne Johansen', 'Rudy R. Negenborn']","This paper presents a distributed solution for the problem of collaborative collision avoidance for autonomous inland waterway ships. A two-layer collision avoidance framework that considers inland waterway traffic regulations is proposed to increase navigational safety for autonomous ships. Our approach allows for modifying traffic rules without changing the collision avoidance algorithm, and is based on a novel formulation of model predictive control (MPC) for collision avoidance of ships. This MPC formulation is designed for inland waterway traffic and can handle complex scenarios. The alternating direction method of multipliers is used as a scheme for exchanging and negotiating intentions among ships. Simulation results show that the proposed algorithm can comply with traffic rules. Furthermore, the proposed algorithm can safely deviate from traffic rules when necessary to increase efficiency in complex scenarios."
https://arxiv.org/abs/2403.00553,2024-03-01,Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores,"['Chantal Shaib', 'Joe Barrow', 'Jiuding Sun', 'Alexa F. Siu', 'Byron C. Wallace', 'Ani Nenkova']","The diversity across outputs generated by large language models shapes the perception of their quality and utility. Prompt leaks, templated answer structure, and canned responses across different interactions are readily noticed by people, but there is no standard score to measure this aspect of model behavior. In this work we empirically investigate diversity scores on English texts. We find that computationally efficient compression algorithms capture information similar to what is measured by slow to compute $n$-gram overlap homogeneity scores. Further, a combination of measures -- compression ratios, self-repetition of long $n$-grams and Self-BLEU and BERTScore -- are sufficient to report, as they have low mutual correlation with each other. The applicability of scores extends beyond analysis of generative models; for example, we highlight applications on instruction-tuning datasets and human-produced texts. We release a diversity score package to facilitate research and invite consistency across reports."
https://arxiv.org/abs/2403.00552,2024-03-01,Sharp spectral gap of adaptive Langevin dynamics,['Lois Delande'],We consider a degenerated Fokker-Planck type differential operator associated to an adaptive Langevin dynamic. We prove Eyring-Kramers formulas for the bottom of the spectrum of this operator in the low temperature regime. The main ingredients are resolvent estimates obtained via hypocoercive techniques and the construction of sharp Gaussian quasimodes through an adaptation of the WKB method.
https://arxiv.org/abs/2403.00551,2024-03-01,Inferences for Random Graphs Evolved by Clustering Attachment,"['Natalia Markovich', 'Maksim Ryzhov', 'Marijus VaiÄiulis']",The evolution of random undirected graphs by the clustering attachment (CA) both without node and edge deletion and with uniform node or edge deletion is investigated. Theoretical results are obtained for the CA without node and edge deletion when a newly appended node is connected to two existing nodes of the graph at each evolution step. Theoretical results concern to (1) the sequence of increments of the consecutive mean clustering coefficients tends to zero; (2) the sequences of node degrees and triangle counts of any fixed node which are proved to be submartingales. These results were obtained for any initial graph. The simulation study is provided for the CA with uniform node or edge deletion and without any deletion. It is shown that (1) the CA leads to light-tailed distributed node degrees and triangle counts; (2) the average clustering coefficient tends to a constant over time; (3) the mean node degree and the mean triangle count increase over time with the rate depending on the parameters of the CA. The exposition is accompanied by a real data study.
https://arxiv.org/abs/2403.00550,2024-03-01,"Imitation Learning Datasets: A Toolkit For Creating Datasets, Training Agents and Benchmarking","['Nathan Gavenski', 'Michael Luck', 'Odinaldo Rodrigues']","Imitation learning field requires expert data to train agents in a task. Most often, this learning approach suffers from the absence of available data, which results in techniques being tested on its dataset. Creating datasets is a cumbersome process requiring researchers to train expert agents from scratch, record their interactions and test each benchmark method with newly created data. Moreover, creating new datasets for each new technique results in a lack of consistency in the evaluation process since each dataset can drastically vary in state and action distribution. In response, this work aims to address these issues by creating Imitation Learning Datasets, a toolkit that allows for: (i) curated expert policies with multithreaded support for faster dataset creation; (ii) readily available datasets and techniques with precise measurements; and (iii) sharing implementations of common imitation learning techniques. Demonstration link: https://nathangavenski.github.io/#/il-datasets-video"
https://arxiv.org/abs/2403.00549,2024-03-01,Relaxometry Guided Quantitative Cardiac Magnetic Resonance Image Reconstruction,"['Yidong Zhao', 'Yi Zhang', 'Qian Tao']","Deep learning-based methods have achieved prestigious performance for magnetic resonance imaging (MRI) reconstruction, enabling fast imaging for many clinical applications. Previous methods employ convolutional networks to learn the image prior as the regularization term. In quantitative MRI, the physical model of nuclear magnetic resonance relaxometry is known, providing additional prior knowledge for image reconstruction. However, traditional reconstruction networks are limited to learning the spatial domain prior knowledge, ignoring the relaxometry prior. Therefore, we propose a relaxometry-guided quantitative MRI reconstruction framework to learn the spatial prior from data and the relaxometry prior from MRI physics. Additionally, we also evaluated the performance of two popular reconstruction backbones, namely, recurrent variational networks (RVN) and variational networks (VN) with U- Net. Experiments demonstrate that the proposed method achieves highly promising results in quantitative MRI reconstruction."
https://arxiv.org/abs/2403.00548,2024-03-01,Special Joyce structures and hyperkÃ¤hler metrics,['IvÃ¡n Tulli'],"Joyce structures were introduced by T. Bridgeland in the context of the space of stability conditions of a three-dimensional Calabi-Yau category and its associated Donaldson-Thomas invariants. In subsequent work, T. Bridgeland and I. Strachan showed that Joyce structures satisfying a certain non-degeneracy condition encode a complex hyperkÃ¤hler structure on the tangent bundle of the base of the Joyce structure. In this work we give a definition of an analogous structure over an affine special KÃ¤hler (ASK) manifold, which we call a special Joyce structure. Furthermore, we show that it encodes a real hyperkÃ¤hler (HK) structure on the tangent bundle of the ASK manifold, possibly of indefinite signature. Particular examples include the semi-flat HK metric associated to an ASK manifold (also known as the rigid c-map metric) and the HK metrics associated to certain uncoupled variations of BPS structures over the ASK manifold. Finally, we relate the HK metrics coming from special Joyce structures to HK metrics on the total space of algebraic integrable systems."
https://arxiv.org/abs/2403.00547,2024-03-01,The EDIBLES Survey. VIII. Band profile alignment of diffuse interstellar bands,"['A. Ebenbichler', 'J. V. Smoker', 'R. Lallement', 'A. Farhang', 'N. L. J. Cox', 'C. Joblin', 'J. Th. van Loon', 'H. Linnartz', 'N. Przybilla', 'P. Ehrenfreund', 'J. Cami', 'M. Cordiner']","Context: There have been many attempts to identify families of diffuse interstellar bands (DIBs) with perfectly correlating band strengths. Although major efforts have been made to classify broadly based DIB families and important insights have been gained, no family has been identified with sufficient accuracy or statistical significance to prove that a series of selected DIBs originates from the same carrier. This can be attributed in part to the exclusive use of equivalent widths to establish DIB families."
https://arxiv.org/abs/2403.00546,2024-03-01,Comparative Study of Simulators for Vehicular Networks,"['Rida Saghir', 'Thenuka Karunathilake', 'Anna FÃ¶rster']","Vehicular Adhoc networks (VANETs) are composed of vehicles connected with wireless links to exchange data. VANETs have become the backbone of the Intelligent Transportation Systems (ITS) in smart cities and enable many essential services like roadside safety, traffic management, platooning, etc with vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications. In any form of research testing and evaluation plays a crucial role. However, in VANETs, real-world experiments require high investment, and heavy resources and can cause many practical difficulties. Therefore, simulations have become critical and the primary way of evaluating VANETs' applications. Furthermore, the upfront challenge is the realistic capture of the networking mechanism of VANETs, which varies from situation to situation. Several factors may contribute to the successful achievement of a random realistic networking behavior. However, the biggest dependency is a powerful tool for the implementation, which could probably take into account all the configuration parameters, loss factors, mobility schemes, and other key features of a VANET, yet give out practical performance metrics with a good trade-off between investment of resources and the results. Hence, the aim of this research is to evaluate some simulators in the scope of VANETs with respect to resource utilization, packet delivery, and computational time."
https://arxiv.org/abs/2403.00545,2024-03-01,Twisted restricted conformal blocks of vertex operator algebras II: twisted restricted conformal blocks on totally ramified orbifold curves,"['Xu Gao', 'Jianqi Liu', 'Yiyi Zhu']","In this paper, we introduce a notion of twisted restricted conformal blocks on totally ramified orbifold curves and establish the isomorphism between the space of twisted restricted conformal blocks and the space of twisted conformal blocks. In the specific example of a twisted projective line, isomorphisms between the space of $g$-twisted (restricted) conformal block and the space of $g$-twisted (restricted) correlation functions are established. This leads to a more conceptual proof of the $g$-twisted fusion rule theorem in vertex operator algebra theory. Furthermore, by introducing a geometric generalization of Zhu's algebra and its modules, we obtain a general version of the twisted fusion rule theorem."
https://arxiv.org/abs/2403.00544,2024-03-01,Carroll swiftons,"['Florian Ecker', 'Daniel Grumiller', 'Marc Henneaux', 'Patricio Salgado-Rebolledo']","We construct Carroll-invariant theories with fields propagating outside the Carroll lightcone, i.e., at a speed strictly greater than zero (`Carroll swiftons'). We first consider models in flat Carroll spacetime in general dimensions, where we present scalar and vector Carroll swifton field theories. We then turn to the coupling to gravity and achieve in particular in two dimensions a Carroll invariant scalar swifton by coupling it suitably to Carroll dilaton gravity. Its backreaction on the geometry generates dynamical torsion."
https://arxiv.org/abs/2403.00543,2024-03-01,SURE: SUrvey REcipes for building reliable and robust deep networks,"['Yuting Li', 'Yingyi Chen', 'Xuanlong Yu', 'Dexiong Chen', 'Xi Shen']","In this paper, we revisit techniques for uncertainty estimation within deep neural networks and consolidate a suite of techniques to enhance their reliability. Our investigation reveals that an integrated application of diverse techniques--spanning model regularization, classifier and optimization--substantially improves the accuracy of uncertainty predictions in image classification tasks. The synergistic effect of these techniques culminates in our novel SURE approach. We rigorously evaluate SURE against the benchmark of failure prediction, a critical testbed for uncertainty estimation efficacy. Our results showcase a consistently better performance than models that individually deploy each technique, across various datasets and model architectures. When applied to real-world challenges, such as data corruption, label noise, and long-tailed class distribution, SURE exhibits remarkable robustness, delivering results that are superior or on par with current state-of-the-art specialized methods. Particularly on Animal-10N and Food-101N for learning with noisy labels, SURE achieves state-of-the-art performance without any task-specific adjustments. This work not only sets a new benchmark for robust uncertainty estimation but also paves the way for its application in diverse, real-world scenarios where reliability is paramount. Our code is available at \url{https://yutingli0606.github.io/SURE/}."
https://arxiv.org/abs/2403.00542,2024-03-01,Machine Learning Training Optimization using the Barycentric Correction Procedure,"['Sofia Ramos-Pulido', 'Neil Hernandez-Gress', 'Hector G. Ceballos-Cancino']","Machine learning (ML) algorithms are predictively competitive algorithms with many human-impact applications. However, the issue of long execution time remains unsolved in the literature for high-dimensional spaces. This study proposes combining ML algorithms with an efficient methodology known as the barycentric correction procedure (BCP) to address this issue. This study uses synthetic data and an educational dataset from a private university to show the benefits of the proposed method. It was found that this combination provides significant benefits related to time in synthetic and real data without losing accuracy when the number of instances and dimensions increases. Additionally, for high-dimensional spaces, it was proved that BCP and linear support vector classification (LinearSVC), after an estimated feature map for the gaussian radial basis function (RBF) kernel, were unfeasible in terms of computational time and accuracy."
https://arxiv.org/abs/2403.00541,2024-03-01,Encounter circumstances of asteroid 99942 Apophis with the catalogue of known asteroids,"['Paul Wiegert', 'Ben Hyatt']","Asteroid 99942 Apophis will pass near the Earth in April 2029. Expected to miss our planet by a safe margin, that could change if Apophis' path was perturbed by a collision with another asteroid in the interim. Though the statistical chance of such a collision is minuscule, the high risk associated with Apophis motivates us to examine even this very unlikely scenario. In this work, we identify encounters between known asteroids and Apophis up to April 2029. Here we show that Apophis will encounter the 1300 meter diameter asteroid 4544 Xanthus in December 2026. Their Minimum Orbit Intersection Distance (MOID) is less than 10,000 km, with Xanthus passing that closest point just four hours after Apophis. Though a direct collision is ruled out, the encounter is close enough that material accompanying Xanthus (if any) could strike Apophis. We also identify other asteroid encounters that deserve monitoring."
https://arxiv.org/abs/2403.00540,2024-03-01,Epsilon-Greedy Thompson Sampling to Bayesian Optimization,"['Bach Do', 'Ruda Zhang']","Thompson sampling (TS) serves as a solution for addressing the exploitation-exploration dilemma in Bayesian optimization (BO). While it prioritizes exploration by randomly generating and maximizing sample paths of Gaussian process (GP) posteriors, TS weakly manages its exploitation by gathering information about the true objective function after each exploration is performed. In this study, we incorporate the epsilon-greedy ($\varepsilon$-greedy) policy, a well-established selection strategy in reinforcement learning, into TS to improve its exploitation. We first delineate two extremes of TS applied for BO, namely the generic TS and a sample-average TS. The former and latter promote exploration and exploitation, respectively. We then use $\varepsilon$-greedy policy to randomly switch between the two extremes. A small value of $\varepsilon \in (0,1)$ prioritizes exploitation, and vice versa. We empirically show that $\varepsilon$-greedy TS with an appropriate $\varepsilon$ is better than one of its two extremes and competes with the other."
https://arxiv.org/abs/2403.00539,2024-03-01,DyPyBench: A Benchmark of Executable Python Software,"['Islem Bouzenia', 'Bajaj Piyush Krishan', 'Michael Pradel']","Python has emerged as one of the most popular programming languages, extensively utilized in domains such as machine learning, data analysis, and web applications. Python's dynamic nature and extensive usage make it an attractive candidate for dynamic program analysis. However, unlike for other popular languages, there currently is no comprehensive benchmark suite of executable Python projects, which hinders the development of dynamic analyses. This work addresses this gap by presenting DyPyBench, the first benchmark of Python projects that is large scale, diverse, ready to run (i.e., with fully configured and prepared test suites), and ready to analyze (by integrating with the DynaPyt dynamic analysis framework). The benchmark encompasses 50 popular opensource projects from various application domains, with a total of 681k lines of Python code, and 30k test cases. DyPyBench enables various applications in testing and dynamic analysis, of which we explore three in this work: (i) Gathering dynamic call graphs and empirically comparing them to statically computed call graphs, which exposes and quantifies limitations of existing call graph construction techniques for Python. (ii) Using DyPyBench to build a training data set for LExecutor, a neural model that learns to predict values that otherwise would be missing at runtime. (iii) Using dynamically gathered execution traces to mine API usage specifications, which establishes a baseline for future work on specification mining for Python. We envision DyPyBench to provide a basis for other dynamic analyses and for studying the runtime behavior of Python code."
https://arxiv.org/abs/2403.00538,2024-03-01,Asymmetrical temporal dynamics of topological edge modes in Su-Schrieffer-Heeger lattice with Kerr nonlinearity,"['Ghada Alharbi', 'Stephan Wong', 'Yongkang Gong', 'Sang Soon Oh']","Optical bistability and oscillating phases exist in a Sagnac interferometer and a single ring resonator made of $Ï^{(3)}$ nonlinear medium where the refractive indices are modulated by the light intensity due to the Kerr nonlinearity. An array of coupled nonlinear ring resonators behave similarly but with more complexity due to the presence of the additional couplings.Here, we theoretically demonstrate the bifurcation of topological edge modes which leads to optical bistability in the Su-Schrieffer-Heeger lattice with the Kerr nonlinearity. Additionally, we demonstrate periodic and chaotic switching behaviors in an oscillating phase resulting from the coupling between the topological edge mode and bulk modes with different chiralities, i.e., clockwise and counter-clockwise circulations."
https://arxiv.org/abs/2403.00537,2024-03-01,A Modular and Robust Physics-Based Approach for Lensless Image Reconstruction,"['Yohann Perron', 'Eric Bezzam', 'Martin Vetterli']","In this paper, we present a modular approach for reconstructing lensless measurements. It consists of three components: a newly-proposed pre-processor, a physics-based camera inverter to undo the multiplexing of lensless imaging, and a post-processor. The pre- and post-processors address noise and artifacts unique to lensless imaging before and after camera inversion respectively. By training the three components end-to-end, we obtain a 1.9 dB increase in PSNR and a 14% relative improvement in a perceptual image metric (LPIPS) with respect to previously proposed physics-based methods. We also demonstrate how the proposed pre-processor provides more robustness to input noise, and how an auxiliary loss can improve interpretability."
https://arxiv.org/abs/2403.00536,2024-03-01,Approximating the Geometric Knapsack Problem in Near-Linear Time and Dynamically,"['Moritz Buchem', 'Paul Deuker', 'Andreas Wiese']","An important goal in algorithm design is determining the best running time for solving a problem (approximately). For some problems, we know the optimal running time, assuming certain conditional lower bounds. In this work, we study the $d$-dimensional geometric knapsack problem where we are far from this level of understanding. We are given a set of weighted d-dimensional geometric items like squares, rectangles, or hypercubes and a knapsack which is a square or a (hyper-)cube. We want to select a subset of items that fit non-overlappingly inside the knapsack, maximizing the total profit of the packed items. We make a significant step towards determining the best running time for solving these problems approximately by presenting approximation algorithms with near-linear running times for any constant dimension d and any constant parameter $Îµ$."
https://arxiv.org/abs/2403.00535,2024-03-01,Water vapour masers in long-period variable stars III. Mira variables U Her and RR Aql,"['A. Winnberg', 'J. Brand', 'D. Engels']","Within the 'Medicina/Effelsberg H2O maser monitoring program' we observed U Her and RR Aql at 22-GHz for about two decades between 1990 and 2011, with a gap between 1997 and 2000 in the case of RR Aql. In addition, maps were obtained in the period 1990-1992 of U Her with the Very Large Array. We find that the strongest emission in U Her is located in a shell with boundaries 11-25 AU. The gas crossing time is 8.5 years. We derive lifetimes for individual maser clouds of less than 4 years, based on the absence of detectable line-of-sight velocity drifts of the maser emission. The shell is not evenly filled, and its structure is maintained on timescales much longer than those of individual maser clouds."
https://arxiv.org/abs/2403.00534,2024-03-01,N-representable one-electron reduced density matrix reconstruction with frozen core electrons,"['Sizhuo Yu', 'Jean-Michel Gillet']","Recent advances in quantum crystallography have shown that, beyond conventional charge density refinement, a one-electron reduced density matrix (1-RDM) satisfying N-representability conditions can be reconstructed using jointly experimental X-ray structure factors (XSF) and directional Compton profiles (DCP) through semi-definite programming. So far, such reconstruction methods for 1-RDM, not constrained to idempotency, had been tested only on a toy model system (CO$_2$). In this work, a new method is assessed on crystalline urea (CO(NH$_2$)$_2$) using static (0 K) and dynamic (50 K) artificial-experimental data. An improved model, including symmetry constraints and frozen-core electron contribution, is introduced to better handle the increasing system complexity. Reconstructed 1-RDMs, deformation densities and DCP anisotropy are analyzed, and it is demonstrated that the changes in the model significantly improve the reconstruction's quality against insufficient information and data corruption. The robustness of the model and the strategy are thus shown to be well-adapted to address the reconstruction problem from actual experimental scattering data."
https://arxiv.org/abs/2403.00533,2024-03-01,Gravitational waves in a cyclic Universe: resilience through cycles and vacuum state,"['Mariaveronica De Angelis', 'Adam Smith', 'William GiarÃ¨', 'Carsten van de Bruck']","We present a generalised calculation for the spectrum of primordial tensor perturbations in a cyclic Universe, making no assumptions about the vacuum state of the theory and accounting for the contribution of tensor modes produced in the dark energy phase of the previous cycle. We show that these modes have minimal impact on the spectrum observed in the current cycle, except for corrections on scales as large as the comoving Hubble radius today. These corrections are due to sub-horizon modes produced towards the end of the dark energy phase, persisting into the ekpyrotic phase of the next cycle as additional quanta. In relation to the vacuum state, we argue that non-Bunch-Davies quanta can easily overwhelm the energy density driving the dark energy phase, potentially compromising the model. Therefore, avoiding backreaction effects sets restrictive constraints on deviations away from the Bunch-Davies vacuum during this phase, limiting the overall freedom to consider alternative vacua in the cyclic Universe."
https://arxiv.org/abs/2403.00532,2024-03-01,Introduction to Theoretical and Experimental aspects of Quantum Optimal Control,"['Q. Ansel', 'E. Dionis', 'F. Arrouas', 'B. Peaudecerf', 'S. GuÃ©rin', 'D. GuÃ©ry-Odelin', 'D. Sugny']","Quantum optimal control is a set of methods for designing time-varying electromagnetic fields to perform operations in quantum technologies. This tutorial paper introduces the basic elements of this theory based on the Pontryagin maximum principle, in a physicist-friendly way. An analogy with classical Lagrangian and Hamiltonian mechanics is proposed to present the main results used in this field. Emphasis is placed on the different numerical algorithms to solve a quantum optimal control problem. Several examples ranging from the control of two-level quantum systems to that of Bose-Einstein Condensates (BEC) in a one-dimensional optical lattice are studied in detail, using both analytical and numerical methods. Codes based on shooting method and gradient-based algorithms are provided. The connection between optimal processes and the quantum speed limit is also discussed in two-level quantum systems. In the case of BEC, the experimental implementation of optimal control protocols is described, both for two-level and many-level cases, with the current constraints and limitations of such platforms. This presentation is illustrated by the corresponding experimental results."
https://arxiv.org/abs/2403.00531,2024-03-01,Phenomenology of renormalization group improved gravity from the kinematics of SPARC galaxies,"['Esha Bhatia', 'Sayan Chakrabarti', 'Sovan Chakraborty']","Renormalization Group correction to General Relativity (RGGR) proposes a logarithmic running of the gravitational coupling $\left(G\right)$, resulting in a modified description of gravity. This has the potential to explain the observed kinematics of the galaxies, including the missing-mass problem. We, for the first time, based on the galaxy morphological types, investigate the dynamics of a diverse collection of galaxies present in the Spitzer Photometry for Accurate Rotation Curve (SPARC) catalog. We phenomenologically constrain the RGGR model parameter $\left(\barÎ½\right)$ along with the mass-to-light ratio for a sample of 100 SPARC galaxies, selected from four different morphological types, viz. early, spiral, late, and starburst. Our statistical analysis finds RGGR to fit the observed galaxy kinematics consistently. The constrained RGGR model parameter also supports the claim that it has a near-linear dependence on the galactic baryonic mass. From our morphology study, we find that the parameter $\barÎ½$ decreases from the early-type to the starburst galaxies. Finally, the renormalization group improved gravity is tested against the two established empirical relations for the SPARC catalog, viz., the Radial Acceleration Relation (RAR) and the Baryonic Tully Fisher relation (BTFR), both are found to be satisfied consistently."
https://arxiv.org/abs/2403.00530,2024-03-01,Extended Hubbard corrected tight-binding model for rhombohedral few-layer graphene,"['Dongkyu Lee', 'Wooil Yang', 'Young-Woo Son', 'Jeil Jung']","Rhombohedral multilayer graphene (RnG) featuring partially flat bands has emerged as an important platform to probe strong Coulomb correlation effects. Theoretical consideration of local electron-electron interactions are of particular importance for electronic eigenstates with a tendency to spatially localize. We present a method to incorporate mean-field electron-electron interaction corrections in the tight-binding hopping parameters of the band Hamiltonian within the extended Hubbard model that incorporates ab initio estimates of on-site ($U$) and inter-site ($V$) Hubbard interactions for the $Ï$ bands of RnG. Our Coulomb-interaction renormalized band structures feature electron-hole asymmetry, band flatness, band gap, and anti-ferromagnetic ground states in excellent agreement with available experiments for $n \geq 4$. We reinterpret the putative gaps proposed in $n=3$ systems in terms of shifting electron and hole density of states peaks depending on the range of the Coulomb interaction models."
https://arxiv.org/abs/2403.00529,2024-03-01,VoxGenesis: Unsupervised Discovery of Latent Speaker Manifold for Speech Synthesis,"['Weiwei Lin', 'Chenhang He', 'Man-Wai Mak', 'Jiachen Lian', 'Kong Aik Lee']","Achieving nuanced and accurate emulation of human voice has been a longstanding goal in artificial intelligence. Although significant progress has been made in recent years, the mainstream of speech synthesis models still relies on supervised speaker modeling and explicit reference utterances. However, there are many aspects of human voice, such as emotion, intonation, and speaking style, for which it is hard to obtain accurate labels. In this paper, we propose VoxGenesis, a novel unsupervised speech synthesis framework that can discover a latent speaker manifold and meaningful voice editing directions without supervision. VoxGenesis is conceptually simple. Instead of mapping speech features to waveforms deterministically, VoxGenesis transforms a Gaussian distribution into speech distributions conditioned and aligned by semantic tokens. This forces the model to learn a speaker distribution disentangled from the semantic content. During the inference, sampling from the Gaussian distribution enables the creation of novel speakers with distinct characteristics. More importantly, the exploration of latent space uncovers human-interpretable directions associated with specific speaker characteristics such as gender attributes, pitch, tone, and emotion, allowing for voice editing by manipulating the latent codes along these identified directions. We conduct extensive experiments to evaluate the proposed VoxGenesis using both subjective and objective metrics, finding that it produces significantly more diverse and realistic speakers with distinct characteristics than the previous approaches. We also show that latent space manipulation produces consistent and human-identifiable effects that are not detrimental to the speech quality, which was not possible with previous approaches. Audio samples of VoxGenesis can be found at: \url{https://bit.ly/VoxGenesis}."
https://arxiv.org/abs/2403.00528,2024-03-01,Large Language Models for Simultaneous Named Entity Extraction and Spelling Correction,"['Edward Whittaker', 'Ikuo Kitagishi']","Language Models (LMs) such as BERT, have been shown to perform well on the task of identifying Named Entities (NE) in text. A BERT LM is typically used as a classifier to classify individual tokens in the input text, or to classify spans of tokens, as belonging to one of a set of possible NE categories."
https://arxiv.org/abs/2403.00527,2024-03-01,"""There is a Job Prepared for Me Here"": Understanding How Short Video and Live-streaming Platforms Empower Ageing Job Seekers in China","['PiaoHong Wang', 'Siying Hu', 'Bo Wen', 'Zhicong Lu']","In recent years, the global unemployment rate has remained persistently high. Compounding this issue, the ageing population in China often encounters additional challenges in finding employment due to prevalent age discrimination in daily life. However, with the advent of social media, there has been a rise in the popularity of short videos and live-streams for recruiting ageing workers. To better understand the motivations of ageing job seekers to engage with these video-based recruitment methods and to explore the extent to which such platforms can empower them, we conducted an interview-based study with ageing job seekers who have had exposure to these short recruitment videos and live-streaming channels. Our findings reveal that these platforms can provide a job-seeking choice that is particularly friendly to ageing job seekers, effectively improving their disadvantaged situation."
https://arxiv.org/abs/2403.00526,2024-03-01,Data Quality Assessment: Challenges and Opportunities,"['Sedir Mohammed', 'Hazar Harmouch', 'Felix Naumann', 'Divesh Srivastava']","Data-oriented applications, their users, and even the law require data of high quality. Research has broken down the rather vague notion of data quality into various dimensions, such as accuracy, consistency, and reputation, to name but a few. To achieve the goal of high data quality, many tools and techniques exist to clean and otherwise improve data. Yet, systematic research on actually assessing data quality in all of its dimensions is largely absent, and with it the ability to gauge the success of any data cleaning effort. It is our vision to establish a systematic and comprehensive framework for the (numeric) assessment of data quality for a given dataset and its intended use. Such a framework must cover the various facets that influence data quality, as well as the many types of data quality dimensions. In particular, we identify five facets that serve as a foundation of data quality assessment. For each facet, we outline the challenges and opportunities that arise when trying to actually assign quality scores to data and create a data quality profile for it, along with a wide range of technologies needed for this purpose."
https://arxiv.org/abs/2403.00525,2024-03-01,Minority magnons and mode branching in monolayer Fe$_3$GeTe$_2$,"['ThorbjÃ¸rn Skovhus', 'Thomas Olsen']","In this letter, we predict the existence of minority magnons in a monolayer of Fe$_3$GeTe$_2$ using first principles calculations. Minority magnons constitute a new type of collective magnetic excitations which increase the magnetic moment rather than lower it, contrary to ordinary (majority) magnons. The presence of such quasi-particles is made possible by the nontrivial ferromagnetic band structure of Fe$_3$GeTe$_2$ originating from its nonequivalent Fe sublattices. The result is a strong peak in the dynamic spin-raising susceptibility $Ï^{-+}(Ï)$ in the long wavelength limit, which is the hallmark of minority magnon physics. We calculate the susceptibility using time-dependent density functional theory and perform a detailed mode analysis, which allows us to separate and investigate the individual magnon modes as well as the Stoner excitations that constitute the many-body spectrum. For minority as well as majority magnons, the analysis reveals a plethora of magnetic excitations, which in addition to the standard main magnon branches include both satellite, valley and spin-inversion magnons, originating from the itinerancy of the ferromagnetic order. The physics underlying this analysis is in no way restricted to Fe$_3$GeTe$_2$, and minority magnons are expected to be observable in many complex ferromagnetic materials."
https://arxiv.org/abs/2403.00524,2024-03-01,Chaos-assisted Turbulence in Spinor Bose-Einstein Condensates,"['Jongmin Kim', 'Jongheum Jung', 'Junghoon Lee', 'Deokhwa Hong', 'Yong-il Shin']","We present a turbulence-sustaining mechanism in a spinor Bose-Einstein condensate, which is based on the chaotic nature of internal spin dynamics. Magnetic driving induces a complete chaotic evolution of the local spin state, thereby continuously randomizing the spin texture of the condensate to maintain the turbulent state. We experimentally demonstrate the onset of turbulence in the driven condensate as the driving frequency changes and show that it is consistent with the regular-to-chaotic transition of the local spin dynamics. This chaos-assisted turbulence establishes the spin-driven spinor condensate as an intriguing platform for exploring quantum chaos and related superfluid turbulence phenomena."
https://arxiv.org/abs/2403.00523,2024-03-01,Assessing the Efficacy of Heuristic-Based Address Clustering for Bitcoin,"['Hugo Schnoering', 'Pierre Porthaux', 'Michalis Vazirgiannis']","Exploring transactions within the Bitcoin blockchain entails examining the transfer of bitcoins among several hundred million entities. However, it is often impractical and resource-consuming to study such a vast number of entities. Consequently, entity clustering serves as an initial step in most analytical studies. This process often employs heuristics grounded in the practices and behaviors of these entities. In this research, we delve into the examination of two widely used heuristics, alongside the introduction of four novel ones. Our contribution includes the introduction of the \textit{clustering ratio}, a metric designed to quantify the reduction in the number of entities achieved by a given heuristic. The assessment of this reduction ratio plays an important role in justifying the selection of a specific heuristic for analytical purposes. Given the dynamic nature of the Bitcoin system, characterized by a continuous increase in the number of entities on the blockchain, and the evolving behaviors of these entities, we extend our study to explore the temporal evolution of the clustering ratio for each heuristic. This temporal analysis enhances our understanding of the effectiveness of these heuristics over time."
https://arxiv.org/abs/2403.00522,2024-03-01,VisionLLaMA: A Unified LLaMA Interface for Vision Tasks,"['Xiangxiang Chu', 'Jianlin Su', 'Bo Zhang', 'Chunhua Shen']","Large language models are built on top of a transformer-based architecture to process textual inputs. For example, the LLaMA stands out among many open-source implementations. Can the same transformer be used to process 2D images? In this paper, we answer this question by unveiling a LLaMA-like vision transformer in plain and pyramid forms, termed VisionLLaMA, which is tailored for this purpose. VisionLLaMA is a unified and generic modelling framework for solving most vision tasks. We extensively evaluate its effectiveness using typical pre-training paradigms in a good portion of downstream tasks of image perception and especially image generation. In many cases, VisionLLaMA have exhibited substantial gains over the previous state-of-the-art vision transformers. We believe that VisionLLaMA can serve as a strong new baseline model for vision generation and understanding. Our code will be released at https://github.com/Meituan-AutoML/VisionLLaMA."
https://arxiv.org/abs/2403.00521,2024-03-01,Microwave Control of the Tin-Vacancy Spin Qubit in Diamond with a Superconducting Waveguide,"['Ioannis Karapatzakis', 'Jeremias Resch', 'Marcel Schrodin', 'Philipp Fuchs', 'Michael Kieschnick', 'Julia Heupel', 'Luis Kussi', 'Christoph SÃ¼rgers', 'Cyril Popov', 'Jan Meijer', 'Christoph Becher', 'Wolfgang Wernsdorfer', 'David Hunger']","Group-IV color centers in diamond are promising candidates for quantum networks due to their dominant zero-phonon line and symmetry-protected optical transitions that connect to coherent spin levels. The negatively charged tin-vacancy (SnV) center possesses long electron spin lifetimes due to its large spin-orbit splitting. However, the magnetic dipole transitions required for microwave spin control are suppressed, and strain is necessary to enable these transitions. Recent work has shown spin control of strained emitters using microwave lines that suffer from Ohmic losses, restricting coherence through heating. We utilize a superconducting coplanar waveguide to measure SnV centers subjected to strain, observing substantial improvement. A detailed analysis of the SnV center electron spin Hamiltonian based on the angle-dependent splitting of the ground and excited states is performed. We demonstrate coherent spin manipulation and obtain a Hahn echo coherence time of up to $T_2 = 430\,Î¼$s. With dynamical decoupling, we can prolong coherence to $T_2 = 10\,$ms, about six-fold improved compared to earlier works. We also observe a nearby coupling $^{13}\mathrm{C}$ spin which may serve as a quantum memory. This substantiates the potential of SnV centers in diamond and demonstrates the benefit of superconducting microwave structures."
https://arxiv.org/abs/2403.00520,2024-03-01,IAI MovieBot 2.0: An Enhanced Research Platform with Trainable Neural Components and Transparent User Modeling,"['Nolwenn Bernard', 'Ivica Kostric', 'Krisztian Balog']","While interest in conversational recommender systems has been on the rise, operational systems suitable for serving as research platforms for comprehensive studies are currently lacking. This paper introduces an enhanced version of the IAI MovieBot conversational movie recommender system, aiming to evolve it into a robust and adaptable platform for conducting user-facing experiments. The key highlights of this enhancement include the addition of trainable neural components for natural language understanding and dialogue policy, transparent and explainable modeling of user preferences, along with improvements in the user interface and research infrastructure."
https://arxiv.org/abs/2403.00519,2024-03-01,"On two non-existence results for Cameron-Liebler $k$-sets in $\mathrm{PG}(n,q)$","['Jan De Beule', 'Jonathan Mannaert', 'Leo Storme']","This paper focuses on non-existence results for Cameron-Liebler $k$-sets. A Cameron-Liebler $k$-set is a collection of $k$-spaces in $\mathrm{PG}(n,q)$ or $\mathrm{AG}(n,q)$ admitting a certain parameter $x$, which is dependent on the size of this collection. One of the main research questions remains the (non-)existence of Cameron-Liebler $k$-sets with parameter $x$. This paper improves two non-existence results. First we show that the parameter of a non-trivial Cameron-Liebler $k$-set in $\mathrm{PG}(n,q)$ should be larger than $q^{n-\frac{5k}{2}-1}$, which is an improvement of an earlier known lower bound. Secondly, we prove a modular equality on the parameter $x$ of Cameron-Liebler $k$-sets in $\mathrm{PG}(n,q)$ with $x<\frac{q^{n-k}-1}{q^{k+1}-1}$, $n\geq 2k+1$, $n-k+1\geq 7$ and $n-k$ even. In the affine case we show a similar result for $n-k+1\geq 3$ and $n-k$ even. This is a generalization of earlier known modular equalities in the projective and affine case."
https://arxiv.org/abs/2403.00518,2024-03-01,Quadratic functions as solutions of polynomial equations,"['Eszter Gselmann', 'Mehak Iqbal']","The so-called polynomial equations play an important role both in algebra and in the theory of functional equations. If the unknown functions in the equation are additive, relatively many results are known. However, even in this case, there are a lot of open questions. In some specific cases, according to classical results, the unknown additive functions are homomorphisms, derivations, or linear combinations of these. The question arises as to whether the solutions can be described even if the unknown functions are not assumed to be additive but to be generalized monomials. As a starting point, we will deal with quadratic functions in this paper. We aim to show that quadratic functions that are solutions to certain polynomial equations necessarily have a `special' form. Further, we also present a method to determine these special forms."
https://arxiv.org/abs/2403.00517,2024-03-01,Optimization of the Energy-Comfort Trade-Off of HVAC Systems in Electric City Buses Based on a Steady-State Model,"['Fabio Widmer', 'Stijn van Dooren', 'Christopher H. Onder']","The electrification of public transport vehicles offers the potential to relieve city centers of pollutant and noise emissions. Furthermore, electric buses have lower life-cycle greenhouse gas (GHG) emissions than diesel buses, particularly when operated with sustainably produced electricity. However, the heating, ventilation, and air-conditioning (HVAC) system can consume a significant amount of energy, thus limiting the achievable driving range. In this paper, we address the HVAC system in an electric city bus by analyzing the trade-off between the energy consumption and the thermal comfort of the passengers. We do this by developing a dynamic thermal model for the bus cabin, which we simplify by considering it to be in steady state. We introduce a method that is able to quickly optimize the steady-state HVAC system inputs for a large number of samples representative of a year-round operation. A comparison between the results from the steady-state optimization approach and a dynamic simulation reveal small deviations in both the HVAC system power demand and achieved thermal comfort. Thus, the approximation of the system performance with a steady-state model is justified. We present two case studies to demonstrate the practical relevance of the approach. First, we show how the method can be used to compare different system designs based on a year-round performance evaluation. Second, we show how the method can be used to generate accurate setpoints for online controllers. In conclusion, this study shows that a steady-state analysis of the HVAC systems of an electric city bus is a valuable approach to evaluate and optimize its performance."
https://arxiv.org/abs/2403.00516,2024-03-01,Extensions of braid group representations to the monoid of singular braids,"['Valeriy G. Bardakov', 'Nafaa Chbili', 'Tatyana A. Kozlovskaya']","Given a representation $\varphi \colon B_n \to G_n$ of the braid group $B_n$, $n \geq 2$ into a group $G_n$, we are considering the problem of whether it is possible to extend this representation to a representation $Î¦\colon SM_n \to A_n$, where $SM_n$ is the singular braid monoid and $A_n$ is an associative algebra, in which the group of units contains $G_n$. We also investigate the possibility of extending the representation $Î¦\colon SM_n \to A_n$ to a representation $\widetildeÎ¦ \colon SB_n \to A_n$ of the singular braid group $SB_n$. On the other hand, given two linear representations $\varphi_1, \varphi_2 \colon H \to GL_m(\Bbbk)$ of a group $H$ into a general linear group over a field $\Bbbk$, we define the defect of one of these representations with respect to the other. Furthermore, we construct a linear representation of $SB_n$ which is an extension of the Lawrence-Krammer-Bigelow representation (LKBR) and compute the defect of this extension with respect to the exterior product of two extensions of the Burau representation. Finally, we discuss how to derive an invariant of classical links from the Lawrence-Krammer-Bigelow representation."
https://arxiv.org/abs/2403.00515,2024-03-01,Are Unikernels Ready for Serverless on the Edge?,"['Felix Moebius', 'Tobias Pfandzelter', 'David Bermbach']","Function-as-a-Service (FaaS) is a promising edge computing execution model but requires secure sandboxing mechanisms to isolate workloads from multiple tenants on constrained infrastructure. Although Docker containers are lightweight and popular in open-source FaaS platforms, they are generally considered insufficient for executing untrusted code and providing sandbox isolation. Commercial cloud FaaS platforms thus rely on Linux microVMs or hardened container runtimes, which are secure but come with a higher resource footprint."
https://arxiv.org/abs/2403.00514,2024-03-01,"Overestimation, Overfitting, and Plasticity in Actor-Critic: the Bitter Lesson of Reinforcement Learning","['Michal Nauman', 'MichaÅ Bortkiewicz', 'Mateusz Ostaszewski', 'Piotr MiÅoÅ', 'Tomasz TrzciÅski', 'Marek Cygan']","Recent advancements in off-policy Reinforcement Learning (RL) have significantly improved sample efficiency, primarily due to the incorporation of various forms of regularization that enable more gradient update steps than traditional agents. However, many of these techniques have been tested in limited settings, often on tasks from single simulation benchmarks and against well-known algorithms rather than a range of regularization approaches. This limits our understanding of the specific mechanisms driving RL improvements. To address this, we implemented over 60 different off-policy agents, each integrating established regularization techniques from recent state-of-the-art algorithms. We tested these agents across 14 diverse tasks from 2 simulation benchmarks. Our findings reveal that while the effectiveness of a specific regularization setup varies with the task, certain combinations consistently demonstrate robust and superior performance. Notably, a simple Soft Actor-Critic agent, appropriately regularized, reliably solves dog tasks, which were previously solved mainly through model-based approaches."
https://arxiv.org/abs/2403.00513,2024-03-01,The non-first-order-factorizable contributions to the three-loop single-mass operator matrix elements $A_{Qg}^{(3)}$ and $ÎA_{Qg}^{(3)}$,"['J. Ablinger', 'A. Behring', 'J. BlÃ¼mlein', 'A. De Freitas', 'A. von Manteuffel', 'C. Schneider', 'K. SchÃ¶nwald']","The non-first-order-factorizable contributions (The terms 'first-order-factorizable contributions' and 'non-first-order-factorizable contributions' have been introduced and discussed in Refs. \cite{Behring:2023rlq,Ablinger:2023ahe}. They describe the factorization behaviour of the difference- or differential equations for a subset of master integrals of a given problem.) to the unpolarized and polarized massive operator matrix elements to three-loop order, $A_{Qg}^{(3)}$ and $ÎA_{Qg}^{(3)}$, are calculated in the single-mass case. For the $_2F_1$-related master integrals of the problem, we use a semi-analytic method based on series expansions and utilize the first-order differential equations for the master integrals which does not need a special basis of the master integrals. Due to the singularity structure of this basis a part of the integrals has to be computed to $O(\varepsilon^5)$ in the dimensional parameter. The solutions have to be matched at a series of thresholds and pseudo-thresholds in the region of the Bjorken variable $x \in ]0,\infty[$ using highly precise series expansions to obtain the imaginary part of the physical amplitude for $x \in ]0,1]$ at a high relative accuracy. We compare the present results both with previous analytic results, the results for fixed Mellin moments, and a prediction in the small-$x$ region. We also derive expansions in the region of small and large values of $x$. With this paper, all three-loop single-mass unpolarized and polarized operator matrix elements are calculated."
https://arxiv.org/abs/2403.00512,2024-03-01,Cloud properties across spatial scales in simulations of the interstellar medium,"['Tine Colman', 'NoÃ© Brucy', 'Philipp Girichidis', 'Simon C. O Glover', 'Milena Benedettini', 'Juan D. Soler', 'Robin G. Tress', 'Alessio Traficante', 'Patrick Hennebelle', 'Ralf S. Klessen', 'Sergio Molinari', 'Marc-Antoine Miville-DeschÃªnes']","Molecular clouds (MC) are structures of dense gas in the interstellar medium (ISM), that extend from ten to a few hundred parsecs and form the main gas reservoir available for star formation. Hydrodynamical simulations of varying complexity are a promising way to investigate MC evolution and their properties. However, each simulation typically has a limited range in resolution and different cloud extraction algorithms are used, which complicates the comparison between simulations. In this work, we aim to extract clouds from different simulations covering a wide range of spatial scales. We compare their properties, such as size, shape, mass, internal velocity dispersion and virial state. We apply the Hop cloud detection algorithm on (M)HD numerical simulations of stratified ISM boxes and isolated galactic disk simulations that were produced using Flash Ramses and Arepo We find that the extracted clouds are complex in shape ranging from round objects to complex filamentary networks in all setups. Despite the wide range of scales, resolution, and sub-grid physics, we observe surprisingly robust trends in the investigated metrics. The mass spectrum matches in the overlap between simulations without rescaling and with a high-mass slope of $\mathrm{d} N/\mathrm{d}\ln M\propto-1$ in accordance with theoretical predictions. The internal velocity dispersion scales with the size of the cloud as $Ï\propto R^{0.75}$ for large clouds ($R\gtrsim3\,\mathrm{pc}$). For small clouds we find larger sigma compared to the power-law scaling, as seen in observations, which is due to supernova-driven turbulence. Almost all clouds are gravitationally unbound with the virial parameter scaling as $Î±_\mathrm{vir}\propto M^{-0.4}$, which is slightly flatter compared to observed scaling, but in agreement given the large scatter."
https://arxiv.org/abs/2403.00511,2024-03-01,Testing the presence of QGP in small systems using (multi-)strange hadron correlations with a $Ï$ meson,"['Christian Bierlich', 'Stefano Cannito', 'Valentina Zaccolo']","The study delves into the enhanced production of strange and multi-strange hadrons in proton-proton collisions at LHC. Novel observables are proposed to distinguish between models describing existing data with or without the assumption of a QGP. Two models are explored: EPOS4, based on core-corona separation between a QGP phase and a vacuum phase, and PYTHIA 8.3, based on microscopic interactions between Lund strings. The observables are based on an event selection requiring the presence of a $Ï$ meson. Correlations between the $Ï$ and (multi-)strange hadrons are shown to be an excellent discriminator between the two types of models. These observations emphasize the need for further testing in upcoming LHC Runs, leveraging improved detectors and increased data collection."
https://arxiv.org/abs/2403.00510,2024-03-01,"ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models","['Bo Li', 'Qinghua Zhao', 'Lijie Wen']","Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and variance, just to name a few."
https://arxiv.org/abs/2403.00509,2024-03-01,Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese,"['Yuqi Chen', 'Sixuan Li', 'Ying Li', 'Mohammad Atari']","In this work, we develop a pipeline for historical-psychological text analysis in classical Chinese. Humans have produced texts in various languages for thousands of years; however, most of the computational literature is focused on contemporary languages and corpora. The emerging field of historical psychology relies on computational techniques to extract aspects of psychology from historical corpora using new methods developed in natural language processing (NLP). The present pipeline, called Contextualized Construct Representations (CCR), combines expert knowledge in psychometrics (i.e., psychological surveys) with text representations generated via transformer-based language models to measure psychological constructs such as traditionalism, norm strength, and collectivism in classical Chinese corpora. Considering the scarcity of available data, we propose an indirect supervised contrastive learning approach and build the first Chinese historical psychology corpus (C-HI-PSY) to fine-tune pre-trained models. We evaluate the pipeline to demonstrate its superior performance compared with other approaches. The CCR method outperforms word-embedding-based approaches across all of our tasks and exceeds prompting with GPT-4 in most tasks. Finally, we benchmark the pipeline against objective, external data to further verify its validity."
https://arxiv.org/abs/2403.00508,2024-03-01,Changepoint problem with angular data using a measure of variation based on the intrinsic geometry of torus,"['Surojit Biswas', 'Buddhananda Banerjee', 'Arnab Kumar Laha']","In many temporally ordered data sets, it is observed that the parameters of the underlying distribution change abruptly at unknown times. The detection of such changepoints is important for many applications. While this problem has been studied substantially in the linear data setup, not much work has been done for angular data. In this article, we utilize the intrinsic geometry of a torus to introduce the notion of the `square of an angle' and use it to propose a new measure of variation, called the `curved variance', of an angular random variable. Using the above ideas, we propose new tests for the existence of changepoint(s) in the concentration, mean direction, and/or both of these. The limiting distributions of the test statistics are derived and their powers are obtained using extensive simulation. It is seen that the tests have better power than the corresponding existing tests. The proposed methods have been implemented on three real-life data sets revealing interesting insights. In particular, our method when used to detect simultaneous changes in mean direction and concentration for hourly wind direction measurements of the cyclonic storm `Amphan' identified changepoints that could be associated with important meteorological events."
https://arxiv.org/abs/2403.00507,2024-03-01,Molecular unfolding formulation with enhanced quantum annealing approach,"['Arit Kumar Bishwas', 'Arish Pitchai', 'Anuraj Som']","Molecular docking is a crucial phase in drug discovery, involving the precise determination of the optimal spatial arrangement between two molecules when they bind. The such analysis, the 3D structure of molecules is a fundamental consideration, involving the manipulation of molecular representations based on their degrees of freedom, including rigid roto-translation and fragment rotations along rotatable bonds, to determine the preferred spatial arrangement when molecules bind to each other. In this paper, quantum annealing based solution to solve Molecular unfolding (MU) problem, a specific phase within molecular docking, is explored and compared with a state-of-the-art classical algorithm named ""GeoDock"". Molecular unfolding focuses on expanding a molecule to an unfolded state to simplify manipulation within the target cavity and optimize its configuration, typically by maximizing molecular area or internal atom distances. Molecular unfolding problem aims to find the torsional configuration that increases the inter-atomic distance within a molecule, which also increases the molecular area. Quantum annealing approach first encodes the problem into a Higher-order Unconstrained Binary Optimization (HUBO) equation which is pruned to an arbitrary percentage to improve the time efficiency and to be able to solve the equation using any quantum annealer. The resultant HUBO is then converted to a Quadratic Unconstrained Binary Optimization equation (QUBO), which is easily embedded on a D-wave annealing Quantum processor."
https://arxiv.org/abs/2403.00506,2024-03-01,PoTeC: A German Naturalistic Eye-tracking-while-reading Corpus,"['Deborah N. Jakobi', 'Thomas Kern', 'David R. Reich', 'Patrick Haller', 'Lena A. JÃ¤ger']",The Potsdam Textbook Corpus (PoTeC) is a naturalistic eye-tracking-while-reading corpus containing data from 75 participants reading 12 scientific texts. PoTeC is the first naturalistic eye-tracking-while-reading corpus that contains eye-movements from domain-experts as well as novices in a within-participant manipulation: It is based on a 2x2x2 fully-crossed factorial design which includes the participants' level of study and the participants' discipline of study as between-subject factors and the text domain as a within-subject factor. The participants' reading comprehension was assessed by a series of text comprehension questions and their domain knowledge was tested by text-independent background questions for each of the texts. The materials are annotated for a variety of linguistic features at different levels. We envision PoTeC to be used for a wide range of studies including but not limited to analyses of expert and non-expert reading strategies. The corpus and all the accompanying data at all stages of the preprocessing pipeline and all code used to preprocess the data are made available via GitHub: https://github.com/DiLi-Lab/PoTeC.
https://arxiv.org/abs/2403.00505,2024-03-01,A Cluster-Based Statistical Channel Model for Integrated Sensing and Communication Channels,"['Zhengyu Zhang', 'Ruisi He', 'Bo Ai', 'Mi Yang', 'Yong Niu', 'Zhangdui Zhong', 'Yujian Li', 'Xuejian Zhang', 'Jing Li']","The emerging 6G network envisions integrated sensing and communication (ISAC) as a promising solution to meet growing demand for native perception ability. To optimize and evaluate ISAC systems and techniques, it is crucial to have an accurate and realistic wireless channel model. However, some important features of ISAC channels have not been well characterized, for example, most existing ISAC channel models consider communication channels and sensing channels independently, whereas ignoring correlation under the consistent environment. Moreover, sensing channels have not been well modeled in the existing standard-level channel models. Therefore, in order to better model ISAC channel, a cluster-based statistical channel model is proposed in this paper, which is based on measurements conducted at 28 GHz. In the proposed model, a new framework based on 3GPP standard is proposed, which includes communication clusters and sensing clusters. Clustering and tracking algorithms are used to extract and analyze ISAC channel characteristics. Furthermore, some special sensing cluster structures such as shared sensing cluster, newborn sensing cluster, etc., are defined to model correlation and difference between communication and sensing channels. Finally, accuracy of the proposed model is validated based on measurements and simulations."
https://arxiv.org/abs/2403.00504,2024-03-01,Learning and Leveraging World Models in Visual Representation Learning,"['Quentin Garrido', 'Mahmoud Assran', 'Nicolas Ballas', 'Adrien Bardes', 'Laurent Najman', 'Yann LeCun']","Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling."
https://arxiv.org/abs/2403.00503,2024-03-01,Granular Aluminum kinetic inductance nonlinearity,"['M. Zhdanova', 'I. Pologov', 'G. Svyatsky', 'V. Chichkov', 'N. Maleeva']","Granular Aluminum is a superconductor known for more than eighty years, which recently found its application in qubits, microwave detectors and compact resonators, due to its high kinetic inductance, critical magnetic field and critical current. Here we report on the nonlinear dependence of granular Aluminum inductance on current, which hints towards parametric amplification of the microwave signal in granular Aluminum films. The phase shift of the microwave signal reached 4 radians at a frequency of 7 GHz, which makes it possible to estimate the nonlinearity of the system as 1.4 % and the potential gain of the order of 17 dB"
https://arxiv.org/abs/2403.00502,2024-03-01,Constraining the abundance of Galactic compact objects with continuous gravitational waves,"['Gopalkrishna Prabhu', 'Aditya Kumar Sharma', 'R. Prasad', 'Shasvath J. Kapadia']","Galactic spinning compact objects (COs) with non-zero ellipticity are expected to be sources of continuous gravitational waves (CGWs). Certain classes of hypothetical COs, such as neutron stars with quark cores (hybrid stars), and quark stars, are thought to be capable of sustaining large ellipticities from theoretical considerations. Such exotic COs (eCOs) with large ellipticities should produce CGWs detectable by the current LIGO-Virgo-Kagra GW detector network. Since no detections for CGWs, from searches in LIGO-Virgo data, have so far been reported, we place constraints on the abundance of highly elliptical eCOs in our Galaxy. We formulate a Bayesian framework to place upper limits on the number count $N_{tot}$ of highly deformed Galactic eCOs. We divide our constraints into two classes: an ""agnostic"" set of upper limits on $N_{tot}$ evaluated on a CGW frequency and ellipticity grid that depend only on the choice of spatial distribution of COs; and a model-dependent set that additionally assumes prior information on the distribution of frequencies. We find that COs with ellipticities $Îµ\gtrsim 10^{-5}$ have abundance upper limits at $90\%$ confidence, of $N_{tot}^{90\%} \lesssim 100$, and those with $Îµ\gtrsim 10^{-6}$ have $N_{tot}^{90\%} \lesssim 10^4$. We additionally place upper-limits on the ellipticity of Galactic COs informed by our choices of spatial distributions, given different abundances $N_{tot}$."
https://arxiv.org/abs/2403.00501,2024-03-01,Pair correlation function of vorticity in a coherent vortex,"['I. V. Kolokolov', 'V. V. Lebedev', 'M. M. Tumakova']","We study the correlations of vorticity fluctuations inside a coherent vortex resulting from the inverse energy cascade in two-dimensional turbulence. The presence of a coherent flow, which is a differential rotation, suppresses small-scale fluctuations of the flow, which are created by an external force, and lead to the fact that these fluctuations can be considered as non-interacting and, therefore, examined in a linear approximation. We calculate the pair correlation function of vorticity and demonstrate that it has a power-law behavior both in space and in time. The obtained results allow us to start a systematic study of the effects associated with the nonlinear interaction of fluctuations, which play an essential role on the periphery of a coherent vortex. Our results are also applicable to the statistics of a passive scalar in a strong shear flow."
https://arxiv.org/abs/2403.00500,2024-03-01,On the height of some generators of galois extensions with big galois group,['Jenvrin Jonathan'],"We study the height of generators of Galois extensions of the rationals having the alternating group $\mathfrak{A}_n$ as Galois group. We prove that if such generators are obtained from certain, albeit classical, constructions, their height tends to infinity as $n$ increases. This provides an analogue of a result by Amoroso, originally established for the symmetric group."
https://arxiv.org/abs/2403.00499,2024-03-01,Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition,"['Ariel Goldstein', 'Gabriel Stanovsky']","Recent advances in LLMs have sparked a debate on whether they understand text. In this position paper, we argue that opponents in this debate hold different definitions for understanding, and particularly differ in their view on the role of consciousness. To substantiate this claim, we propose a thought experiment involving an open-source chatbot $Z$ which excels on every possible benchmark, seemingly without subjective experience. We ask whether $Z$ is capable of understanding, and show that different schools of thought within seminal AI research seem to answer this question differently, uncovering their terminological disagreement. Moving forward, we propose two distinct working definitions for understanding which explicitly acknowledge the question of consciousness, and draw connections with a rich literature in philosophy, psychology and neuroscience."
https://arxiv.org/abs/2403.00498,2024-03-01,Spectral analysis of a class of linear hyperbolic partial differential equations,"['Anthony Hastir', 'Birgit Jacob', 'Hans Zwart']","A class of linear hyperbolic partial differential equations, sometimes called networks of waves, is considered. For this class of systems, necessary and sufficient conditions are formulated for the operator dynamics to generate a $C_0$-group. This property turns out to be equivalent to the Riesz-spectral nature of that operator. In that case, its spectrum is computed explicitly, leading to easily checkable stability conditions. We apply our results to characterize exponential stability of a co-current heat exchanger."
https://arxiv.org/abs/2403.00497,2024-03-01,"Graph Homomorphism, Monotone Classes and Bounded Pathwidth","['Tala Eagling-Vose', 'Barnaby Martin', 'Daniel Paulusma', 'Mark Siggers', 'Siani Smith']","A recent paper describes a framework for studying the computational complexity of graph problems on monotone classes, that is those omitting a set of graphs as a subgraph. If the problems lie in the framework, and many do, then the computational complexity can be described for all monotone classes defined by a finite set of omitted subgraphs. It is known that certain homomorphism problems, e.g. $C_5$-Colouring, do not sit in the framework. By contrast, we show that the more general problem of Graph Homomorphism does sit in the framework."
https://arxiv.org/abs/2403.00496,2024-03-01,Benchmarking reconstructive spectrometer with multi-resonant cavities,"['Chunhui Yao', 'Kangning Xu', 'Tianhua Lin', 'Jie Ma', 'Chumeng Yao', 'Peng Bao', 'Zhitian Shi', 'Richard Penty', 'Qixiang Cheng']","Recent years have seen the rapid development of miniaturized reconstructive spectrometers (RSs), yet they still confront a range of technical challenges, such as bandwidth/resolution ratio, sensing speed, and/or power efficiency. Reported RS designs often suffer from insufficient decorrelation between sampling channels, which results in limited compressive sampling efficiency, in essence, due to inadequate engineering of sampling responses. This in turn leads to poor spectral-pixel-to-channel ratios (SPCRs), typically restricted at single digits. So far, there lacks a general guideline for manipulating RS sampling responses for the effectiveness of spectral information acquisition. In this study, we shed light on a fundamental parameter from the compressive sensing theory - the average mutual correlation coefficient v - and provide insight into how it serves as a critical benchmark in RS design with regards to the SPCR and reconstruction accuracy. To this end, we propose a novel RS design with multi-resonant cavities, consisting of a series of partial reflective interfaces. Such multi-cavity configuration offers an expansive parameter space, facilitating the superlative optimization of sampling matrices with minimized v. As a proof-of-concept demonstration, a single-shot, dual-band RS is implemented on a SiN platform, tailored for capturing signature spectral shapes across different wavelength regions, with customized photonic crystal nanobeam mirrors. Experimentally, the device demonstrates an overall operation bandwidth of 270 nm and a <0.5 nm resolution with only 15 sampling channels per band, leading to a record high SPCR of 18.0. Moreover, the proposed multi-cavity design can be readily adapted to various photonic platforms. For instance, we showcase that by employing multi-layer coatings, an ultra-broadband RS can be optimized to exhibit a 700 nm bandwidth with an SPCR of over 100."
https://arxiv.org/abs/2403.00495,2024-03-01,Low-temperature aqueous solution growth of the acousto-optic TeO2 single crystals,"['Lu Han', 'Chao Liu', 'Xiaoli Wang', 'Feiyu Li', 'Chuanyan Fan', 'Junjie Zhang']","$Î±$-TeO2 is widely used in acousto-optic devices due to its excellent physical properties. Conventionally, $Î±$-TeO2 single crystals were grown using melt methods. Here, we report for the first time the growth of $Î±$-TeO2 single crystals using the aqueous solution method below 100 Â°C. Solubility curve of $Î±$-TeO2 was measured, and then single crystals with dimensions of 3.5x3.5x2.5 mm3 were successfully grown using seed crystals that were synthesized from spontaneous nucleation. The as-grown single crystals belong to the P41212 space group, evidenced by single crystal X-ray diffraction and Rietveld refinement on powder diffraction. Rocking curve measurements show that the as-grown crystals exhibit high crystallinity with a full-width at half maxima (FWHM) of 57.2''. Ultraviolet-Visible absorption spectroscopy indicates the absorption edge is 350 nm and the band gap is estimated to be 3.58 eV. The density and Vickers hardness of as-grown single crystals are measured to be 6.042 g/cm3 and 404 kg/mm2, repectively. Our findings provide an easy-to-access and energy-saving method for growing single crystals of inorganic compounds."
https://arxiv.org/abs/2403.00494,2024-03-01,Nonlinear optical responses in superconductors under magnetic fields: quantum geometry and topological superconductivity,"['Hiroto Tanaka', 'Hikaru Watanabe', 'Youichi Yanase']","Noncentrosymmetric superconductors offer fascinating phenomena of quantum transport and optics such as nonreciprocal and nonlinear responses. Time-reversal symmetry breaking often plays an essential role in the emergence and enhancement of nonreciprocal transport. In this paper, we show the nonreciprocal optical responses in noncentrosymmetric superconductors arising from time-reversal symmetry breaking by demonstrating them in $s$-wave superconductors with a Rashba spin-orbit coupling and a magnetic field. Numerical results reveal the superconductivity-induced bulk photocurrent and second harmonic generation, which are forbidden at the zero magnetic field. We discuss the properties and mechanisms of the superconducting nonlinear responses emerging under the magnetic field. In particular, we investigate the magnetic-field dependence of the photocurrent conductivity and clarify the essential ingredients which give a contribution unique to superconductors under the magnetic field. This contribution is dominant in the low carrier density regime although the corresponding joint density of states is tiny. We attribute the enhancement to the quantum geometry. Moreover, the nonlinear conductivity shows peculiar sign reversal at the transition to the topological superconducting state. We propose a bulk probe of topological transition and quantum geometry in superconductors."
https://arxiv.org/abs/2403.00493,2024-03-01,Investigation of spin excitations and charge order in bulk crystals of the infinite-layer nickelate LaNiO$_2$,"['S. Hayashida', 'V. Sundaramurthy', 'P. Puphal', 'M. Garcia-Fernandez', 'Ke-Jin Zhou', 'B. Fenk', 'M. Isobe', 'M. Minola', 'Y. -M. Wu', 'Y. E. Suyolcu', 'P. A. van Aken', 'B. Keimer', 'M. Hepting']","Recent x-ray spectroscopic studies have revealed spin excitations and charge density waves in thin films of infinite-layer (IL) nickelates. However, clarifying whether the origin of these phenomena is intrinsic to the material class or attributable to impurity phases in the films has presented a major challenge. Here we utilize topotactic methods to synthesize bulk crystals of the IL nickelate LaNiO$_2$ with crystallographically oriented surfaces. We examine these crystals using resonant inelastic x-ray scattering (RIXS) at the Ni $L_3$-edge to elucidate the spin and charge correlations in the bulk of the material. While we detect the presence of prominent spin excitations in the crystals, fingerprints of charge order are absent at the ordering vectors identified in previous in thin-film studies. These results contribute to the understanding of the bulk properties of LaNiO$_2$ and establish topotactically synthesized crystals as viable complementary specimens for spectroscopic investigations."
https://arxiv.org/abs/2403.00492,2024-03-01,Manifolds realized as orbit spaces of non-free $\mathbb Z_2^k$-actions on real moment-angle manifolds,['Nikolai Erokhovets'],"We consider (non-necessarily free) actions of subgroups $H\subset \mathbb Z_2^m$ on the real moment-angle manifold $\mathbb R\mathcal{Z}_P$ corresponding to a simple convex $n$ polytope $P$ with $m$ facets. The criterion when the orbit space $\mathbb R\mathcal{Z}_P/H$ is a topological manifold (perhaps with a boundary) can be extracted from results by M.A. Mikhailova and C. Lange. For any dimension $n$ we construct series of manifolds $\mathbb R\mathcal{Z}_P/H$ homeomorphic to $S^n$ and series of manifolds $M^n=\mathbb R\mathcal{Z}_P/H$ admitting a hyperelliptic involution $Ï\in\mathbb Z_2^m/H$, that is an involution $Ï$ such that $M^n/\langleÏ\rangle$ is homeomorphic to $S^n$. For any $3$-polytope $P$ we classify all subgroups $H\subset\mathbb Z_2^m$ such that $\mathbb R\mathcal{Z}_P/H$ is a $3$-sphere or a rational homology $3$-sphere. For any $3$-polytope $P$ and any subgroup $H\subset\mathbb Z_2^m$ we classify all hyperelliptic involutions $Ï\in\mathbb Z_2^m/H$ acting on $\mathbb R\mathcal{Z}_P/H$. As a corollary we obtain that a $3$-dimensional small cover has $3$ hyperelliptic involutions in $\mathbb Z_2^3$ if and only if it is a rational homology $3$-sphere and if and only if it correspond to a triple of Hamiltonian cycles such that each edge of the polytope belongs to exactly two of them."
https://arxiv.org/abs/2403.00491,2024-03-01,Analyzing Divergence for Nondeterministic Probabilistic Models,"['Hao Wu', 'Yuxi Fu', 'Huan Long', 'Xian Xu', 'Wenbo Zhang']","Branching and weak probabilistic bisimilarities are two well-known notions capturing behavioral equivalence between nondeterministic probabilistic systems. For probabilistic systems, divergence is of major concern. Recently several divergence-sensitive refinements of branching and weak probabilistic bisimilarities have been proposed in the literature. Both the definitions of these equivalences and the techniques to investigate them differ significantly. This paper presents a comprehensive comparative study on divergence-sensitive behavioral equivalence relations that refine the branching and weak probabilistic bisimilarities. Additionally, these equivalence relations are shown to have efficient checking algorithms. The techniques of this paper might be of independent interest in a more general setting."
https://arxiv.org/abs/2403.00490,2024-03-01,Quijote-PNG: Optimizing the summary statistics to measure Primordial non-Gaussianity,"['Gabriel Jung', 'Andrea Ravenni', 'Michele Liguori', 'Marco Baldi', 'William R. Coulton', 'Francisco Villaescusa-Navarro', 'Benjamin D. Wandelt']","We apply a suite of different estimators to the Quijote-PNG halo catalogues to find the best approach to constrain Primordial non-Gaussianity (PNG) at non-linear cosmological scales, up to $k_{\rm max} = 0.5 \, h\,{\rm Mpc}^{-1}$. The set of summary statistics considered in our analysis includes the power spectrum, bispectrum, halo mass function, marked power spectrum, and marked modal bispectrum. Marked statistics are used here for the first time in the context of PNG study. We perform a Fisher analysis to estimate their cosmological information content, showing substantial improvements when marked observables are added to the analysis. Starting from these summaries, we train deep neural networks (NN) to perform likelihood-free inference of cosmological and PNG parameters. We assess the performance of different subsets of summary statistics; in the case of $f_\mathrm{NL}^\mathrm{equil}$, we find that a combination of the power spectrum and a suitable marked power spectrum outperforms the combination of power spectrum and bispectrum, the baseline statistics usually employed in PNG analysis. A minimal pipeline to analyse the statistics we identified can be implemented either with our ML algorithm or via more traditional estimators, if these are deemed more reliable."
https://arxiv.org/abs/2403.00489,2024-03-01,Multiple Ways of Working with Users to Develop Physically Assistive Robots,"['Amal Nanavati', 'Max Pascher', 'Vinitha Ranganeni', 'Ethan K. Gordon', 'Taylor Kessler Faulkner', 'Siddhartha S. Srinivasa', 'Maya Cakmak', 'PatrÃ­cia Alves-Oliveira', 'Jens Gerken']","Despite the growth of physically assistive robotics (PAR) research over the last decade, nearly half of PAR user studies do not involve participants with the target disabilities. There are several reasons for this -- recruitment challenges, small sample sizes, and transportation logistics -- all influenced by systemic barriers that people with disabilities face. However, it is well-established that working with end-users results in technology that better addresses their needs and integrates with their lived circumstances. In this paper, we reflect on multiple approaches we have taken to working with people with motor impairments across the design, development, and evaluation of three PAR projects: (a) assistive feeding with a robot arm; (b) assistive teleoperation with a mobile manipulator; and (c) shared control with a robot arm. We discuss these approaches to working with users along three dimensions -- individual- vs. community-level insight, logistic burden on end-users vs. researchers, and benefit to researchers vs. community -- and share recommendations for how other PAR researchers can incorporate users into their work."
https://arxiv.org/abs/2403.00488,2024-03-01,Inferring solar differential rotation and viscosity via passive imaging with inertial waves,"['Tram Thi Ngoc Nguyen', 'Thorsten Hohage', 'Damien Fournier', 'Laurent Gizon']","The recent discovery of inertial waves on the surface of the Sun offers new possibilities to learn about the solar interior. These waves are long-lived with a period on the order of the Sun rotation period ($\sim$27 days) and are sensitive to parameters deep inside the Sun. They are excited by turbulent convection, leading to a passive imaging problem. In this work, we present the forward and inverse problem of reconstructing viscosity and differential rotation on the Sun from cross-covariance observations of these inertial waves."
https://arxiv.org/abs/2403.00487,2024-03-01,The total absolute curvature of closed curves with singularities,"['Atsufumi Honda', 'Chisa Tanaka', 'Yuta Yamauchi']","In this paper, we give a generalization of Fenchel's theorem for closed curves as frontals in Euclidean space $\mathbb{R}^n$. We prove that, for a non-co-orientable closed frontal in $\mathbb{R}^n$, its total absolute curvature is greater than or equal to $Ï$. It is equal to $Ï$ if and only if the curve is a planar locally $L$-convex closed frontal whose rotation index is $1/2$ or $-1/2$. Furthermore, if the equality holds and if every singular point is a cusp, then the number $N$ of cusps is an odd integer greater than or equal to $3$, and $N=3$ holds if and only if the curve is simple."
https://arxiv.org/abs/2403.00486,2024-03-01,Selective-Stereo: Adaptive Frequency Information Selection for Stereo Matching,"['Xianqi Wang', 'Gangwei Xu', 'Hao Jia', 'Xin Yang']","Stereo matching methods based on iterative optimization, like RAFT-Stereo and IGEV-Stereo, have evolved into a cornerstone in the field of stereo matching. However, these methods struggle to simultaneously capture high-frequency information in edges and low-frequency information in smooth regions due to the fixed receptive field. As a result, they tend to lose details, blur edges, and produce false matches in textureless areas. In this paper, we propose Selective Recurrent Unit (SRU), a novel iterative update operator for stereo matching. The SRU module can adaptively fuse hidden disparity information at multiple frequencies for edge and smooth regions. To perform adaptive fusion, we introduce a new Contextual Spatial Attention (CSA) module to generate attention maps as fusion weights. The SRU empowers the network to aggregate hidden disparity information across multiple frequencies, mitigating the risk of vital hidden disparity information loss during iterative processes. To verify SRU's universality, we apply it to representative iterative stereo matching methods, collectively referred to as Selective-Stereo. Our Selective-Stereo ranks $1^{st}$ on KITTI 2012, KITTI 2015, ETH3D, and Middlebury leaderboards among all published methods. Code is available at https://github.com/Windsrain/Selective-Stereo."
https://arxiv.org/abs/2403.00485,2024-03-01,"A Survey of Geometric Graph Neural Networks: Data Structures, Models and Applications","['Jiaqi Han', 'Jiacheng Cen', 'Liming Wu', 'Zongzhao Li', 'Xiangzhe Kong', 'Rui Jiao', 'Ziyang Yu', 'Tingyang Xu', 'Fandi Wu', 'Zihe Wang', 'Hongteng Xu', 'Zhewei Wei', 'Yang Liu', 'Yu Rong', 'Wenbing Huang']","Geometric graph is a special kind of graph with geometric features, which is vital to model many scientific problems. Unlike generic graphs, geometric graphs often exhibit physical symmetries of translations, rotations, and reflections, making them ineffectively processed by current Graph Neural Networks (GNNs). To tackle this issue, researchers proposed a variety of Geometric Graph Neural Networks equipped with invariant/equivariant properties to better characterize the geometry and topology of geometric graphs. Given the current progress in this field, it is imperative to conduct a comprehensive survey of data structures, models, and applications related to geometric GNNs. In this paper, based on the necessary but concise mathematical preliminaries, we provide a unified view of existing models from the geometric message passing perspective. Additionally, we summarize the applications as well as the related datasets to facilitate later research for methodology development and experimental evaluation. We also discuss the challenges and future potential directions of Geometric GNNs at the end of this survey."
https://arxiv.org/abs/2403.00484,2024-03-01,BMO-type functionals related to the total variation and connection to denoising models,"['Serena Guarino Lo Bianco', 'Roberta Schiattarella']","The purpose of this paper is to analyze the asymptotic behaviour in the spirit of $Î$-convergence of BMO-type functionals related to the total variation of a function $u$. Moreover, we deal with a minimization problem coming from applications in image processing."
https://arxiv.org/abs/2403.00483,2024-03-01,RealCustom: Narrowing Real Text Word for Real-Time Open-Domain Text-to-Image Customization,"['Mengqi Huang', 'Zhendong Mao', 'Mingcong Liu', 'Qian He', 'Yongdong Zhang']","Text-to-image customization, which aims to synthesize text-driven images for the given subjects, has recently revolutionized content creation. Existing works follow the pseudo-word paradigm, i.e., represent the given subjects as pseudo-words and then compose them with the given text. However, the inherent entangled influence scope of pseudo-words with the given text results in a dual-optimum paradox, i.e., the similarity of the given subjects and the controllability of the given text could not be optimal simultaneously. We present RealCustom that, for the first time, disentangles similarity from controllability by precisely limiting subject influence to relevant parts only, achieved by gradually narrowing real text word from its general connotation to the specific subject and using its cross-attention to distinguish relevance. Specifically, RealCustom introduces a novel ""train-inference"" decoupled framework: (1) during training, RealCustom learns general alignment between visual conditions to original textual conditions by a novel adaptive scoring module to adaptively modulate influence quantity; (2) during inference, a novel adaptive mask guidance strategy is proposed to iteratively update the influence scope and influence quantity of the given subjects to gradually narrow the generation of the real text word. Comprehensive experiments demonstrate the superior real-time customization ability of RealCustom in the open domain, achieving both unprecedented similarity of the given subjects and controllability of the given text for the first time. The project page is https://corleone-huang.github.io/realcustom/."
https://arxiv.org/abs/2403.00482,2024-03-01,Implicit high-order gas-kinetic schemes for compressible flows on three-dimensional unstructured meshes II: unsteady flows,"['Yaqing Yang', 'Liang Pan', 'Kun Xu']","For the simulations of unsteady flow, the global time step becomes really small with a large variation of local cell size. In this paper, an implicit high-order gas-kinetic scheme (HGKS) is developed to remove the restrictions on the time step for unsteady simulations. In order to improve the efficiency and keep the high-order accuracy, a two-stage third-order implicit time-accurate discretization is proposed. In each stage, an artificial steady solution is obtained for the implicit system with the pseudo-time iteration. In the iteration, the classical implicit methods are adopted to solve the nonlinear system, including the lower-upper symmetric Gauss-Seidel (LUSGS) and generalized minimum residual (GMRES) methods. To achieve the spatial accuracy, the HGKSs with both non-compact and compact reconstructions are constructed. For the non-compact scheme, the weighted essentially non-oscillatory (WENO) reconstruction is used. For the compact one, the Hermite WENO (HWENO) reconstruction is adopted due to the updates of both cell-averaged flow variables and their derivatives. The expected third-order temporal accuracy is achieved with the two-stage temporal discretization. For the smooth flow, only a single artificial iteration is needed. For uniform meshes, the efficiency of the current implicit method improves significantly in comparison with the explicit one. For the flow with discontinuities, compared with the well-known Crank-Nicholson method, the spurious oscillations in the current schemes are well suppressed. The increase of the artificial iteration steps introduces extra reconstructions associating with a reduction of the computational efficiency. Overall, the current implicit method leads to an improvement in efficiency over the explicit one in the cases with a large variation of mesh size."
https://arxiv.org/abs/2403.00481,2024-03-01,Quantum symmetry in multigraphs (part II),"['Debashish Goswami', 'Sk Asfaq Hossain']","This article is a continuation of ""Quantum symmetry in multigraphs (part I)"". In this article, we give an explicit construction of a non-Bichon type co-action on a multigraph that is, it preserves quantum symmetry of (V,E) in our sense but not always in Bichon's sense. This construction itself is motivated from automorphisms of quantum graphs."
https://arxiv.org/abs/2403.00480,2024-03-01,Markov processes with jump kernels decaying at the boundary,"['Soobin Cho', 'Panki Kim', 'Renming Song', 'Zoran VondraÄek']",The goal of this work is to develop a general theory for non-local singular operators of the type $$
https://arxiv.org/abs/2403.00479,2024-03-01,Observational Evidence for Hot Wind Impact on pc-scale in Low-luminosity Active Galactic Nucleus,"['Fangzheng Shi', 'Feng Yuan', 'Zhiyuan Li', 'Zhao Su', 'Suoqing Ji']","Supermassive black holes in galaxies spend majority of their lifetime in the low-luminosity regime, powered by hot accretion flow. Strong winds launched from the hot accretion flow have the potential to play an important role in active galactic nuclei (AGN) feedback. Direct observational evidence for these hot winds with temperature around 10 keV, has been obtained through the detection of highly ionized iron emission lines with Doppler shifts in two prototypical low-luminosity AGNs, namely M81* and NGC 7213. In this work, we further identify blueshifted H-like O/Ne emission lines in the soft X-ray spectra of these two sources. These lines are interpreted to be associated with additional outflowing components possessing velocity around several $10^3$ km/s and lower temperature (~0.2-0.4 keV). Blue-shifted velocity and the X-ray intensity of these additional outflowing components are hard to be explained by previously detected hot wind freely propagating to larger radii. Through detailed numerical simulations, we find the newly detected blue-shifted emission lines would come from circumnuclear gas shock-heated by the hot wind instead. Hot wind can provide larger ram pressure force on the clumpy circumnuclear gas than the gravitational force from central black hole, effectively impeding the black hole accretion of gas. Our results provide strong evidences for the energy and momentum feedback by the hot AGN wind."
https://arxiv.org/abs/2403.00478,2024-03-01,Admissable sets do not exist for all parameters,['Luke Pebody'],"A cap set in $\mathbb{F}_3^n$ is a subset that contains no three elements adding to 0. Building on a construction of Edel, a recent paper of Tyrrell gave the first improvement to the lower bound for a size of a cap set in two decades showing that, for large enough $n$, there is always a cap set in $\mathbb{F}_3^n$ of size at least $2.218^n$. This was shown by constructing what is called an $I(11,7)$ admissible set."
https://arxiv.org/abs/2403.00477,2024-03-01,Robustness of the pyrochlore structure in rare-earth A2Ir2O7 iridates and pressure-induced structural transformation in IrO2,"['Daniel StaÅ¡ko', 'Kristina VlÃ¡Å¡kovÃ¡', 'Andrej Kancko', 'Daniel M. TÃ¶bbens', 'Dominik Daisenberger', 'Gaston Garbarino', 'Ross Harvey Colman', 'Milan Klicpera']","A comprehensive study of the structural properties of the heavily investigated rare-earth A2Ir2O7 series under extreme conditions is presented. The series is covered by studying iridates with A = Pr, Sm, Dy-Lu. Temperature- and pressure-dependent synchrotron X-ray powder diffraction experiments reveal robustness of the pyrochlore structure throughout the rare-earth series, down to 4 K and up to 20 GPa. The thermal expansivity and pressure compressibility are determined, including Debye temperature, bulk modulus and GrÃ¼neisen parameter. Temperature and pressure evolution of the fractional coordinate of oxygen at 48f Wyckoff position, the sole free atomic position parameter, is investigated and discussed regarding the antiferromagnetic ordering of the Ir magnetic moments. In addition, the pressure evolution of the crystal structure of an IrO2 minority phase is followed. The tetragonal rutile-type structure is orthorhombically distorted at 15 GPa, and the orthorhombic structure is not fully stabilised up to 20 GPa."
https://arxiv.org/abs/2403.00476,2024-03-01,TempCompass: Do Video LLMs Really Understand Videos?,"['Yuanxin Liu', 'Shicheng Li', 'Yi Liu', 'Yuxiang Wang', 'Shuhuai Ren', 'Lei Li', 'Sishuo Chen', 'Xu Sun', 'Lu Hou']","Recently, there is a surge in interest surrounding video large language models (Video LLMs). However, existing benchmarks fail to provide a comprehensive feedback on the temporal perception ability of Video LLMs. On the one hand, most of them are unable to distinguish between different temporal aspects (e.g., speed, direction) and thus cannot reflect the nuanced performance on these specific aspects. On the other hand, they are limited in the diversity of task formats (e.g., only multi-choice QA), which hinders the understanding of how temporal perception performance may vary across different types of tasks. Motivated by these two problems, we propose the \textbf{TempCompass} benchmark, which introduces a diversity of temporal aspects and task formats. To collect high-quality test data, we devise two novel strategies: (1) In video collection, we construct conflicting videos that share the same static content but differ in a specific temporal aspect, which prevents Video LLMs from leveraging single-frame bias or language priors. (2) To collect the task instructions, we propose a paradigm where humans first annotate meta-information for a video and then an LLM generates the instruction. We also design an LLM-based approach to automatically and accurately evaluate the responses from Video LLMs. Based on TempCompass, we comprehensively evaluate 8 state-of-the-art (SOTA) Video LLMs and 3 Image LLMs, and reveal the discerning fact that these models exhibit notably poor temporal perception ability. Our data will be available at \url{https://github.com/llyx97/TempCompass}."
https://arxiv.org/abs/2403.00475,2024-03-01,Torsion pairs via the Ziegler spectrum,"['Lidia Angeleri HÃ¼gel', 'Rosanna Laking', 'Francesco Sentieri']","We establish a bijection between torsion pairs in the category of finite-dimensional modules over a finite-dimensional algebra A and pairs (Z, I) formed by a closed rigid set Z in the Ziegler spectrum of A and a set I of indecomposable injective A-modules. This can be regarded as an extension of a result from $Ï$-tilting theory which parametrises the functorially finite torsion pairs over A. We also obtain a one-one-correspondence between finite-dimensional bricks and certain (possibly infinite-dimensional) indecomposable modules satisfying a rigidity condition. Our results also hold when A is an artinian ring."
https://arxiv.org/abs/2403.00474,2024-03-01,Volatility-based strategy on Chinese equity index ETF options,['Peng Yifeng'],"In recent years, there has been quick developments of derivative markets in China and standardized derivative trading have reached considerable volumes. In this research, we collect all the daily data of ETF options traded at Shanghai Stock Exchange and start with a simple short-volatility strategy. The strategy delivers nice performance before 2018, providing significant excess return over the buy and hold benchmark. However, after 2018, this strategy starts to deteriorate and no obvious risk-adjusted return is shown. Based on the discussion of relationship between the strategy's performance and market's volatility, we improve the model by adjusting positions and exposure according to volatility forecasts using methods such as volatility momentum and GARCH. The new models have improved performance in different ways, where larger upside capture and smaller drawbacks can be achieved in market fluctuation. This research has shown potentials of volatility-based trading on Chinese equity index options, and with further improvement and implementation considerations, real-world practical trading strategies can be formed."
https://arxiv.org/abs/2403.00473,2024-03-01,Computer-Controlled 3D Freeform Surface Weaving,"['Xiangjia Chen', 'Lip M. Lai', 'Zishun Liu', 'Chengkai Dai', 'Isaac C. W. Leung', 'Charlie C. L. Wang', 'Yeung Yam']","In this paper, we present a new computer-controlled weaving technology that enables the fabrication of woven structures in the shape of given 3D surfaces by using threads in non-traditional materials with high bending-stiffness, allowing for multiple applications with the resultant woven fabrics. A new weaving machine and a new manufacturing process are developed to realize the function of 3D surface weaving by the principle of short-row shaping. A computational solution is investigated to convert input 3D freeform surfaces into the corresponding weaving operations (indicated as W-code) to guide the operation of this system. A variety of examples using cotton threads, conductive threads and optical fibres are fabricated by our prototype system to demonstrate its functionality."
https://arxiv.org/abs/2403.00472,2024-03-01,Frailty or Frailties: Exploring Frailty Index Subdimensions in the English Longitudinal Study of Ageing,"['Lara Johnson', 'Bruce Guthrie', 'Paul A T Kelly', 'Atul Anand', 'Alan Marshall', 'Sohan Seth']","Background: Frailty, a state of increased vulnerability to adverse health outcomes, has garnered significant attention in research and clinical practice. Existing constructs aggregate clinical features or health deficits into a single score. While simple and interpretable, this approach may overlook the complexity of frailty and not capture the full range of variation between individuals."
https://arxiv.org/abs/2403.00471,2024-03-01,"Idiosyncratic Risk, Government Debt and Inflation",['Matthias HÃ¤nsel'],"How does public debt matter for price stability? If it is useful for the private sector to insure idiosyncratic risk, government debt expansions can increase the natural rate of interest and create inflation. As I demonstrate using a tractable model, this holds in the presence of an active Taylor rule and does not require the absence of future fiscal consolidation. Further analysis using a full-blown 2-asset HANK model reveals the quantitative magnitude of the mechanism to crucially depend on the structure of the asset market: under standard assumptions, the effect of public debt on the natural rate is either overly strong or overly weak. Employing a parsimonious way to overcome this issue, my framework suggests relevant effects of public debt on inflation under active monetary policy: In particular, persistently elevated public debt may make it harder to go the last ""mile of disinflation"" unless central banks explicitly take its effect on the neutral rate into account."
https://arxiv.org/abs/2403.00470,2024-03-01,Autonomous Robotic Arm Manipulation for Planetary Missions using Causal Machine Learning,"['C. McDonnell', 'M. Arana-Catania', 'S. Upadhyay']","Autonomous robotic arm manipulators have the potential to make planetary exploration and in-situ resource utilization missions more time efficient and productive, as the manipulator can handle the objects itself and perform goal-specific actions. We train a manipulator to autonomously study objects of which it has no prior knowledge, such as planetary rocks. This is achieved using causal machine learning in a simulated planetary environment. Here, the manipulator interacts with objects, and classifies them based on differing causal factors. These are parameters, such as mass or friction coefficient, that causally determine the outcomes of its interactions. Through reinforcement learning, the manipulator learns to interact in ways that reveal the underlying causal factors. We show that this method works even without any prior knowledge of the objects, or any previously-collected training data. We carry out the training in planetary exploration conditions, with realistic manipulator models."
https://arxiv.org/abs/2403.00469,2024-03-01,On an estimate on GÃ¶tzky's domain,['DÃ¡vid TÃ³th'],"A fundamental domain $F\subset H^2$ for the Hilbert modular group belonging to the quadratic number field $Q(\sqrt{5})$ was constructed by GÃ¶tzky almost a hundred years ago. He also gave a lower bound for the height $y_1y_2$ of the points $(z_1,z_2)=(x_1+iy_1,x_2+iy_2)\in F$. Later Gundlach used analogous domains and estimates for other fields as well to give a complete list of totally elliptic conjugacy classes in some Hilbert modular groups, while not long ago Deutsch analysed two of these domains by numerical computations and stated some conjectures about them. We prove one of these by giving a sharp lower bound for the height of the points of GÃ¶tzky's domain."
https://arxiv.org/abs/2403.00468,2024-03-01,Probabilistic central Bell polynomials,"['R. Xu', 'Y. Ma', 'T. Kim', 'D. S. Kim', 'S. Boulaars']","Let Y be a random variable whose moment generating function exists in a neighborhood of the origin. In this paper, we study the probabilistic central Bell polynomials associated with random variable Y, as probabilistic extension of the central Bell polynomials. In addition, we investigate the probabilistic central factorial numbers of the second kind associated with Y and the probabilistic central Fubini polynomials associated with Y. The aim of this paper is to derive some properties, explicit expressions, certain identities and recurrence relations for those polynomials and numbers."
https://arxiv.org/abs/2403.00467,2024-03-01,When ControlNet Meets Inexplicit Masks: A Case Study of ControlNet on its Contour-following Ability,"['Wenjie Xuan', 'Yufei Xu', 'Shanshan Zhao', 'Chaoyue Wang', 'Juhua Liu', 'Bo Du', 'Dacheng Tao']","ControlNet excels at creating content that closely matches precise contours in user-provided masks. However, when these masks contain noise, as a frequent occurrence with non-expert users, the output would include unwanted artifacts. This paper first highlights the crucial role of controlling the impact of these inexplicit masks with diverse deterioration levels through in-depth analysis. Subsequently, to enhance controllability with inexplicit masks, an advanced Shape-aware ControlNet consisting of a deterioration estimator and a shape-prior modulation block is devised. The deterioration estimator assesses the deterioration factor of the provided masks. Then this factor is utilized in the modulation block to adaptively modulate the model's contour-following ability, which helps it dismiss the noise part in the inexplicit masks. Extensive experiments prove its effectiveness in encouraging ControlNet to interpret inaccurate spatial conditions robustly rather than blindly following the given contours. We showcase application scenarios like modifying shape priors and composable shape-controllable generation. Codes are soon available."
https://arxiv.org/abs/2403.00466,2024-03-01,Three-Dimensional Freeform Reflector Design with a Microfacet Surface Roughness Model,"['VÃ¬ Kronberg', 'Martijn Anthonissen', 'Jan ten Thije Boonkkamp', 'Wilbert IJzerman']","This manuscript will unify inverse freeform reflector design and surface light scattering to design freeform reflectors with a scattering surface. We use microfacets, which are small, tilted mirrors superimposed on a smooth surface. We form a simple model of surface roughness and light scattering based on the orientations of the microfacets. Using a least-squares solver to compute the smooth reflector as a starting point, we can subsequently alter the surface using an optimization procedure to account for the scattering. After optimization, the resulting reflector surface produces the desired scattered light distribution. We verify the resulting reflector using raytracing."
https://arxiv.org/abs/2403.00465,2024-03-01,Polyamorous Scheduling,"['Leszek GÄsieniec', 'Benjamin Smith', 'Sebastian Wild']","Finding schedules for pairwise meetings between the members of a complex social group without creating interpersonal conflict is challenging, especially when different relationships have different needs. We formally define and study the underlying optimisation problem: Polyamorous Scheduling."
https://arxiv.org/abs/2403.00464,2024-03-01,Attacking Delay-based PUFs with Minimal Adversary Model,"['Hongming Fei', 'Owen Millwood', 'Prosanta Gope', 'Jack Miskelly', 'Biplab Sikdar']","Physically Unclonable Functions (PUFs) provide a streamlined solution for lightweight device authentication. Delay-based Arbiter PUFs, with their ease of implementation and vast challenge space, have received significant attention; however, they are not immune to modelling attacks that exploit correlations between their inputs and outputs. Research is therefore polarized between developing modelling-resistant PUFs and devising machine learning attacks against them. This dichotomy often results in exaggerated concerns and overconfidence in PUF security, primarily because there lacks a universal tool to gauge a PUF's security. In many scenarios, attacks require additional information, such as PUF type or configuration parameters. Alarmingly, new PUFs are often branded `secure' if they lack a specific attack model upon introduction. To impartially assess the security of delay-based PUFs, we present a generic framework featuring a Mixture-of-PUF-Experts (MoPE) structure for mounting attacks on various PUFs with minimal adversarial knowledge, which provides a way to compare their performance fairly and impartially. We demonstrate the capability of our model to attack different PUF types, including the first successful attack on Heterogeneous Feed-Forward PUFs using only a reasonable amount of challenges and responses. We propose an extension version of our model, a Multi-gate Mixture-of-PUF-Experts (MMoPE) structure, facilitating multi-task learning across diverse PUFs to recognise commonalities across PUF designs. This allows a streamlining of training periods for attacking multiple PUFs simultaneously. We conclude by showcasing the potent performance of MoPE and MMoPE across a spectrum of PUF types, employing simulated, real-world unbiased, and biased data sets for analysis."
https://arxiv.org/abs/2403.00463,2024-03-01,The first law of thermodynamics in hydrodynamic steady and unsteady flows,"['Konrad GiÅ¼yÅski', 'Karol Makuch', 'Jan Paczesny', 'PaweÅ Å»uk', 'Anna MacioÅek', 'Robert HoÅyst']","We studied planar compressible flows of ideal gas as models of a non-equilibrium thermodynamic system. We demonstrate that internal energy $U(S^{*},V,N)$ of such systems in stationary and non-stationary states is the function of only three parameters of state, i.e. non-equilibrium entropy $S^{*}$, volume $V$ and number of particles $N$ in the system. Upon transition between different states, the system obeys the first thermodynamic law, i.e. $dU=T^{*}dS^{*}-p^{*}dV+Î¼^{*}dN$, where $U=3/2 NRT^{*}$ and $p^{*}V=NRT^{*}$. Placing a cylinder inside the channel, we find that U depends on the location of the cylinder $y_{c}$ only via the parameters of state, i.e. $U(S^{*}(y_{c}),V,N(y_{c}))$ at V=const. Moreover, when the flow around the cylinder becomes unstable, and velocity, pressure, and density start to oscillate as a function of time, t, U depends on t only via the parameters of state, i.e. $U(S^{*}(t),V,N(t))$ for V=const. These examples show that such a form of internal energy is robust and does not depend on the particular boundary conditions even in the unsteady flow."
https://arxiv.org/abs/2403.00462,2024-03-01,LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues,"['Joe Stacey', 'Jianpeng Cheng', 'John Torr', 'Tristan Guigue', 'Joris Driesen', 'Alexandru Coca', 'Mark Gaynor', 'Anders Johannsen']","Virtual assistants are poised to take a dramatic leap forward in terms of their dialogue capabilities, spurred by recent advances in transformer-based Large Language Models (LLMs). Yet a major bottleneck to achieving genuinely transformative task-oriented dialogue capabilities remains the scarcity of high quality and linguistically sophisticated data. Existing datasets, while impressive in scale, have limited domain coverage and contain few genuinely challenging conversational phenomena; those which are present are typically unlabelled, making it difficult to assess the strengths and weaknesses of models without time-consuming and costly human evaluation. Moreover, creating high quality dialogue data has until now required considerable human input, limiting both the scale of these datasets and the ability to rapidly bootstrap data for a new target domain. We aim to overcome these issues with LUCID, a modularised and highly automated LLM-driven data generation system that produces realistic, diverse and challenging dialogues. We use LUCID to generate a seed dataset of 4,277 multi-domain, multi-intent conversations across 100 intents to demonstrate its capabilities. The generated conversations include a wide range of challenging phenomena and diverse user behaviour, conveniently identifiable via a set of turn-level tags. Finally, we provide separate test sets for seen and unseen intents, allowing for convenient out-of-distribution evaluation. We release both the data generation code and the dataset itself."
https://arxiv.org/abs/2403.00461,2024-03-01,Phase retrieval beyond the homogeneous object assumption for X-ray in-line holographic imaging,"['Jens Lucht', 'Leon M. Lohse', 'Thorsten Hohage', 'Tim Salditt']","X-ray near field holography has proven to be a powerful 2D and 3D imaging technique with applications ranging from biomedical research to material sciences. To reconstruct meaningful and quantitative images from the measurement intensities, however, it relies on computational phase retrieval which in many cases assumes the phase-shift and attenuation coefficient of the sample to be proportional. Here, we demonstrate an efficient phase retrieval algorithm that does not rely on this homogeneous-object assumption and is a generalization of the well-established contrast-transfer-function (CTF) approach. We then investigate its stability and present an experimental study comparing the proposed algorithm with established methods. The algorithm shows superior reconstruction quality compared to the established CTF-based method at similar computational cost. Our analysis provides a deeper fundamental understanding of the homogeneous object assumption and the proposed algorithm will help improve the image quality for near-field holography in biomedical applications"
https://arxiv.org/abs/2403.00460,2024-03-01,Slender vortex filaments in the Boussinesq Approximation,"['Marie Rodal', 'Daniel Margerit', 'Rupert Klein']","A model for the motion of slender vortex filaments is extended to include the effect of gravity. The model, initially introduced by Callegari and Ting (SIAM, J. of App. Math., (1978), vol. 35, pp. 148-175), is based on a matched asymptotic expansion in which the outer solution, given by the Biot-Savart law, is matched with the inner solution derived from the Navier-Stokes equations. Building on recent work by Harikrishnan et al (Phys. of Fluids, (2023), vol. 35) the Boussinesq approximation is applied such that the density variations only enter in the gravity term. However, unlike Harikrishnan et al. (2023) the density variation enters at a lower order in the asymptotic expansion, and thus has a more significant impact on the self-induced velocity of the vortex filament. In this regime, which corresponds to the regime studied by Chang and Smith (J. of Fl. Mech., (2018), vol. 857), the effect of gravity is given by an alteration of the core constant, which couples the motion of the filament to the motion within the vortical core, in addition to a change in the compatability conditions (evolution equations) which determine the leading order azimuthal and tangential velocity fields in the vortex core. The results are used to explain certain properties of bouyant vortex rings, as well as qualitatively explore the impact of gravity on tornado type atmospheric vorticies."
https://arxiv.org/abs/2403.00459,2024-03-01,Deformable One-shot Face Stylization via DINO Semantic Guidance,"['Yang Zhou', 'Zichong Chen', 'Hui Huang']","This paper addresses the complex issue of one-shot face stylization, focusing on the simultaneous consideration of appearance and structure, where previous methods have fallen short. We explore deformation-aware face stylization that diverges from traditional single-image style reference, opting for a real-style image pair instead. The cornerstone of our method is the utilization of a self-supervised vision transformer, specifically DINO-ViT, to establish a robust and consistent facial structure representation across both real and style domains. Our stylization process begins by adapting the StyleGAN generator to be deformation-aware through the integration of spatial transformers (STN). We then introduce two innovative constraints for generator fine-tuning under the guidance of DINO semantics: i) a directional deformation loss that regulates directional vectors in DINO space, and ii) a relative structural consistency constraint based on DINO token self-similarities, ensuring diverse generation. Additionally, style-mixing is employed to align the color generation with the reference, minimizing inconsistent correspondences. This framework delivers enhanced deformability for general one-shot face stylization, achieving notable efficiency with a fine-tuning duration of approximately 10 minutes. Extensive qualitative and quantitative comparisons demonstrate our superiority over state-of-the-art one-shot face stylization methods. Code is available at \url{https://github.com/zichongc/DoesFS}."
https://arxiv.org/abs/2403.00458,2024-03-01,Prices and preferences in the electric vehicle market,"['Chung Yi See', 'Vasco Rato Santos', 'Lucas Woodley', 'Megan Yeo', 'Daniel Palmer', 'Shuheng Zhang', 'and Ashley Nunes']","Although electric vehicles are less polluting than gasoline powered vehicles, adoption is challenged by higher procurement prices. Existing discourse emphasizes EV battery costs as being principally responsible for this price differential and widespread adoption is routinely conditioned upon battery costs declining. We scrutinize such reasoning by sourcing data on EV attributes and market conditions between 2011 and 2023. Our findings are fourfold. First, EV prices are influenced principally by the number of amenities, additional features, and dealer-installed accessories sold as standard on an EV, and to a lesser extent, by EV horsepower. Second, EV range is negatively correlated with EV price implying that range anxiety concerns may be less consequential than existing discourse suggests. Third, battery capacity is positively correlated with EV price, due to more capacity being synonymous with the delivery of more horsepower. Collectively, this suggests that higher procurement prices for EVs reflects consumer preference for vehicles that are feature dense and more powerful. Fourth and finally, accommodating these preferences have produced vehicles with lower fuel economy, a shift that reduces envisioned lifecycle emissions benefits by at least 3.26 percent, subject to the battery pack chemistry leveraged and the carbon intensity of the electrical grid. These findings warrant attention as decarbonization efforts increasingly emphasize electrification as a pathway for complying with domestic and international climate agreements."
https://arxiv.org/abs/2403.00457,2024-03-01,"Waves, patterns and bifurcations: a tutorial review on the vertebrate segmentation clock","['Paul FranÃ§ois', 'Victoria Mochulska']","Proper vertebrae formation relies on a tissue-wide oscillator called the segmentation clock. Individual cellular oscillators in the presomitic mesoderm are modulated by intercellular coupling and external signals, leading to the propagation of oscillatory waves of genetic expression eventually stabilizing into a static pattern of genetic expression. Here, we review 4 decades of biophysical models of this process, starting from the pioneering Clock and Wavefront model by Cooke and Zeeman, and the reaction-diffusion model by Meinhardt. We discuss how modern descriptions followed advances in molecular description and visualization of the process, reviewing phase models, delayed models, systems-level, and finally geometric models. We connect models to high-level aspects of embryonic development from embryonic scaling to wave propagation, up to reconstructed stem cell systems. We provide new analytical calculations and insights into classical and recent models, leading us to propose a geometric description of somitogenesis organized along two primary waves of differentiation."
https://arxiv.org/abs/2403.00456,2024-03-01,Inertia onset in disordered porous media flow,"['Damian Sniezek', 'Sahrish B. Naqvi', 'Maciej Matyka']","We investigate the very onset of the inertial regime in pore-scale fluid flow in a three-dimensional, disordered porous media. We analyze how the flow structure changes with increasing Reynolds number. In particular, we compute tortuosity, spatial kinetic energy localization, and the pore-space volume fraction containing negative streamwise velocity. Our analysis shows that the onset of inertia observed in a standard way by computing the friction factor appears at a Reynolds number two orders of magnitude higher than indicated by analyzing tortuosity and spatial distribution of kinetic energy."
https://arxiv.org/abs/2403.00455,2024-03-01,A Survey on Self-healing Software System,['Zahra Yazdanparast'],"With the increasing complexity of software systems, it becomes very difficult to install, configure, adjust, and maintain them. As systems become more interconnected and diverse, system architects are less able to predict and design the interaction between components, deferring the handling of these issues to runtime. One of the important problems that occur during execution is system failures, which increase the need for self-healing systems. The main purpose of self-healing is to have an automatic system that can heal itself without human intervention. This system has predefined actions and procedures that are suitable for recovering the system from different failure modes. In this study, different self-healing methods are categorized and a summary of them is presented."
https://arxiv.org/abs/2403.00454,2024-03-01,Shorts vs. Regular Videos on YouTube: A Comparative Analysis of User Engagement and Content Creation Trends,"['Caroline Violot', 'TuÄrulcan Elmas', 'Igor Bilogrevic', 'Mathias Humbert']","YouTube introduced the Shorts video format in 2021, allowing users to upload short videos that are prominently displayed on its website and app. Despite having such a large visual footprint, there are no studies to date that have looked at the impact Shorts introduction had on the production and consumption of content on YouTube. This paper presents the first comparative analysis of YouTube Shorts versus regular videos with respect to user engagement (i.e., views, likes, and comments), content creation frequency and video categories. We collected a dataset containing information about 70k channels that posted at least one Short, and we analyzed the metadata of all the videos (9.9M Shorts and 6.9M regular videos) they uploaded between January 2021 and December 2022, spanning a two-year period including the introduction of Shorts. Our longitudinal analysis shows that content creators consistently increased the frequency of Shorts production over this period, especially for newly-created channels, which surpassed that of regular videos. We also observe that Shorts target mostly entertainment categories, while regular videos cover a wide variety of categories. In general, Shorts attract more views and likes per view than regular videos, but attract less comments per view. However, Shorts do not outperform regular videos in the education and political categories as much as they do in other categories. Our study contributes to understanding social media dynamics, to quantifying the spread of short-form content, and to motivating future research on its impact on society."
https://arxiv.org/abs/2403.00453,2024-03-01,Exploring Fairness for FAS-assisted Communication Systems: from NOMA to OMA,"['Junteng Yao', 'Liaoshi Zhou', 'Tuo Wu', 'Ming Jin', 'Cunhua Pan', 'Maged Elkashlan', 'Kai-Kit Wong']","This paper addresses the fairness issue within fluid antenna system (FAS)-assisted non-orthogonal multiple access (NOMA) and orthogonal multiple access (OMA) systems, where a single fixed-antenna base station (BS) transmits superposition-coded signals to two users, each with a single fluid antenna. We define fairness through the minimization of the maximum outage probability for the two users, under total resource constraints for both FAS-assisted NOMA and OMA systems. Specifically, in the FAS-assisted NOMA systems, we study both a special case and the general case, deriving a closed-form solution for the former and applying a bisection search method to find the optimal solution for the latter. Moreover, for the general case, we derive a locally optimal closed-form solution to achieve fairness. In the FAS-assisted OMA systems, to deal with the non-convex optimization problem with coupling of the variables in the objective function, we employ an approximation strategy to facilitate a successive convex approximation (SCA)-based algorithm, achieving locally optimal solutions for both cases. Empirical analysis validates that our proposed solutions outperform conventional NOMA and OMA benchmarks in terms of fairness."
https://arxiv.org/abs/2403.00452,2024-03-01,An Ordinal Diffusion Model for Generating Medical Images with Different Severity Levels,"['Shumpei Takezaki', 'Seiichi Uchida']","Diffusion models have recently been used for medical image generation because of their high image quality. In this study, we focus on generating medical images with ordinal classes, which have ordinal relationships, such as severity levels. We propose an Ordinal Diffusion Model (ODM) that controls the ordinal relationships of the estimated noise images among the classes. Our model was evaluated experimentally by generating retinal and endoscopic images of multiple severity classes. ODM achieved higher performance than conventional generative models by generating realistic images, especially in high-severity classes with fewer training samples."
https://arxiv.org/abs/2403.00451,2024-03-01,Charge-conjugation asymmetry and molecular content: the $D_{s0}^\ast(2317)^\pm$ in matter,"['Victor Montesinos', 'Miguel Albaladejo', 'Juan Nieves', 'Laura Tolos']","We analyze the modifications that a dense nuclear medium induces in the $D_{s0}^\ast(2317)^\pm$ and $D_{s1}(2460)^\pm$. In the vacuum, we consider them as isoscalar $D^{(*)}K$ and $\overline{D}{}^{(*)}\overline{K}$ $S$-wave bound states, which are dynamically generated from effective interactions that lead to different Weinberg compositeness scenarios. Matter effects are incorporated through the two-meson loop functions, taking into account the self energies that the $D^{(*)}$, $\overline{D}{}^{(*)}$, $K$, and $\overline{K}$ develop when embedded in a nuclear medium. Although particle-antiparticle [$D^{(\ast)}_{s0,s1}(2317,2460)^+$ versus $D^{(\ast)}_{s0,s1}(2317,2460)^-$] lineshapes are the same in vacuum, we find extremely different density patterns in matter. This charge-conjugation asymmetry mainly stems from the very different kaon and antikaon interaction with the nucleons of the dense medium. We show that the in-medium lineshapes found for these resonances strongly depend on their $D^{(*)}K$/$\overline{D}{}^{(*)}\overline{K}$ molecular content, and discuss how this novel feature can be used to better determine/constrain the inner structure of these exotic states."
https://arxiv.org/abs/2403.00450,2024-03-01,Parallel Hyperparameter Optimization Of Spiking Neural Network,"['Thomas Firmin', 'Pierre Boulet', 'El-Ghazali Talbi']","Spiking Neural Networks (SNN). SNNs are based on a more biologically inspired approach than usual artificial neural networks. Such models are characterized by complex dynamics between neurons and spikes. These are very sensitive to the hyperparameters, making their optimization challenging. To tackle hyperparameter optimization of SNNs, we initially extended the signal loss issue of SNNs to what we call silent networks. These networks fail to emit enough spikes at their outputs due to mistuned hyperparameters or architecture. Generally, search spaces are heavily restrained, sometimes even discretized, to prevent the sampling of such networks. By defining an early stopping criterion detecting silent networks and by designing specific constraints, we were able to instantiate larger and more flexible search spaces. We applied a constrained Bayesian optimization technique, which was asynchronously parallelized, as the evaluation time of a SNN is highly stochastic. Large-scale experiments were carried-out on a multi-GPU Petascale architecture. By leveraging silent networks, results show an acceleration of the search, while maintaining good performances of both the optimization algorithm and the best solution obtained. We were able to apply our methodology to two popular training algorithms, known as spike timing dependent plasticity and surrogate gradient. Early detection allowed us to prevent worthless and costly computation, directing the search toward promising hyperparameter combinations. Our methodology could be applied to multi-objective problems, where the spiking activity is often minimized to reduce the energy consumption. In this scenario, it becomes essential to find the delicate frontier between low-spiking and silent networks. Finally, our approach may have implications for neural architecture search, particularly in defining suitable spiking architectures."
https://arxiv.org/abs/2403.00449,2024-03-01,Trace-class operators on Hilbert modules and Haagerup tensor products,"['Tyrone Crisp', 'Michael Rosbotham']","We show that the space of trace-class operators on a Hilbert module over a commutative C*-algebra, as defined and studied in earlier work of Stern and van Suijlekom (Journal of Functional Analysis, 2021), is completely isometrically isomorphic to a Haagerup tensor product of the module with its operator-theoretic adjoint. This generalises a well-known property of Hilbert spaces. In the course of proving this, we also obtain a new proof of a result of Stern-van Suijlekom concerning the equivalence between two definitions of trace-class operators on Hilbert modules."
https://arxiv.org/abs/2403.00448,2024-03-01,When Large Language Models Confront Repository-Level Automatic Program Repair: How Well They Done?,"['Yuxiao Chen', 'Jingzheng Wu', 'Xiang Ling', 'Changjiang Li', 'Zhiqing Rui', 'Tianyue Luo', 'Yanjun Wu']","In recent years, large language models (LLMs) have demonstrated substantial potential in addressing automatic program repair (APR) tasks. However, the current evaluation of these models for APR tasks focuses solely on the limited context of the single function or file where the bug is located, overlooking the valuable information in the repository-level context. This paper investigates the performance of popular LLMs in handling repository-level repair tasks. We introduce RepoBugs, a new benchmark comprising 124 typical repository-level bugs from open-source repositories. Preliminary experiments using GPT3.5 based on the function where the error is located, reveal that the repair rate on RepoBugs is only 22.58%, significantly diverging from the performance of GPT3.5 on function-level bugs in related studies. This underscores the importance of providing repository-level context when addressing bugs at this level. However, the repository-level context offered by the preliminary method often proves redundant and imprecise and easily exceeds the prompt length limit of LLMs. To solve the problem, we propose a simple and universal repository-level context extraction method (RLCE) designed to provide more precise context for repository-level code repair tasks. Evaluations of three mainstream LLMs show that RLCE significantly enhances the ability to repair repository-level bugs. The improvement reaches a maximum of 160% compared to the preliminary method. Additionally, we conduct a comprehensive analysis of the effectiveness and limitations of RLCE, along with the capacity of LLMs to address repository-level bugs, offering valuable insights for future research."
https://arxiv.org/abs/2403.00447,2024-03-01,Continuous Approximations of Projected Dynamical Systems via Control Barrier Functions,"['Giannis Delimpaltadakis', 'Jorge CortÃ©s', 'W. P. M. H.', ' Heemels']","Projected Dynamical Systems (PDSs) form a class of discontinuous constrained dynamical systems, and have been used widely to solve optimization problems and variational inequalities. Recently, they have also gained significant attention for control purposes, such as high-performance integrators, saturated control and feedback optimization. In this work, we establish that locally Lipschitz continuous dynamics, involving Control Barrier Functions (CBFs), namely CBF-based dynamics, approximate PDSs. Specifically, we prove that trajectories of CBF-based dynamics uniformly converge to trajectories of PDSs, as a CBF-parameter is taken to infinity. Towards this, we also prove that CBF-based dynamics are perturbations of PDSs, with quantitative bounds on the perturbation. Our results pave the way to implement discontinuous PDS-based controllers in a continuous fashion, employing CBFs. Moreover, they can be employed to numerically simulate PDSs, overcoming disadvantages of existing discretization schemes, such as computing projections to possibly non-convex sets. Finally, this bridge between CBFs and PDSs may yield other potential benefits, including novel insights on stability."
https://arxiv.org/abs/2403.00446,2024-03-01,Safe Hybrid-Action Reinforcement Learning-Based Decision and Control for Discretionary Lane Change,"['Ruichen Xu', 'Xiao Liu', 'Jinming Xu', 'Yuan Lin']","Autonomous lane-change, a key feature of advanced driver-assistance systems, can enhance traffic efficiency and reduce the incidence of accidents. However, safe driving of autonomous vehicles remains challenging in complex environments. How to perform safe and appropriate lane change is a popular topic of research in the field of autonomous driving. Currently, few papers consider the safety of reinforcement learning in autonomous lane-change scenarios. We introduce safe hybrid-action reinforcement learning into discretionary lane change for the first time and propose Parameterized Soft Actor-Critic with PID Lagrangian (PASAC-PIDLag) algorithm. Furthermore, we conduct a comparative analysis of the Parameterized Soft Actor-Critic (PASAC), which is an unsafe version of PASAC-PIDLag. Both algorithms are employed to train the lane-change strategy of autonomous vehicles to output discrete lane-change decision and longitudinal vehicle acceleration. Our simulation results indicate that at a traffic density of 15 vehicles per kilometer (15 veh/km), the PASAC-PIDLag algorithm exhibits superior safety with a collision rate of 0%, outperforming the PASAC algorithm, which has a collision rate of 1%. The outcomes of the generalization assessments reveal that at low traffic density levels, both the PASAC-PIDLag and PASAC algorithms are proficient in attaining a 0% collision rate. Under conditions of high traffic flow density, the PASAC-PIDLag algorithm surpasses PASAC in terms of both safety and optimality."
https://arxiv.org/abs/2403.00445,2024-03-01,Distributed Persistent Homology for 2D Alpha Complexes,"['Freya Jensen', 'Ãlvaro Torras-Casas']","We introduce a new algorithm to parallelise the computation of persistent homology of 2D alpha complexes. Our algorithm distributes the input point cloud among the cores which then compute a cover based on a rectilinear grid. We show how to compute the persistence Mayer-Vietoris spectral sequence from these covers and how to obtain persistent homology from it. For this, we introduce second-page collapse conditions and explain how to solve the extension problem. Finally, we give an overview of an implementation in C++ using Open MPI and discuss some experimental results."
https://arxiv.org/abs/2403.00444,2024-03-01,Dual symmetries of dense three and two-color QCD and some QCD-like NJL models,"['T. G. Khunjua', 'K. G. Klimenko', 'R. N. Zhokhov']","In this paper the symmetry properties of the phase diagram of dense quark matter composed of $u$ and $d$ quarks with two or three colors has been investigated in the framework of massless (3+1)-dimensional Nambu--Jona-Lasinio (NJL) and QCD models. It turns out that in the presence of baryon $Î¼_B$, isospin $Î¼_I$, chiral $Î¼_5$ and chiral isospin $Î¼_{I5}$ chemical potentials the Lagrangians of these models are invariant under the so-called dual transformations. Consequently, the entire NJL model (or QCD) thermodynamic potentials are dually symmetric. In particular, it means that in the total $(Î¼_B,Î¼_I,Î¼_5,Î¼_{I5})$-phase portraits of these models the chiral symmetry breaking (CSB) and charged pion condensation (PC) phases are arranged dually conjugated (or symmetrical) to each other (in the case of three-color models). Whereas in the case of two-color quark matter, these models predict the entire phase structure in which there are dual symmetries between CSB, charged PC and baryon superfluid phases."
https://arxiv.org/abs/2403.00443,2024-03-01,Amplitude modulations and resonant decay of excited oscillons,"['F. Blaschke', 'K. SÅawiÅska', 'T. RomaÅczukiewicz', 'A. WereszczyÅski']","We show that the decay of strongly excited oscillons in a single vacuum model reveals a chaotic, fractal-like pattern very much like one found in kink-antikink collision in the $Ï^4$ model. This structure can be attributed to the resonant energy transfer mechanism triggered by the modulations of amplitudes of constituent oscillons which form the excited oscillon. We also find evidence that such modulations arise as a motion of two quasi-breathers inside the constituent oscillon."
https://arxiv.org/abs/2403.00442,2024-03-01,Ergodic and non-ergodic properties of disordered SU(3) chains,"['Bhupen Dabholkar', 'Fabien Alet']","Non-abelian symmetries are thought to be incompatible with many-body localization, but have been argued to produce in certain disordered systems a broad non-ergodic regime distinct from many-body localization. In this context, we present a numerical study of properties of highly-excited eigenstates of disordered chains with SU(3) symmetry. We find that while weakly disordered systems rapidly thermalize, strongly-disordered systems indeed exhibit non-thermal signatures over a large range of system sizes, similar to the one found in previously studied SU(2) systems. Our analysis is based on the spectral, entanglement, and thermalization properties of eigenstates obtained through large-scale exact diagonalization exploiting the full SU(3) symmetry."
https://arxiv.org/abs/2403.00441,2024-03-01,Enhancing Gravitational Wave Parameter Estimation with Non-Linear Memory: Breaking the Distance-Inclination Degeneracy,"['Yumeng Xu', 'Maria RossellÃ³-Sastre', 'Shubhanshu Tiwari', 'Michael Ebersold', 'Eleanor Z Hamilton', 'Cecilio GarcÃ­a-QuirÃ³s', 'HÃ©ctor EstellÃ©s', 'Sascha Husa']","In this study, we investigate the role of the non-linear memory effect in gravitational wave (GW) parameter estimation, particularly we explore its capability to break the degeneracy between luminosity distance and inclination angle in binary coalescence events. Motivated by the rapid growth in GW detections and the increasing sensitivity of GW observatories enhancing the precision of cosmological and astrophysical measurements is crucial. We propose leveraging the non-linear memory effect -- a subtle, persistent feature in the GW signal resulting from the cumulative impact of emitted gravitational waves -- as a novel approach to enhance parameter estimation accuracy. Through a comprehensive series of injection studies, encompassing both reduced and full parameter spaces, we evaluate the effectiveness of non-linear memory in various scenarios for aligned-spin systems. Our findings demonstrate the significant potential of non-linear memory in resolving the inclination-distance degeneracy, particularly for events with high signal-to-noise ratios (SNR $>$ 60) for the current generation of detectors and in the context of future detector sensitivities such as the planned LIGO A$^\sharp$ upgrade. The results also suggest that excluding non-linear memory from parameter estimation could introduce significant systematics in future LIGO A$^\sharp$ detections. This observation will hold even greater weight for next-generation detectors, highlighting the importance of including non-linear memory in GW models for achieving high-accuracy measurements for gravitational wave (GW) astronomy."
https://arxiv.org/abs/2403.00440,2024-03-01,Ground water retention correlation to atmospheric muon rates,"['Theodore Avgitas', 'Jean-Christophe Ianigro', 'Jacques Marteau']","Muography is an investigation technique based on the detection of the atmospheric muon flux' modification through matter. It has found lately multiple applications in geosciences, archaelogy, and non invasive industrial controls. Mostly known for its imaging capabilities, muography may be exploited as well for monitoring purposes since the atmospheric muon flux is available permanently. In this paper we present an interesting measurement performed in the context of an archaelogical project called ArchÃ©muons, on the archaeological site of ""Palais du Miroir"" in Vienne, South of Lyon, France. We installed a muon detector in an underground gallery within the foundations of the building for the second half of 2023. The primary goal is to measure details of those foundations which are largely not excavated yet. Meanwhile we observed over more than 6 months long-term and short-term variations of the muon rates since the start of the experiment, which seem to exhibit a correlation with the rain accumulating on the free field just above the gallery. We propose as an explanation for this behavior the retention of water by the soil above the detector site."
https://arxiv.org/abs/2403.00439,2024-03-01,Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts,"['Taewook Kim', 'Hyomin Han', 'Eytan Adar', 'Matthew Kay', 'John Joon Young Chung']","Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while promoting authors' values."
https://arxiv.org/abs/2403.00438,2024-03-01,Your Model Is Not Predicting Depression Well And That Is Why: A Case Study of PRIMATE Dataset,"['Kirill Milintsevich', 'Kairit Sirts', 'GaÃ«l Dias']","This paper addresses the quality of annotations in mental health datasets used for NLP-based depression level estimation from social media texts. While previous research relies on social media-based datasets annotated with binary categories, i.e. depressed or non-depressed, recent datasets such as D2S and PRIMATE aim for nuanced annotations using PHQ-9 symptoms. However, most of these datasets rely on crowd workers without the domain knowledge for annotation. Focusing on the PRIMATE dataset, our study reveals concerns regarding annotation validity, particularly for the lack of interest or pleasure symptom. Through reannotation by a mental health professional, we introduce finer labels and textual spans as evidence, identifying a notable number of false positives. Our refined annotations, to be released under a Data Use Agreement, offer a higher-quality test set for anhedonia detection. This study underscores the necessity of addressing annotation quality issues in mental health datasets, advocating for improved methodologies to enhance NLP model reliability in mental health assessments."
https://arxiv.org/abs/2403.00437,2024-03-01,LoMOE: Localized Multi-Object Editing via Multi-Diffusion,"['Goirik Chakrabarty', 'Aditya Chandrasekar', 'Ramya Hebbalaguppe', 'Prathosh AP']","Recent developments in the field of diffusion models have demonstrated an exceptional capacity to generate high-quality prompt-conditioned image edits. Nevertheless, previous approaches have primarily relied on textual prompts for image editing, which tend to be less effective when making precise edits to specific objects or fine-grained regions within a scene containing single/multiple objects. We introduce a novel framework for zero-shot localized multi-object editing through a multi-diffusion process to overcome this challenge. This framework empowers users to perform various operations on objects within an image, such as adding, replacing, or editing $\textbf{many}$ objects in a complex scene $\textbf{in one pass}$. Our approach leverages foreground masks and corresponding simple text prompts that exert localized influences on the target regions resulting in high-fidelity image editing. A combination of cross-attention and background preservation losses within the latent space ensures that the characteristics of the object being edited are preserved while simultaneously achieving a high-quality, seamless reconstruction of the background with fewer artifacts compared to the current methods. We also curate and release a dataset dedicated to multi-object editing, named $\texttt{LoMOE}$-Bench. Our experiments against existing state-of-the-art methods demonstrate the improved effectiveness of our approach in terms of both image editing quality and inference speed."
https://arxiv.org/abs/2403.00436,2024-03-01,Abductive Ego-View Accident Video Understanding for Safe Driving Perception,"['Jianwu Fang', 'Lei-lei Li', 'Junfei Zhou', 'Junbin Xiao', 'Hongkai Yu', 'Chen Lv', 'Jianru Xue', 'Tat-Seng Chua']","We present MM-AU, a novel dataset for Multi-Modal Accident video Understanding. MM-AU contains 11,727 in-the-wild ego-view accident videos, each with temporally aligned text descriptions. We annotate over 2.23 million object boxes and 58,650 pairs of video-based accident reasons, covering 58 accident categories. MM-AU supports various accident understanding tasks, particularly multimodal video diffusion to understand accident cause-effect chains for safe driving. With MM-AU, we present an Abductive accident Video understanding framework for Safe Driving perception (AdVersa-SD). AdVersa-SD performs video diffusion via an Object-Centric Video Diffusion (OAVD) method which is driven by an abductive CLIP model. This model involves a contrastive interaction loss to learn the pair co-occurrence of normal, near-accident, accident frames with the corresponding text descriptions, such as accident reasons, prevention advice, and accident categories. OAVD enforces the causal region learning while fixing the content of the original frame background in video generation, to find the dominant cause-effect chain for certain accidents. Extensive experiments verify the abductive ability of AdVersa-SD and the superiority of OAVD against the state-of-the-art diffusion models. Additionally, we provide careful benchmark evaluations for object detection and accident reason answering since AdVersa-SD relies on precise object and accident reason information."
https://arxiv.org/abs/2403.00435,2024-03-01,Hierarchical Indexing for Retrieval-Augmented Opinion Summarization,"['Tom Hosking', 'Hao Tang', 'Mirella Lapata']","We propose a method for unsupervised abstractive opinion summarization, that combines the attributability and scalability of extractive approaches with the coherence and fluency of Large Language Models (LLMs). Our method, HIRO, learns an index structure that maps sentences to a path through a semantically organized discrete hierarchy. At inference time, we populate the index and use it to identify and retrieve clusters of sentences containing popular opinions from input reviews. Then, we use a pretrained LLM to generate a readable summary that is grounded in these extracted evidential clusters. The modularity of our approach allows us to evaluate its efficacy at each stage. We show that HIRO learns an encoding space that is more semantically structured than prior work, and generates summaries that are more representative of the opinions in the input reviews. Human evaluation confirms that HIRO generates more coherent, detailed and accurate summaries that are significantly preferred by annotators compared to prior work."
https://arxiv.org/abs/2403.00434,2024-03-01,Probabilistic Semantic Communication over Wireless Networks with Rate Splitting,"['Zhouxiang Zhao', 'Zhaohui Yang', 'Ye Hu', 'Qianqian Yang', 'Wei Xu', 'Zhaoyang Zhang']","In this paper, the problem of joint transmission and computation resource allocation for probabilistic semantic communication (PSC) system with rate splitting multiple access (RSMA) is investigated. In the considered model, the base station (BS) needs to transmit a large amount of data to multiple users with RSMA. Due to limited communication resources, the BS is required to utilize semantic communication techniques to compress the large-sized data. The semantic communication is enabled by shared probability graphs between the BS and the users. The probability graph can be used to further compress the transmission data at the BS, while the received compressed semantic information can be recovered through using the same shared probability graph at each user side. The semantic information compression progress consumes additional computation power at the BS, which inevitably decreases the transmission power due to limited total power budget. Considering both the effect of semantic compression ratio and computation power, the semantic rate expression for RSMA is first obtained. Then, based on the obtained rate expression, an optimization problem is formulated with the aim of maximizing the sum of semantic rates of all users under total power, semantic compression ratio, and rate allocation constraints. To tackle this problem, an iterative algorithm is proposed, where the rate allocation and transmit beamforming design subproblem is solved using a successive convex approximation method, and the semantic compression ratio subproblem is addressed using a greedy algorithm. Numerical results validate the effectiveness of the proposed scheme."
https://arxiv.org/abs/2403.00433,2024-03-01,Jiagu: Optimizing Serverless Computing Resource Utilization with Harmonized Efficiency and Practicability,"['Qingyuan Liu', 'Yanning Yang', 'Dong Du', 'Yubin Xia', 'Ping Zhang', 'Jia Feng', 'James Larus', 'Haibo Chen']","Current serverless platforms struggle to optimize resource utilization due to their dynamic and fine-grained nature. Conventional techniques like overcommitment and autoscaling fall short, often sacrificing utilization for practicability or incurring performance trade-offs. Overcommitment requires predicting performance to prevent QoS violation, introducing trade-off between prediction accuracy and overheads. Autoscaling requires scaling instances in response to load fluctuations quickly to reduce resource wastage, but more frequent scaling also leads to more cold start overheads. This paper introduces Jiagu, which harmonizes efficiency with practicability through two novel techniques. First, pre-decision scheduling achieves accurate prediction while eliminating overheads by decoupling prediction and scheduling. Second, dual-staged scaling achieves frequent adjustment of instances with minimum overhead. We have implemented a prototype and evaluated it using real-world applications and traces from the public cloud platform. Our evaluation shows a 54.8% improvement in deployment density over commercial clouds (with Kubernetes) while maintaining QoS, and 81.0%--93.7% lower scheduling costs and a 57.4%--69.3% reduction in cold start latency compared to existing QoS-aware schedulers in research work."
https://arxiv.org/abs/2403.00432,2024-03-01,Revisiting log-periodic oscillations,['Jean-Marc Luck'],"This work is inspired by a recent study of a two-dimensional stochastic fragmentation model. We show that the configurational entropy of this model exhibits log-periodic oscillations as a function of the sample size, by exploiting an exact recursion relation for the numbers of its jammed configurations. This is seemingly the first statistical-mechanical model where log-periodic oscillations affect the size dependence of an extensive quantity. We then propose and investigate in great depth a one-dimensional analogue of the fragmentation model. This one-dimensional model possesses a critical point, separating a strong-coupling phase where the free energy is super-extensive from a weak-coupling one where the free energy is extensive and exhibits log-periodic oscillations. This model is generalized to a family of one-dimensional models with two integer parameters, which exhibit essentially the same phenomenology."
https://arxiv.org/abs/2403.00431,2024-03-01,Robotic Process Automation as a Driver for Sustainable Innovation and Entrepreneurship,['Petr Prucha'],"Technological innovation plays a crucial role in driving economic growth and development. In this study, we investigate the extent to which technological innovation contributes to a more sustainable future and fosters entrepreneurship. To examine this, we focus on robotic process automation (RPA) highly relevant technology. We conducted a comprehensive analysis by examining the usage of RPA and its impact on environmental, social, and governance (ESG) factors. Our research involved gathering data from the 300 largest companies in terms of market capitalization. We assessed whether these companies used RPA and obtained their corresponding ESG ratings. To investigate the relationship between RPA and ESG, we employed a contingency table analysis, which involved categorizing the data based on ESG ratings. We further used Pearson's Chi-square Test of Independence to assess the impact of RPA on ESG. Our findings revealed a statistically significant association between RPA and ESG ratings, indicating their interconnection. The calculated value for Pearson's Chi-square Test of Independence was 6.54, with a corresponding p-value of 0.0381. This indicates that at a significance level of five percent, the RPA and ESG variables depend on each other. These results suggest that RPA, representative of modern technologies, likely influences the achievement of a sustainable future and the promotion of entrepreneurship. In conclusion, our study provides empirical evidence supporting the notion that technological innovations such as RPA have the potential to positively shape sustainability efforts and entrepreneurial endeavours."
https://arxiv.org/abs/2403.00430,2024-03-01,Introducing locality in some generalized AG codes,['Bastien Pacifico'],"In 1999, Xing, Niederreiter and Lam introduced a generalization of AG codes using the evaluation at non-rational places of a function field. In this paper, we show that one can obtain a locality parameter $r$ in such codes by using only non-rational places of degrees at most $r$. This is, up to the author's knowledge, a new way to construct locally recoverable codes (LRCs). We give an example of such a code reaching the Singleton-like bound for LRCs, and show the parameters obtained for some longer codes over $\mathbb F_3$. We then investigate similarities with certain concatenated codes. Contrary to previous methods, our construction allows one to obtain directly codes whose dimension is not a multiple of the locality. Finally, we give an asymptotic study using the Garcia-Stichtenoth tower of function fields, for both our construction and a construction of concatenated codes. We give explicit infinite families of LRCs with locality 2 over any finite field of cardinality greater than 3 following our new approach."
https://arxiv.org/abs/2403.00429,2024-03-01,Population Power Curves in ASCA with Permutation Testing,"['Jose Camacho', 'Michael Sorochan Armstrong']","In this paper, we revisit the Power Curves in ANOVA Simultaneous Component Analysis (ASCA) based on permutation testing, and introduce the Population Curves derived from population parameters describing the relative effect among factors and interactions. We distinguish Relative from Absolute Population Curves, where the former represent statistical power in terms of the normalized effect size between structure and noise, and the latter in terms of the sample size. Relative Population Curves are useful to find the optimal ASCA model (e.g., fixed/random factors, crossed/nested relationships, interactions, the test statistic, transformations, etc.) for the analysis of an experimental design at hand. Absolute Population Curves are useful to determine the sample size and the optimal number of levels for each factor during the planning phase on an experiment. We illustrate both types of curves through simulation. We expect Population Curves to become the go-to approach to plan the optimal analysis pipeline and the required sample size in an omics study analyzed with ASCA."
https://arxiv.org/abs/2403.00428,2024-03-01,Gauge equivalence of 1+1 Calogero-Moser-Sutherland field theory and higher rank trigonometric Landau-Lifshitz model,"['K. Atalikov', 'A. Zotov']","We consider the classical integrable 1+1 trigonometric ${\rm gl}_N$ Landau-Lifshitz models constructed by means of quantum $R$-matrices satisfying also the associative Yang-Baxter equation. It is shown that 1+1 field analogue of the trigonometric Calogero-Moser-Sutherland model is gauge equivalent to the Landau-Lifshitz model, which arises from the Antonov-Hasegawa-Zabrodin trigonometric non-standard $R$-matrix. The latter generalizes the Cherednik's 7-vertex $R$-matrix in ${\rm GL}_2$ case to the case of ${\rm GL}_N$. Explicit change of variables between the 1+1 models is obtained."
https://arxiv.org/abs/2403.00427,2024-03-01,Production of Resonances in Partial Chemical Equilibrium,"['Boris Tomasik', 'Sandor Lokos']","Within the model of partial chemical equilibrium (PCE) we calculate the multiplicity ratios of selected unstable resonances to given stable species. We focus on those ratios that have been measured either in Pb+Pb collisions at the LHC or in Au+Au collisions at the top RHIC energy. The model provides an interpretation how in an expanding hadronic fireball with decreasing temperature the final numbers of stable hadrons after decays of all resonances remain unchanged. Each stable species acquires its own chemical potential and the resonances are kept in equilibrium with them. Multiplicities of unstable resonances provide a test of this scenario. We observe that the ratios of $K^{*}/K$ and $Ï^0/Ï$ fit reasonably well into the picture of single kinetic freeze-out of the single-particle spectra, but the $Ï$-meson and hyperon resonances are not reproduced by this model."
https://arxiv.org/abs/2403.00426,2024-03-01,Deep Learning Computed Tomography based on the Defrise and Clack Algorithm,"['Chengze Ye', 'Linda-Sophie Schneider', 'Yipeng Sun', 'Andreas Maier']","This study presents a novel approach for reconstructing cone beam computed tomography (CBCT) for specific orbits using known operator learning. Unlike traditional methods, this technique employs a filtered backprojection type (FBP-type) algorithm, which integrates a unique, adaptive filtering process. This process involves a series of operations, including weightings, differentiations, the 2D Radon transform, and backprojection. The filter is designed for a specific orbit geometry and is obtained using a data-driven approach based on deep learning. The approach efficiently learns and optimizes the orbit-related component of the filter. The method has demonstrated its ability through experimentation by successfully learning parameters from circular orbit projection data. Subsequently, the optimized parameters are used to reconstruct images, resulting in outcomes that closely resemble the analytical solution. This demonstrates the potential of the method to learn appropriate parameters from any specific orbit projection data and achieve reconstruction. The algorithm has demonstrated improvement, particularly in enhancing reconstruction speed and reducing memory usage for handling specific orbit reconstruction."
https://arxiv.org/abs/2403.00425,2024-03-01,HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding,"['Zhaorun Chen', 'Zhuokai Zhao', 'Hongyin Luo', 'Huaxiu Yao', 'Bo Li', 'Jiawei Zhou']","While large vision-language models (LVLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, they invariably suffer from object hallucinations (OH). We introduce HALC, a novel decoding algorithm designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal visual information in vision-language tasks and operates on both local and global contexts simultaneously. Specifically, HALC integrates a robust auto-focal grounding mechanism (locally) to correct hallucinated tokens on the fly, and a specialized beam search algorithm (globally) to significantly reduce OH while preserving text generation quality. Additionally, HALC can be integrated into any LVLMs as a plug-and-play module without extra training. Extensive experimental studies demonstrate the effectiveness of HALC in reducing OH, outperforming state-of-the-arts across four benchmarks."
https://arxiv.org/abs/2403.00424,2024-03-01,Data-Based Control of Continuous-Time Linear Systems with Performance Specifications,"['Victor G. Lopez', 'Matthias A. MÃ¼ller']","The design of direct data-based controllers has become a fundamental part of control theory research in the last few years. In this paper, we consider three classes of data-based state feedback control problems for linear systems. These control problems are such that, besides stabilization, some additional performance requirements must be satisfied. First, we formulate and solve a trajectory-reference control problem, on which desired closed-loop trajectories are known and a controller that allows the system to closely follow those trajectories is computed. Then, in the area of data-based optimal control, we solve two different problems: the inverse problem of optimal control, and the solution of the LQR problem for continuous-time systems. Finally, we consider the case in which the precise position of the desired poles of the closed-loop system is known, and introduce a data-based variant of a robust pole-placement procedure. Although we focus on continuous-time systems, all of the presented methods can also be easily formulated for the discrete-time case. The applicability of the proposed methods is tested using numerical simulations."
https://arxiv.org/abs/2403.00423,2024-03-01,Validation of ML-UQ calibration statistics using simulated reference values: a sensitivity analysis,['Pascal Pernot'],"Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration statistics do not have predefined reference values and are mostly used in comparative studies. In consequence, calibration is almost never validated and the diagnostic is left to the appreciation of the reader. Simulated reference values, based on synthetic calibrated datasets derived from actual uncertainties, have been proposed to palliate this problem. As the generative probability distribution for the simulation of synthetic errors is often not constrained, the sensitivity of simulated reference values to the choice of generative distribution might be problematic, shedding a doubt on the calibration diagnostic. This study explores various facets of this problem, and shows that some statistics are excessively sensitive to the choice of generative distribution to be used for validation when the generative distribution is unknown. This is the case, for instance, of the correlation coefficient between absolute errors and uncertainties (CC) and of the expected normalized calibration error (ENCE). A robust validation workflow to deal with simulated reference values is proposed."
https://arxiv.org/abs/2403.00422,2024-03-01,Inference for Interval-Identified Parameters Selected from an Estimated Set,"['Sukjin Han', 'Adam McCloskey']","Interval identification of parameters such as average treatment effects, average partial effects and welfare is particularly common when using observational data and experimental data with imperfect compliance due to the endogeneity of individuals' treatment uptake. In this setting, a treatment or policy will typically become an object of interest to the researcher when it is either selected from the estimated set of best-performers or arises from a data-dependent selection rule. In this paper, we develop new inference tools for interval-identified parameters chosen via these forms of selection. We develop three types of confidence intervals for data-dependent and interval-identified parameters, discuss how they apply to several examples of interest and prove their uniform asymptotic validity under weak assumptions."
https://arxiv.org/abs/2403.00421,2024-03-01,Monte Carlo based techniques for quantum magnets with long-range interactions,"['P. Adelhardt', 'J. A. Koziol', 'A. Langheld', 'K. P. Schmidt']","Long-range interactions are relevant for a large variety of quantum systems in quantum optics and condensed matter physics. In particular, the control of quantum-optical platforms promises to gain deep insights in quantum-critical properties induced by the long-range nature of interactions. From a theoretical perspective, long-range interactions are notoriously complicated to treat. Here, we give an overview of recent advancements to investigate quantum magnets with long-range interactions focusing on two techniques based on Monte Carlo integration. First, the method of perturbative continuous unitary transformations where classical Monte Carlo integration is applied within the embedding scheme of white graphs. This linked-cluster expansion allows to extract high-order series expansions of energies and observables in the thermodynamic limit. Second, stochastic series expansion quantum Monte Carlo which enables calculations on large finite systems. Finite-size scaling can then be used to determine physical properties of the infinite system. In recent years, both techniques have been applied successfully to one- and two-dimensional quantum magnets involving long-range Ising, XY, and Heisenberg interactions on various bipartite and non-bipartite lattices. Here, we summarise the obtained quantum-critical properties including critical exponents for all these systems in a coherent way. Further, we review how long-range interactions are used to study quantum phase transitions above the upper critical dimension and the scaling techniques to extract these quantum critical properties from the numerical calculations."
https://arxiv.org/abs/2403.00420,2024-03-01,Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey,"['Lucas Schott', 'Josephine Delas', 'Hatem Hajri', 'Elies Gherbi', 'Reda Yaich', 'Nora Boulahia-Cuppens', 'Frederic Cuppens', 'Sylvain Lamprier']","Deep Reinforcement Learning (DRL) is an approach for training autonomous agents across various complex environments. Despite its significant performance in well known environments, it remains susceptible to minor conditions variations, raising concerns about its reliability in real-world applications. To improve usability, DRL must demonstrate trustworthiness and robustness. A way to improve robustness of DRL to unknown changes in the conditions is through Adversarial Training, by training the agent against well suited adversarial attacks on the dynamics of the environment. Addressing this critical issue, our work presents an in-depth analysis of contemporary adversarial attack methodologies, systematically categorizing them and comparing their objectives and operational mechanisms. This classification offers a detailed insight into how adversarial attacks effectively act for evaluating the resilience of DRL agents, thereby paving the way for enhancing their robustness."
https://arxiv.org/abs/2403.00419,2024-03-01,Majorana zero-modes in a dissipative Rashba nanowire,"['Arnob Kumar Ghosh', 'Annica M. Black-Schaffer']","Condensed matter systems are continuously subjected to dissipation, which often has adverse effects on quantum phenomena. We focus on the impact of dissipation on a superconducting Rashba nanowire. We reveal that the system can still host Majorana zero-modes (MZMs) with a finite lifetime in the presence of dissipation. Most interestingly, dissipation can also generate two kinds of dissipative boundary states: four robust zero-modes (RZMs) and two MZMs, in the regime where the non-dissipative system is topologically trivial. The MZMs appear via bulk gap closing and are topologically characterized by a winding number. The RZMs are not associated with any bulk states and possess no winding number, but their emergence is instead tied to exceptional points. Further, we confirm the stability of the dissipation-induced RZMs and MZMs in the presence of random disorder. Our study paves the way for both realizing and stabilizing MZMs in an experimental setup, driven by dissipation."
https://arxiv.org/abs/2403.00418,2024-03-01,LLMs for Targeted Sentiment in News Headlines: Exploring Different Levels of Prompt Prescriptiveness,"['Jana JuroÅ¡', 'Laura Majer', 'Jan Å najder']","News headlines often evoke sentiment by intentionally portraying entities in particular ways, making targeted sentiment analysis (TSA) of headlines a worthwhile but difficult task. Fine-tuned encoder models show satisfactory TSA performance, but their background knowledge is limited, and they require a labeled dataset. LLMs offer a potentially universal solution for TSA due to their broad linguistic and world knowledge along with in-context learning abilities, yet their performance is heavily influenced by prompt design. Drawing parallels with annotation paradigms for subjective tasks, we explore the influence of prompt design on the performance of LLMs for TSA of news headlines. We evaluate the predictive accuracy of state-of-the-art LLMs using prompts with different levels of prescriptiveness, ranging from plain zero-shot to elaborate few-shot prompts matching annotation guidelines. Recognizing the subjective nature of TSA, we evaluate the ability of LLMs to quantify predictive uncertainty via calibration error and correlation to human inter-annotator agreement. We find that, except for few-shot prompting, calibration and F1-score improve with increased prescriptiveness, but the optimal level depends on the model."
https://arxiv.org/abs/2403.00417,2024-03-01,Rethinking Tokenization: Crafting Better Tokenizers for Large Language Models,['Jinbiao Yang'],"Tokenization significantly influences language models(LMs)' performance. This paper traces the evolution of tokenizers from word-level to subword-level, analyzing how they balance tokens and types to enhance model adaptability while controlling complexity. Despite subword tokenizers like Byte Pair Encoding (BPE) overcoming many word tokenizer limitations, they encounter difficulties in handling non-Latin languages and depend heavily on extensive training data and computational resources to grasp the nuances of multiword expressions (MWEs). This article argues that tokenizers, more than mere technical tools, should drawing inspiration from the cognitive science about human language processing. This study then introduces the ""Principle of Least Effort"" from cognitive science, that humans naturally seek to reduce cognitive effort, and discusses the benefits of this principle for tokenizer development. Based on this principle, the paper proposes that the Less-is-Better (LiB) model could be a new approach for LLM tokenizer. The LiB model can autonomously learn an integrated vocabulary consisting of subwords, words, and MWEs, which effectively reduces both the numbers of tokens and types. Comparative evaluations show that the LiB tokenizer outperforms existing word and BPE tokenizers, presenting an innovative method for tokenizer development, and hinting at the possibility of future cognitive science-based tokenizers being more efficient."
https://arxiv.org/abs/2403.00416,2024-03-01,Data-efficient Event Camera Pre-training via Disentangled Masked Modeling,"['Zhenpeng Huang', 'Chao Li', 'Hao Chen', 'Yongjian Deng', 'Yifeng Geng', 'Limin Wang']","In this paper, we present a new data-efficient voxel-based self-supervised learning method for event cameras. Our pre-training overcomes the limitations of previous methods, which either sacrifice temporal information by converting event sequences into 2D images for utilizing pre-trained image models or directly employ paired image data for knowledge distillation to enhance the learning of event streams. In order to make our pre-training data-efficient, we first design a semantic-uniform masking method to address the learning imbalance caused by the varying reconstruction difficulties of different regions in non-uniform data when using random masking. In addition, we ease the traditional hybrid masked modeling process by explicitly decomposing it into two branches, namely local spatio-temporal reconstruction and global semantic reconstruction to encourage the encoder to capture local correlations and global semantics, respectively. This decomposition allows our selfsupervised learning method to converge faster with minimal pre-training data. Compared to previous approaches, our self-supervised learning method does not rely on paired RGB images, yet enables simultaneous exploration of spatial and temporal cues in multiple scales. It exhibits excellent generalization performance and demonstrates significant improvements across various tasks with fewer parameters and lower computational costs."
https://arxiv.org/abs/2403.00415,2024-03-01,Cyclic Higgs bundles and the Toledo invariant,"['Oscar GarcÃ­a-Prada', 'Miguel GonzÃ¡lez']","Let $G$ be a complex semisimple Lie group and $\mathfrak g$ its Lie algebra. In this paper, we study a special class of cyclic Higgs bundles constructed from a $\mathbb Z$-grading $\mathfrak g = \bigoplus_{j=1-m}^{m-1}\mathfrak g_j$ by using the natural representation $G_0 \to GL(\mathfrak g_1 \oplus \mathfrak g_{1-m})$, where $G_0 \le G$ is the connected subgroup corresponding to $\mathfrak g_0$. The resulting Higgs pairs include $G^{\mathbb R}$-Higgs bundles for $G^{\mathbb R} \le G$ a real form of Hermitian type (in the case $m=2$) and fixed points of the ${\mathbb C}^*$-action on $G$-Higgs bundles (in the case where the Higgs field vanishes along $\mathfrak g_{1-m}$). In both of these situations a topological invariant with interesting properties, known as the Toledo invariant, has been defined and studied in the literature. This paper generalises its definition and properties to the case of arbitrary $(G_0,\mathfrak g_1 \oplus \mathfrak g_{1-m})$-Higgs pairs, which give rise to families of cyclic Higgs bundles. The results are applied to the example with $m=3$ that arises from the theory of quaternion-KÃ¤hler symmetric spaces."
https://arxiv.org/abs/2403.00414,2024-03-01,A 'MeerKAT-meets-LOFAR' study of the complex multi-component (mini-)halo in the extreme sloshing cluster Abell 2142,"['C. J. Riseley', 'A. Bonafede', 'L. Bruno', 'A. Botteon', 'M. Rossetti', 'N. Biava', 'E. Bonnassieux', 'F. Loi', 'T. Vernstrom', 'M. Balboni']","Clusters of galaxies are turbulent environments, whether merging systems with a turbulent intracluster medium (ICM) or relaxed systems sloshing within the potential well. In many such clusters, diffuse radio sources associated with the ICM are found: radio haloes and mini-haloes. Abell 2142 is a rich cluster undergoing extreme core sloshing, generating four cold fronts and a complex multi-component radio halo. Recent work revealed three halo components which span 2.4 Mpc. Particle acceleration on such scales is poorly understood, and requires high-quality multi-frequency data to understand. We use new deep MeerKAT L-band (1283 MHz) observations, combined with LOFAR HBA (143 MHz) data and X-ray data from XMM-Newton and Chandra to study the spectrum of the halo and the connection between the thermal and non-thermal components of the ICM. We detect the third halo component for the first time at 1283 MHz and confirm its ultra-steep spectrum nature, recovering $Î±_{\rm H3, total} = -1.68 \pm 0.10$. All components follow power-law spectra which steepen toward the cluster outskirts. We profile the halo along three directions, finding evidence of asymmetry and spectral steepening perpendicular to the main axis of the cluster. Our thermal/non-thermal investigation shows sub-linear correlations that are steeper at 1283 MHz than 143 MHz, and we find different connections in different components of the halo. We find both a moderate anti-correlation (H1, the core) and positive correlation (H2, the ridge) between radio spectral index and X-ray temperature. Our results are broadly consistent with an interpretation of inhomogeneous turbulent (re-)acceleration. However, the anti-correlation between radio spectral index and X- ray temperature in the cluster core is challenging to explain; the presence of three cold fronts and a generally lower temperature may provide the foundations of an explanation."
https://arxiv.org/abs/2403.00413,2024-03-01,Mean Field Games Incorporating Carryover Effects: Optimizing Advertising Models,"['Michele Ricciardi', 'Mauro Rosestolato']","We consider a class of optimal control problems that arise in connection with optimal advertising under uncertainty. Two main features appear in the model: a delay in the control variable driving the state dynamics; a mean-field term both in the state dynamics and in the utility functional, taking into account for other agents. We interpret the model in a competitive environment, hence we set it in the framework of Mean Field Games. We rephrase the problem in an infinite dimensional setting, in order to obtain the associated Mean Field Game system. Finally, we specify the problem to a simple case, and solve it providing an explicit solution."
https://arxiv.org/abs/2403.00412,2024-03-01,Improved Bounds for Point Selections and Halving Hyperplanes in Higher Dimensions,['Natan Rubin'],"Let $(P,E)$ be a $(d+1)$-uniform geometric hypergraph, where $P$ is an $n$-point set in general position in $\mathbb{R}^d$ and $E\subseteq {P\choose d+1}$ is a collection of $Îµ{n\choose d+1}$ $d$-dimensional simplices with vertices in $P$, for $0<Îµ\leq 1$. We show that there is a point $x\in {\mathbb R}^d$ that pierces $\displaystyle Î©\left(Îµ^{(d^4+d)(d+1)+Î´}{n\choose d+1}\right)$ simplices in $E$, for any fixed $Î´>0$. This is a dramatic improvement in all dimensions $d\geq 3$, over the previous lower bounds of the general form $\displaystyle Îµ^{(cd)^{d+1}}n^{d+1}$, which date back to the seminal 1991 work of Alon, BÃ¡rÃ¡ny, FÃ¼redi and Kleitman."
https://arxiv.org/abs/2403.00411,2024-03-01,Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with Fact-Checking in Turkish,"['Recep Firat Cekinel', 'Pinar Karagoz', 'Cagri Coltekin']","The rapid spread of misinformation through social media platforms has raised concerns regarding its impact on public opinion. While misinformation is prevalent in other languages, the majority of research in this field has concentrated on the English language. Hence, there is a scarcity of datasets for other languages, including Turkish. To address this concern, we have introduced the FCTR dataset, consisting of 3238 real-world claims. This dataset spans multiple domains and incorporates evidence collected from three Turkish fact-checking organizations. Additionally, we aim to assess the effectiveness of cross-lingual transfer learning for low-resource languages, with a particular focus on Turkish. We demonstrate in-context learning (zero-shot and few-shot) performance of large language models in this context. The experimental results indicate that the dataset has the potential to advance research in the Turkish language."
https://arxiv.org/abs/2403.00410,2024-03-01,Assessing objective quality metrics for JPEG and MPEG point cloud coding,"['Davi Lazzarotto', 'Michela Testolina', 'Touradj Ebrahimi']","As applications using immersive media gain increasing attention from both academia and industry, research in the field of point cloud compression has greatly intensified in recent years, leading to the development of the MPEG compression standards V-PCC and G-PCC, as well as the more recent JPEG Pleno learning-based point cloud coding. Each of the above-mentioned standards is based on a different algorithm, introducing distinct types of degradation that may impair the quality of experience when high lossy compression is applied. Although the impact on perceptual quality could be accurately evaluated during subjective quality assessment experiments, objective quality metrics serve as predictors of the visually perceived quality and provide similarity scores without human intervention. Nevertheless, their accuracy can be susceptible to the characteristics of the evaluated media as well as to the type and intensity of the added distortion. While the performance of multiple state-of-the-art objective quality metrics has already been evaluated through their correlation with subjective scores obtained in the presence of artifacts produced by the MPEG standards, no study has evaluated how metrics perform with the more recent JPEG Pleno point cloud coding. In this paper, a study is conducted to benchmark the performance of a large set of objective quality metrics in a subjective dataset including distortions produced by JPEG and MPEG codecs. The dataset also contains three different trade-offs between color and geometry compression for each codec, adding another dimension to the analysis. Performance indexes are computed over the entire dataset but also after splitting according to the codec and to the original model, resulting in detailed insights about the overall performance of each visual quality predictor as well as their cross-content and cross-codec generalization ability."
https://arxiv.org/abs/2403.00409,2024-03-01,Provably Robust DPO: Aligning Language Models with Noisy Feedback,"['Sayak Ray Chowdhury', 'Anush Kini', 'Nagarajan Natarajan']","Learning from preference-based feedback has recently gained traction as a promising approach to align language models with human interests. While these aligned generative models have demonstrated impressive capabilities across various tasks, their dependence on high-quality human preference data poses a bottleneck in practical applications. Specifically, noisy (incorrect and ambiguous) preference pairs in the dataset might restrict the language models from capturing human intent accurately. While practitioners have recently proposed heuristics to mitigate the effect of noisy preferences, a complete theoretical understanding of their workings remain elusive."
https://arxiv.org/abs/2403.00408,2024-03-01,Semi-Local Exotic Lagrangian Tori in Dimension Four,"['JoÃ© Brendel', 'Johannes Hauber', 'Joel Schmitz']","We study exotic Lagrangian tori in dimension four. In certain Stein domains $B_{dpq}$ (which naturally appear in almost toric fibrations) we find $d+1$ families of monotone Lagrangian tori which are mutually distinct, up to symplectomorphisms. We prove that these remain distinct under embeddings of $B_{dpq}$ into geometrically bounded symplectic four-manifolds. We show that there are infinitely many different such embeddings when $X$ is compact and (almost) toric and hence conclude that $X$ contains arbitrarily many Lagrangian tori which are distinct up to symplectomorphisms of $X$. In dimension four arbitrarily many different Lagrangian tori were previously known only in del Pezzo surfaces."
https://arxiv.org/abs/2403.00407,2024-03-01,Configurations in the Euclidean space related to the 3D genome reconstruction problem from partially phased data,['Annachiara Korchmaros'],"A motivation for studying the following problems comes from applications to Biology; see \cite{cifuentes20233d}. In the $3$-dimensional Euclidean space ${\bf{E}}^3$, fix six pairwise distinct points \begin{equation*} \label{eqA} \begin{array}{ccc} A=(a_1,a_2,a_3), & B=(b_1,b_2,b_3), & C=(c_1,c_2,c_3), \\ D=(d_1,d_2,d_3), & E=(e_1,e_2,e_3), & F=(f_1,f_2,f_3) \end{array} \end{equation*} together with two further points $X^*=(x_1^*,x_2^*,x_3^*)$ and $Y^*=(y_1^*,y_2^*,y_3^*)$ in $\mathbf{E}^3$. We aim to show that System $(*)$ consisting of the following six equations in the unknowns $X=(x_1,x_2,x_3)$ and $Y=(y_1,y_2,y_3)$ \begin{equation} \label{egy} \frac{1}{\|X-T\|^2} +\frac{1}{\|Y-T\|^2}=\frac{1}{\|X^*-T\|^2} +\frac{1}{\|Y^*-T\|^2}, \quad T\in\{A,B,\ldots,F\}. \end{equation} has only finitely many solutions provided that both of the following two conditions are satisfied: (i) no four of the fixed points $A,B,C,D,E,F$ are coplanar; (ii) no four of the six spheres of center $T$ and radius $1/\sqrt{k_T}$ with \begin{equation} \label{kxy} k_T=\frac{1}{\|X^*-T\|^2} +\frac{1}{\|Y^*-T\|^2} \end{equation} share a common point in ${\bf{E}}^3$. Furthermore, we exhibit configurations $ABCDEFX^*Y^*$, showing that (i) is also necessary. This result is an improvement on \cite[Theorem 1]{cifuentes20233d} where the finiteness of solutions of System $(*)$ is only ensured for sufficiently generic choices of the points $A,B,\ldots,F,X^*,Y^*.$ We also show if System $(*)$ has finitely many solutions and System $(*)$ extended with $T\in\{A,B,\ldots,F,G\}$ has some solutions other than $(X^*,Y^*)$ and $(Y^*,X^*)$ then $G$ lies on an explicitly given affine variety $W\subsetneqq \mathbb{R}^3$ only depending on $\{A,B,\ldots,F\}$. This result proves the \cite[Conjecture 1]{cifuentes20233d}."
https://arxiv.org/abs/2403.00406,2024-03-01,Adaptive Restructuring of Merkle and Verkle Trees for Enhanced Blockchain Scalability,"['Oleksandr Kuznetsov', 'Dzianis Kanonik', 'Alex Rusnak', 'Anton Yezhov', 'Oleksandr Domin']","The scalability of blockchain technology remains a pivotal challenge, impeding its widespread adoption across various sectors. This study introduces an innovative approach to address this challenge by proposing the adaptive restructuring of Merkle and Verkle trees, fundamental components of blockchain architecture responsible for ensuring data integrity and facilitating efficient verification processes. Unlike traditional static tree structures, our adaptive model dynamically adjusts the configuration of these trees based on usage patterns, significantly reducing the average path length required for verification and, consequently, the computational overhead associated with these processes. Through a comprehensive conceptual framework, we delineate the methodology for adaptive restructuring, encompassing both binary and non-binary tree configurations. This framework is validated through a series of detailed examples, demonstrating the practical feasibility and the efficiency gains achievable with our approach. Moreover, we present a comparative analysis with existing scalability solutions, highlighting the unique advantages of adaptive restructuring in terms of simplicity, security, and efficiency enhancement without introducing additional complexities or dependencies. This study's implications extend beyond theoretical advancements, offering a scalable, secure, and efficient method for blockchain data verification that could facilitate broader adoption of blockchain technology in finance, supply chain management, and beyond. As the blockchain ecosystem continues to evolve, the principles and methodologies outlined herein are poised to contribute significantly to its growth and maturity."
https://arxiv.org/abs/2403.00405,2024-03-01,SoK: Cross-Chain Bridging Architectural Design Flaws and Mitigations,"['Jakob Svennevik Notland', 'Jinguye Li', 'Mariusz Nowostawski', 'Peter Halland Haro']","Cross-chain bridges are solutions that enable interoperability between heterogeneous blockchains. In contrast to the underlying blockchains, the bridges often provide inferior security guarantees and have been targets of hacks causing damage in the range of 1.5 to 2 billion USD in 2022. The current state of bridge architectures is that they are ambiguous, and there is next to no notion of how different architectures and their components are related to different vulnerabilities. Throughout this study, we have analysed 60 different bridges and 34 bridge exploits in the last three years (2021-2023). Our analyses identified 13 architectural components of the bridges. We linked the components to eight types of vulnerabilities, also called design flaws. We identified prevention measures and proposed 11 impact reduction measures based on the existing and possible countermeasures to address the imminent exploits of the design flaws. The results are meant to be used as guidelines for designing and implementing secure cross-chain bridge architectures, preventing design flaws, and mitigating the negative impacts of exploits."
https://arxiv.org/abs/2403.00404,2024-03-01,Secure Routing for Mobile Ad hoc Networks,"['Panagiotis Papadimitratos', 'Zygmunt J. Haas']","The emergence of the Mobile Ad Hoc Networking (MANET) technology advocates self-organized wireless interconnection of communication devices that would either extend or operate in concert with the wired networking infrastructure or, possibly, evolve to autonomous networks. In either case, the proliferation of MANET-based applications depends on a multitude of factors, with trustworthiness being one of the primary challenges to be met. Despite the existence of well-known security mechanisms, additional vulnerabilities and features pertinent to this new networking paradigm might render such traditional solutions inapplicable. In particular, the absence of a central authorization facility in an open and distributed communication environment is a major challenge, especially due to the need for cooperative network operation. In particular, in MANET, any node may compromise the routing protocol functionality by disrupting the route discovery process. In this paper, we present a route discovery protocol that mitigates the detrimental effects of such malicious behavior, as to provide correct connectivity information. Our protocol guarantees that fabricated, compromised, or replayed route replies would either be rejected or never reach back the querying node. Furthermore, the protocol responsiveness is safeguarded under different types of attacks that exploit the routing protocol itself. The sole requirement of the proposed scheme is the existence of a security association between the node initiating the query and the sought destination. Specifically, no assumption is made regarding the intermediate nodes, which may exhibit arbitrary and malicious behavior. The scheme is robust in the presence of a number of non-colluding nodes, and provides accurate routing information in a timely manner."
https://arxiv.org/abs/2403.00403,2024-03-01,Fractal interpolation in the context of prediction accuracy optimization,"['Alexandra Baicoianu', 'Cristina Gabriela GavrilÄ', 'Cristina Maria Pacurar', 'Victor Dan Pacurar']","This paper focuses on the hypothesis of optimizing time series predictions using fractal interpolation techniques. In general, the accuracy of machine learning model predictions is closely related to the quality and quantitative aspects of the data used, following the principle of \textit{garbage-in, garbage-out}. In order to quantitatively and qualitatively augment datasets, one of the most prevalent concerns of data scientists is to generate synthetic data, which should follow as closely as possible the actual pattern of the original data."
https://arxiv.org/abs/2403.00402,2024-03-01,Spatio-temporal reconstruction of substance dynamics using compressed sensing in multi-spectral magnetic resonance spectroscopic imaging,"['Utako Yamamoto', 'Hirohiko Imai', 'Kei Sano', 'Masayuki Ohzeki', 'Tetsuya Matsuda', 'Toshiyuki Tanaka']","The objective of our study is to observe dynamics of multiple substances in vivo with high temporal resolution from multi-spectral magnetic resonance spectroscopic imaging (MRSI) data. The multi-spectral MRSI can effectively separate spectral peaks of multiple substances and is useful to measure spatial distributions of substances. However it is difficult to measure time-varying substance distributions directly by ordinary full sampling because the measurement requires a significantly long time. In this study, we propose a novel method to reconstruct the spatio-temporal distributions of substances from randomly undersampled multi-spectral MRSI data on the basis of compressed sensing (CS) and the partially separable function model with base spectra of substances. In our method, we have employed spatio-temporal sparsity and temporal smoothness of the substance distributions as prior knowledge to perform CS. The effectiveness of our method has been evaluated using phantom data sets of glass tubes filled with glucose or lactate solution in increasing amounts over time and animal data sets of a tumor-bearing mouse to observe the metabolic dynamics involved in the Warburg effect in vivo. The reconstructed results are consistent with the expected behaviors, showing that our method can reconstruct the spatio-temporal distribution of substances with a temporal resolution of four seconds which is extremely short time scale compared with that of full sampling. Since this method utilizes only prior knowledge naturally assumed for the spatio-temporal distributions of substances and is independent of the number of the spectral and spatial dimensions or the acquisition sequence of MRSI, it is expected to contribute to revealing the underlying substance dynamics in MRSI data already acquired or to be acquired in the future."
https://arxiv.org/abs/2403.00401,2024-03-01,Enhancing Biomechanical Simulations Based on A Posteriori Error Estimates: The Potential of Dual Weighted Residual-Driven Adaptive Mesh Refinement,"['Huu Phuoc Bui', 'Michel Duprez', 'Pierre-Yves Rohan', 'Arnaud Lejeune', 'Stephane P. A. Bordas', 'Marek Bucki', 'Franz Chouly']","The Finite Element Method (FEM) is a well-established procedure for computing approximate solutions to deterministic engineering problems described by partial differential equations. FEM produces discrete approximations of the solution with a discretisation error that can be an be quantified with \emph{a posteriori} error estimates. The practical relevance of error estimates for biomechanics problems, especially for soft tissue where the response is governed by large strains, is rarely addressed. In this contribution, we propose an implementation of \emph{a posteriori} error estimates targeting a user-defined quantity of interest, using the Dual Weighted Residual (DWR) technique tailored to biomechanics. The proposed method considers a general setting that encompasses three-dimensional geometries and model non-linearities, which appear in hyperelastic soft tissues. We take advantage of the automatic differentiation capabilities embedded in modern finite element software, which allows the error estimates to be computed generically for a large class of models and constitutive laws. First we validate our methodology using experimental measurements from silicone samples, and then illustrate its applicability for patient-specific computations of pressure ulcers on a human heel."
https://arxiv.org/abs/2403.00400,2024-03-01,Kron reduction of nonlinear networks,"['Arjan van der Schaft', 'Bart Besselink', 'Anne-Men Huijzer']",Kron reduction is concerned with the elimination of interior nodes of physical network systems such as linear resistor electrical circuits. In this paper it is shown how this can be extended to networks with nonlinear static relations between the variables associated to the edges of the underlying directed graph.
https://arxiv.org/abs/2403.00399,2024-03-01,As Soon as Possible but Rationally,"['VÃ©ronique BruyÃ¨re', 'Christophe Grandmont', 'Jean-FranÃ§ois Raskin']","This paper addresses complexity problems in rational verification and synthesis for multi-player games played on weighted graphs, where the objective of each player is to minimize the cost of reaching a specific set of target vertices. In these games, one player, referred to as the system, declares his strategy upfront. The other players, composing the environment, then rationally make their moves according to their objectives. The rational behavior of these responding players is captured through two models: they opt for strategies that either represent a Nash equilibrium or lead to a play with a Pareto-optimal cost tuple."
https://arxiv.org/abs/2403.00398,2024-03-01,Learning Quadrupedal Locomotion with Impaired Joints Using Random Joint Masking,"['Mincheol Kim', 'Ukcheol Shin', 'Jung-Yup Kim']","Quadrupedal robots have played a crucial role in various environments, from structured environments to complex harsh terrains, thanks to their agile locomotion ability. However, these robots can easily lose their locomotion functionality if damaged by external accidents or internal malfunctions. In this paper, we propose a novel deep reinforcement learning framework to enable a quadrupedal robot to walk with impaired joints. The proposed framework consists of three components: 1) a random joint masking strategy for simulating impaired joint scenarios, 2) a joint state estimator to predict an implicit status of current joint condition based on past observation history, and 3) progressive curriculum learning to allow a single network to conduct both normal gait and various joint-impaired gaits. We verify that our framework enables the Unitree's Go1 robot to walk under various impaired joint conditions in real-world indoor and outdoor environments."
https://arxiv.org/abs/2403.00397,2024-03-01,The Price of Fairness in Bipartite Matching,"['RÃ©mi Castera', 'Felipe Garrido-Lucero', 'Mathieu Molina', 'Simon Mauras', 'Patrick Loiseau', 'Vianney Perchet']","We investigate notions of group fairness in bipartite matching markets involving agents and jobs, where agents are grouped based on sensitive attributes. Employing a geometric approach, we characterize how many agents can be matched in each group, showing that the set of feasible matchings forms a (discrete) polymatroid. We show how we can define weakly-fair matchings geometrically, for which poly-matroid properties imply that they are maximal. Next, we focus on strong fairness notions (inspired by group-fairness metrics in machine learning), where each group gets their exact same fraction of their entitlement, and we explore the Price of Fairness (PoF), i.e., the loss in optimality when imposing such fairness constraints. Importantly, we advocate for the notion of opportunity fairness, where a group entitlement is the maximum number of agents that can be matched without the presence of other competing groups. We show that the opportunity PoF is bounded independently of the number of agents and jobs, but may be linear in the number of groups. Finally, we provide improved bounds with additional structural properties, or with stochastic graphs."
https://arxiv.org/abs/2403.00396,2024-03-01,GLFNET: Global-Local (frequency) Filter Networks for efficient medical image segmentation,"['Athanasios Tragakis', 'Qianying Liu', 'Chaitanya Kaul', 'Swalpa Kumar Roy', 'Hang Dai', 'Fani Deligianni', 'Roderick Murray-Smith', 'Daniele Faccio']","We propose a novel transformer-style architecture called Global-Local Filter Network (GLFNet) for medical image segmentation and demonstrate its state-of-the-art performance. We replace the self-attention mechanism with a combination of global-local filter blocks to optimize model efficiency. The global filters extract features from the whole feature map whereas the local filters are being adaptively created as 4x4 patches of the same feature map and add restricted scale information. In particular, the feature extraction takes place in the frequency domain rather than the commonly used spatial (image) domain to facilitate faster computations. The fusion of information from both spatial and frequency spaces creates an efficient model with regards to complexity, required data and performance. We test GLFNet on three benchmark datasets achieving state-of-the-art performance on all of them while being almost twice as efficient in terms of GFLOP operations."
https://arxiv.org/abs/2403.00395,2024-03-01,Generalized Carleson Embeddings of M{Ã¼}ntz Spaces,"['MickaÃ«l Latocca', 'Vincent Munnier']","This paper establishes Carleson embeddings of M{Ã¼}ntz spaces $M^q_Î$ into weighted Lebesgue spaces $L^p(\mathrm{d}Î¼)$, where $Î¼$ is a Borel regular measure on $[0,1]$ satisfying $Î¼([1-\varepsilon])\lesssim \varepsilon^Î²$. In the case $Î²\geqslant 1$ we show that such measures are exactly the ones for which Carleson embeddings $L^{\frac{p}Î²} \hookrightarrow L^p(\mathrm{d}Î¼)$ hold. The case $Î²\in (0,1)$ is more intricate but we characterize such measures $Î¼$ in terms of a summability condition on their moments. Our proof relies on a generalization of $L^p$ estimates {Ã } la Gurariy-Macaev in the weighted $L^p$ spaces setting, which we think can be of interest in other contexts."
https://arxiv.org/abs/2403.00394,2024-03-01,List-Mode PET Image Reconstruction Using Dykstra-Like Splitting,"['Kibo Ote', 'Fumio Hashimoto', 'Yuya Onishi', 'Yasuomi Ouchi']","To converge the block iterative method in image reconstruction for positron emission tomography (PET), careful control of relaxation parameters is required, which is a challenging task. The automatic determination of relaxation parameters for list-mode reconstructions also remains challenging. Therefore, a different approach than controlling relaxation parameters would be desired by list-mode PET reconstruction. In this study, we propose a list-mode maximum likelihood Dykstra-like splitting PET reconstruction (LM-MLDS). LM-MLDS converges the list-mode block iterative method by adding the distance from an initial image as a penalty term into an objective function. LM-MLDS takes a two-step approach because its performance depends on the quality of the initial image. The first step uses a uniform image as the initial image, and then the second step uses a reconstructed image after one main iteration as the initial image. We evaluated LM-MLDS using simulation and clinical data. LM-MLDS provided a higher peak signal-to-noise ratio and suppressed an oscillation of tradeoff curves between noise and contrast than the other block iterative methods. In a clinical study, LM-MLDS removed the false hotspots at the edge of the axial field of view and improved the image quality of slices covering the top of the head to the cerebellum. LM-MLDS showed different noise properties than the other methods due to Gaussian denoising induced by the proximity operator. The list-mode proximal splitting PET reconstruction is useful not only for optimizing nondifferentiable functions such as total variation but also for converging block iterative methods without controlling relaxation parameters."
https://arxiv.org/abs/2403.00393,2024-03-01,Private Benchmarking to Prevent Contamination and Improve Comparative Evaluation of LLMs,"['Nishanth Chandran', 'Sunayana Sitaram', 'Divya Gupta', 'Rahul Sharma', 'Kashish Mittal', 'Manohar Swaminathan']","Benchmarking is the de-facto standard for evaluating LLMs, due to its speed, replicability and low cost. However, recent work has pointed out that the majority of the open source benchmarks available today have been contaminated or leaked into LLMs, meaning that LLMs have access to test data during pretraining and/or fine-tuning. This raises serious concerns about the validity of benchmarking studies conducted so far and the future of evaluation using benchmarks. To solve this problem, we propose Private Benchmarking, a solution where test datasets are kept private and models are evaluated without revealing the test data to the model. We describe various scenarios (depending on the trust placed on model owners or dataset owners), and present solutions to avoid data contamination using private benchmarking. For scenarios where the model weights need to be kept private, we describe solutions from confidential computing and cryptography that can aid in private benchmarking. Finally, we present solutions the problem of benchmark dataset auditing, to ensure that private benchmarks are of sufficiently high quality."
https://arxiv.org/abs/2403.00392,2024-03-01,Irreducible components of sets of points in the plane that satisfy distance conditions,"['Niels Lubbes', 'Mehdi Makhul', 'Josef Schicho', 'Audie Warren']","For a given graph whose edges are labeled with general real numbers, we consider the set of functions from the vertex set into the Euclidean plane such that the distance between the images of neighbouring vertices is equal to the corresponding edge label. This set of functions can be expressed as the zero set of quadratic polynomials and our main result characterizes the number of complex irreducible components of this zero set in terms of combinatorial properties of the graph. In case the complex components are three-dimensional, then the graph is minimally rigid and the component number is a well-known invariant from rigidity theory. If the components are four-dimensional, then they correspond to one-dimensional coupler curves of flexible planar mechanisms. As an application, we characterize the degree of irreducible components of such coupler curves combinatorially."
https://arxiv.org/abs/2403.00391,2024-03-01,Perturbative global solutions of a large class of cross diffusion systems in any dimension,"['L Desvillettes', 'A Moussa']","This article focuses on a large family of cross-diffusion systems of the form $\partial$ t U-$Î$A(U) = 0, in dimension d $\in$ N * , and where U $\in$ R 2. We show that under natural conditions on the nonlinearity A, those systems have a unique smooth (nonnegative for all components) solution when the initial data are small enough in a suitable norm."
https://arxiv.org/abs/2403.00390,2024-03-01,Deterministic Weighted Automata under Partial Observability,"['Jakub Michaliszyn', 'Jan Otop']","Weighted automata is a basic tool for specification in quantitative verification, which allows to express quantitative features of analysed systems such as resource consumption. Quantitative specification can be assisted by automata learning as there are classic results on Angluin-style learning of weighted automata. The existing work assumes perfect information about the values returned by the target weighted automaton. In assisted synthesis of a quantitative specification, knowledge of the exact values is a strong assumption and may be infeasible. In our work, we address this issue by introducing a new framework of partially-observable deterministic weighted automata, in which weighted automata return intervals containing the computed values of words instead of the exact values. We study the basic properties of this framework with the particular focus on the challenges of"
https://arxiv.org/abs/2403.00389,2024-03-01,Dynamics of helical vortex filaments in non viscous incompressible flows,"['Martin Donati', 'Christophe Lacave', 'Evelyne Miot']","In this paper we study concentrated solutions of the three-dimensional Euler equations in helical symmetry without swirl. We prove that any helical vorticity solution initially concentrated around helices of pairwise distinct radii remains concentrated close to filaments. As suggested by the vortex filament conjecture, we prove that those filaments are translating and rotating helices. Similarly to what is obtained in other frameworks, the localization is weak in the direction of the movement but strong in its normal direction, and holds on an arbitrary long time interval in the naturally rescaled time scale. In order to prove this result, we derive a new explicit formula for the singular part of the Biot-Savart kernel in a two-dimensional reformulation of the problem. This allows us to obtain an appropriate decomposition of the velocity field to reproduce recent methods used to describe the dynamics of vortex rings or point-vortices for the lake equation."
https://arxiv.org/abs/2403.00388,2024-03-01,New Rigidity Results for Critical Metrics of Some Quadratic Curvature Functionals,['Marco Bernardini'],"We prove a new rigidity result for metrics defined on closed smooth $ n $-manifolds that are critical for the quadratic functional $ \mathfrak{F}_{t} $, which depends on the Ricci curvature $ Ric $ and the scalar curvature $ R $, and that satisfy a pinching condition of the form $ Sec > ÎµR $, where $ Îµ$ is a function of $ t $ and $ n $, while $ Sec $ denotes the sectional curvature. In particular, we show that Bach-flat metrics with constant scalar curvature satisfying $ Sec > \frac{1}{48} R $ are Einstein and, by a known result, are isometric to $ \mathbb{S}^{4} $, $ \mathbb{RP}^{4} $ or $ \mathbb{CP}^{2} $."
https://arxiv.org/abs/2403.00387,2024-03-01,"For time-invariant delay systems, global asymptotic stability does not imply uniform global attractivity","['Antoine Chaillet', 'Fabian Wirth', 'Andrii Mironchenko', 'Lucas Brivadis']","Adapting a counterexample recently proposed by J.L. Mancilla-Aguilar and H. Haimovich, we show here that, for time-delay systems, global asymptotic stability does not ensure that solutions converge uniformly to zero over bounded sets of initial states. Hence, the convergence might be arbitrarily slow even if initial states are confined to a bounded set."
https://arxiv.org/abs/2403.00386,2024-03-01,Quantitative estimates of $L^p$ maximal regularity for nonautonomous operators and global existence for quasilinear equations,"['ThÃ©o Belin', 'Pauline Lafitte']","In this work, we obtain quantitative estimates of the continuity constant for the $L^p$ maximal regularity of relatively continuous nonautonomous operators $\mathbb{A} : I \longrightarrow \mathcal{L}(D,X)$, where $D \subset X$ densely and compactly. They allow in particular to establish a new general growth condition for the global existence of strong solutions of Cauchy problems for nonlocal quasilinear equations for a certain class of nonlinearities $u \longrightarrow \mathbb{A}(u)$. The estimates obtained rely on the precise asymptotic analysis of the continuity constant with respect to perturbations of the operator of the form $\mathbb{A}(\cdot) + Î»I$ as $Î»\longrightarrow \pm \infty$. A complementary work in preparation supplements this abstract inquiry with an application of these results to nonlocal parabolic equations in noncylindrical domains depending on the time variable."
https://arxiv.org/abs/2403.00385,2024-03-01,Classical and Bayesian statistical methods for low-level metrology,['Guillaume Manificat'],"This document presents the statistical methods used to process low-level measurements in the presence of noise. These methods can be classical or Bayesian. The question is placed in the general framework of the problem of nuisance parameters, one of the canonical problems of statistical inference. By using a simple criterion proposed by Bolstad (2007), it is possible to define statistically significant results during a measurement process (act of measuring in the vocabulary of metrology). This result is similar for a classic paradigm (called ""frequentist"") or Bayesian: the presence of zero in the interval considered (confidence or credibility). It is shown that in the case of homoskedastic Gaussians, the commonly used results are found. The case of Poisson distributions is then considered. In the case of heteroscedastic Gaussians, which is that of radioactivity measurement, we can consider them as Poisson laws in the limit of large counts. The results are different from those commonly used, and in particular those from standards (ISO 11929). Their statistical performances, characterized by simulation, are better and are well verified experimentally. This is confirmed theoretically by the use of the Neyman-Pearson lemma which makes it possible to formally determine the statistical tests with the best performances. These results also make it possible to understand the paradox of the possible divergence of the detection limit. It is also formally shown that the confidence intervals thus calculated by getting rid of the nuisance parameter according to established methods result in the commonly used confidence interval. To our knowledge, this constitutes the first formal derivation of these confidence intervals. This method is based on keeping the measurement results whether they are significant or not (not censoring them). This is recommended in several standards or documents, is compatible with the ISO 11929 standard and is in line with recent proposals in the field of statistics. On the other hand, all the information necessary to determine whether a measurement result is significant or not remains available. The conservation and restitution of all results is currently applied in the USA. The textbook case of the WIPP incident makes it possible to ensure favorable public perception. The implications and applications of this method in different fields are finally discussed."
https://arxiv.org/abs/2403.00384,2024-03-01,Penalization of Galton Watson trees with marked vertices,"['Romain Abraham', 'Sonia Boulal', 'Pierre Debs']","We consider a Galton-Watson tree where each node is marked independently of each others with a probability depending on itsout-degree. Using a penalization method, we exhibit new martingales where the number of marks up to level n -- 1 appears. Then, we use these martingales to define new probability measures via a Girsanov transformation and describe the distribution of the random trees under these new probabilities."
https://arxiv.org/abs/2403.00383,2024-03-01,The Mollified (Discrete) Uniform Distribution and its Applications,['Christian H. WeiÃ'],"The mollified uniform distribution is rediscovered, which constitutes a ``soft'' version of the continuous uniform distribution. Important stochastic properties are derived and used to demonstrate potential fields of applications. For example, it constitutes a model covering platykurtic, mesokurtic and leptokurtic shapes. Its cumulative distribution function may also serve as the soft-clipping response function for defining generalized linear models with approximately linear dependence. Furthermore, it might be considered for teaching, as an appealing example for the convolution of random variables. Finally, a discrete type of mollified uniform distribution is briefly discussed as well."
https://arxiv.org/abs/2403.00382,2024-03-01,Optimization of 3-D flight trajectory of variable trim kites for airborne wind energy production,"['Rafal Noga', 'Xaver Paulig', 'Lukas Schmidt', 'Benjamin Karg', 'Manfred Quack', 'Mahmoud Soliman']","Skysails Power GmbH is the leading manufacturer of light and efficient power kites that harness the wind's untapped supplies at high altitudes, aiming at profoundly altering wind energy's impact in achieving the global energy transition. Novel, variable trim kites have been developed that allow to modulate the aerodynamic coefficients of the airborne system, significantly improving the overall system efficiency. The flight control of variable trim kites is much more complex than that of previous kite generations and its mastering is a challenge and one of the keys to a successful operation. Numerical optimization is applied to find a set of flight trajectories in order to maximize the energy production while satisfying several constraints on the system operating in a wide range of conditions. This industry abstract provides a general introduction of the trajectory optimization problem with variable trim kites. We also briefly introduce the state-of-the-art optimization setup. This is followed by demonstration of high-quality example results of the optimization. Finally, we discuss the results and their applications."
https://arxiv.org/abs/2403.00381,2024-03-01,Structured Deep Neural Networks-Based Backstepping Trajectory Tracking Control for Lagrangian Systems,"['Jiajun Qian', 'Liang Xu', 'Xiaoqiang Ren', 'Xiaofan Wang']","Deep neural networks (DNN) are increasingly being used to learn controllers due to their excellent approximation capabilities. However, their black-box nature poses significant challenges to closed-loop stability guarantees and performance analysis. In this paper, we introduce a structured DNN-based controller for the trajectory tracking control of Lagrangian systems using backing techniques. By properly designing neural network structures, the proposed controller can ensure closed-loop stability for any compatible neural network parameters. In addition, improved control performance can be achieved by further optimizing neural network parameters. Besides, we provide explicit upper bounds on tracking errors in terms of controller parameters, which allows us to achieve the desired tracking performance by properly selecting the controller parameters. Furthermore, when system models are unknown, we propose an improved Lagrangian neural network (LNN) structure to learn the system dynamics and design the controller. We show that in the presence of model approximation errors and external disturbances, the closed-loop stability and tracking control performance can still be guaranteed. The effectiveness of the proposed approach is demonstrated through simulations."
https://arxiv.org/abs/2403.00380,2024-03-01,A sharp Sobolev trace inequality of order four on three-balls,"['Xuezhang Chen', 'Shihong Zhang']","We establish a fourth order sharp Sobolev trace inequality on three-balls, and its equivalence to a third order sharp Sobolev inequality on two-spheres."
https://arxiv.org/abs/2403.00379,2024-03-01,The Impact of Frequency Bands on Acoustic Anomaly Detection of Machines using Deep Learning Based Model,"['Tin Nguyen', 'Lam Pham', 'Phat Lam', 'Dat Ngo', 'Hieu Tang', 'Alexander Schindler']","In this paper, we propose a deep learning based model for Acoustic Anomaly Detection of Machines, the task for detecting abnormal machines by analysing the machine sound. By conducting extensive experiments, we indicate that multiple techniques of pseudo audios, audio segment, data augmentation, Mahalanobis distance, and narrow frequency bands, which mainly focus on feature engineering, are effective to enhance the system performance. Among the evaluating techniques, the narrow frequency bands presents a significant impact. Indeed, our proposed model, which focuses on the narrow frequency bands, outperforms the DCASE baseline on the benchmark dataset of DCASE 2022 Task 2 Development set. The important role of the narrow frequency bands indicated in this paper inspires the research community on the task of Acoustic Anomaly Detection of Machines to further investigate and propose novel network architectures focusing on the frequency bands."
https://arxiv.org/abs/2403.00378,2024-03-01,A group action on cyclic compositions and $Î³$-positivity,"['Shishuo Fu', 'Jie Yang']","Let $w_{n,k,m}$ be the number of Dyck paths of semilength $n$ with $k$ occurrences of $UD$ and $m$ occurrences of $UUD$. We establish in two ways a new interpretation of the numbers $w_{n,k,m}$ in terms of plane trees and internal nodes. The first way builds on a new characterization of plane trees that involves cyclic compositions. The second proof utilizes a known interpretation of $w_{n,k,m}$ in terms of plane trees and leaves, and a recent involution on plane trees constructed by Li, Lin, and Zhao. Moreover, a group action on the set of cyclic compositions (or equivalently, $2$-dominant compositions) is introduced, which amounts to give a combinatorial proof of the $Î³$-positivity of the Narayana polynomial, as well as the $Î³$-positivity of the polynomial $W_{2k+1,k}(t):=\sum_{1\le m\le k}w_{2k+1,k,m}t^m$ previously obtained by BÃ³na et al, with apparently new combinatorial interpretations of their $Î³$-coefficients."
https://arxiv.org/abs/2403.00377,2024-03-01,Emergence of Accurate Atomic Energies from Machine Learned Noble Gas Potentials,"['Frank Uhlig', 'Samuel Tovey', 'Christian Holm']","The quantum theory of atoms in molecules (QTAIM) gives access to well-defined local atomic energies. Due to their locality, these energies are potentially interesting in fitting atomistic machine learning models as they inform about physically relevant properties. However, computationally, quantum-mechanically accurate local energies are notoriously difficult to obtain for large systems. Here, we show that by employing semi-empirical correlations between different components of the total energy, we can obtain well-defined local energies at a moderate cost. We employ this methodology to investigate energetics in noble liquids or argon, krypton, and their mixture. Instead of using these local energies to fit atomistic models, we show how well these local energies are reproduced by machine-learned models trained on the total energies. The results of our investigation suggest that smaller neural networks, trained only on the total energy of an atomistic system, are more likely to reproduce the underlying local energy partitioning faithfully than larger networks. Furthermore, we demonstrate that networks more capable of this energy decomposition are, in turn, capable of transferring to previously unseen systems. Our results are a step towards understanding how much physics can be learned by neural networks and where this can be applied, particularly how a better understanding of physics aids in the transferability of these neural networks."
https://arxiv.org/abs/2403.00376,2024-03-01,Invariant Test-Time Adaptation for Vision-Language Model Generalization,"['Huan Ma', 'Yan Zhu', 'Changqing Zhang', 'Peilin Zhao', 'Baoyuan Wu', 'Long-Kai Huang', 'Qinghua Hu', 'Bingzhe Wu']","Vision-language foundation models have exhibited remarkable success across a multitude of downstream tasks due to their scalability on extensive image-text paired datasets. However, these models display significant limitations when applied to long-tail tasks, such as fine-grained image classification, as a result of ""decision shortcuts"" that hinders their generalization capabilities. In this work, we find that the CLIP model possesses a rich set of features, encompassing both \textit{desired invariant causal features} and \textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP on downstream tasks originates from its inability to effectively utilize pre-trained features in accordance with specific task requirements. To address this challenge, this paper introduces a test-time prompt tuning paradigm that optimizes a learnable prompt, thereby compelling the model to exploit genuine causal invariant features while disregarding decision shortcuts during the inference phase. The proposed method effectively alleviates excessive dependence on potentially misleading, task-irrelevant contextual information, while concurrently emphasizing critical, task-related visual cues. We conduct comparative analysis of the proposed method against various approaches which validates its effectiveness."
https://arxiv.org/abs/2403.00375,2024-03-01,Polarization-dependent effects in vibrational absorption spectra of 2D finite-size adsorbate islands on dielectric substrates,"['Benedikt Zerulla', 'Marjan KrstiÄ', 'Shuang Chen', 'Zairan Yu', 'Dominik Beutel', 'Christof Holzer', 'Markus Nyman', 'Alexei Nefedov', 'Yuemin Wang', 'Thomas G. MayerhÃ¶fer', 'Christof WÃ¶ll', 'Carsten Rockstuhl']","In the last years, Infrared Reflection-Absorption Spectroscopy (IRRAS) became a standard technique to study vibrational excitations of molecules. These investigations are strongly motivated by perspective applications in monitoring chemical processes. For a better understanding of the adsorption mechanism of molecules on dielectrics, the polarization-dependence of an interaction of infrared light with adsorbates at dielectric surfaces is commonly used. Thus, the peak positions in absorption spectra could be different for s- and p-polarized light. This shift between the peak positions depends on both the molecule itself and the dielectric substrate. While the origin of this shift is well understood for infinite two-dimensional adsorbate layers, finite-size samples, which consist of 2D islands of a small number of molecules, have never been considered. Here, we present a study on polarization-dependent finite-size effects in the optical response of such islands on dielectric substrates. The study uses a multi-scale modeling approach that connects quantum chemistry calculations to Maxwell scattering simulations. We distinguish the optical response of a single molecule, a finite number of molecules, and a two-dimensional adsorbate layer. We analyze CO and CO$_2$ molecules deposited on CeO$_2$ and Al$_2$O$_3$ substrates. The evolution of the shift between the polarization-dependent absorbance peaks is firstly studied for a single molecule, which it does not exhibit for at all, and for finite molecular islands, which it increases with increasing island size for, as well as for an infinite two-dimensional adsorbate layer. In the latter case, the agreement between the obtained results and the experimental IRRAS data and more traditional three/four-layer-model theoretical studies supports the predictive power of the multi-scale approach."
https://arxiv.org/abs/2403.00374,2024-03-01,Amoeba Measures of Random Plane Curves,"['Ali UlaÅ ÃzgÃ¼r KiÅisel', 'Jean-Yves Welschinger']","We prove that the expected area of the amoeba of a complex plane curve of degree $d$ is less than $\displaystyle{3\ln(d)^2/2+9\ln(d)+9}$ and once rescaled by $\ln(d)^2$, is asymptotically bounded from below by $3/4$. In order to get this lower bound, given disjoint isometric embeddings of a bidisc of size $1/\sqrt{d}$ in the complex projective plane, we lower estimate the probability that one of them is a submanifold chart of a complex plane curve. It exponentially converges to one as the number of bidiscs grow to $+\infty$."
https://arxiv.org/abs/2403.00373,2024-03-01,Frobenius rigidity in $\mathbb A^1$-homotopy theory,"['Timo Richarz', 'Jakob Scholbach']",We study the homotopy fixed points under the Frobenius endomorphism on the stable $\mathbb A^1$-homotopy category of schemes in characteristic p>0 and prove a rigidity result for cellular objects in these categories after inverting p. As a consequence we determine the analogous fixed points on the K-theory of algebraically closed fields in positive characteristic. We also prove a rigidity result for the homotopy fixed points of the partial Frobenius pullback on motivic cohomology groups in weights at most 1.
https://arxiv.org/abs/2403.00372,2024-03-01,HyperSDFusion: Bridging Hierarchical Structures in Language and Geometry for Enhanced 3D Text2Shape Generation,"['Zhiying Leng', 'Tolga Birdal', 'Xiaohui Liang', 'Federico Tombari']","3D shape generation from text is a fundamental task in 3D representation learning. The text-shape pairs exhibit a hierarchical structure, where a general text like ""chair"" covers all 3D shapes of the chair, while more detailed prompts refer to more specific shapes. Furthermore, both text and 3D shapes are inherently hierarchical structures. However, existing Text2Shape methods, such as SDFusion, do not exploit that. In this work, we propose HyperSDFusion, a dual-branch diffusion model that generates 3D shapes from a given text. Since hyperbolic space is suitable for handling hierarchical data, we propose to learn the hierarchical representations of text and 3D shapes in hyperbolic space. First, we introduce a hyperbolic text-image encoder to learn the sequential and multi-modal hierarchical features of text in hyperbolic space. In addition, we design a hyperbolic text-graph convolution module to learn the hierarchical features of text in hyperbolic space. In order to fully utilize these text features, we introduce a dual-branch structure to embed text features in 3D feature space. At last, to endow the generated 3D shapes with a hierarchical structure, we devise a hyperbolic hierarchical loss. Our method is the first to explore the hyperbolic hierarchical representation for text-to-shape generation. Experimental results on the existing text-to-shape paired dataset, Text2Shape, achieved state-of-the-art results."
https://arxiv.org/abs/2403.00371,2024-03-01,Quasi-one-dimensional spin transport in antiferromagnetic Z3 nodal net metals,"['Tingli He', 'Lei Li', 'Chaoxi Cui', 'Run-Wu Zhang', 'Zhi-Ming Yu', 'Guodong Liu', 'Xiaoming Zhang']","In three dimensions, the quasi-one-dimensional (Q1D) transport is commonly thought to only appear in the systems with Q1D chain structure. Here, based on first-principle calculations, we go beyond the common belief to show that the Q1D transport can also be realized in many 3D antiferromagnetic (AFM) metals with topological node structure but without Q1D chain structure, including the existing compounds \b{eta}-Fe2(PO4)O and Co2(PO4)O, and LiTi2O4. All these materials have an AFM ground state and exhibit an ideal crossed Z3 Weyl nodal line in each spin channel, formed by three straight and flat nodal lines traversing the whole Brillouin zone. These nodal lines eventually lead to an AFM Z3 nodal net. Surprisingly, we find that the longitudinal conductivity Ïxx in these topological nodal net metals is dozens of times larger than Ïyy and Ïzz in the up-spin channel, while Ïyy dominates the transport in the down-spin channel. This means that each spin channel has a Q1D transport signature, and the principal moving direction for the two spin channels is orthogonal, leading to Q1D direction-dependent spin transport. This novel phenomenon can not be found in both conventional 3D bulk materials and Q1D chain materials, and may solely be induced by the Z3 nodal net, as it gradually disappears when the Fermi level moves away from the nodal net. Our work not only enhances the comprehension of topological physics in antiferromagnets, but also opens a new direction for the exploration of topological spintronics."
https://arxiv.org/abs/2403.00370,2024-03-01,Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview,"['Heyang Liu', 'Yu Wang', 'Yanfeng Wang']","End-to-end (E2E) approach is gradually replacing hybrid models for automatic speech recognition (ASR) tasks. However, the optimization of E2E models lacks an intuitive method for handling decoding shifts, especially in scenarios with a large number of domain-specific rare words that hold specific important meanings. Furthermore, the absence of knowledge-intensive speech datasets in academia has been a significant limiting factor, and the commonly used speech corpora exhibit significant disparities with realistic conversation. To address these challenges, we present Medical Interview (MED-IT), a multi-turn consultation speech dataset that contains a substantial number of knowledge-intensive named entities. We also explore methods to enhance the recognition performance of rare words for E2E models. We propose a novel approach, post-decoder biasing, which constructs a transform probability matrix based on the distribution of training transcriptions. This guides the model to prioritize recognizing words in the biasing list. In our experiments, for subsets of rare words appearing in the training speech between 10 and 20 times, and between 1 and 5 times, the proposed method achieves a relative improvement of 9.3% and 5.1%, respectively."
https://arxiv.org/abs/2403.00369,2024-03-01,Hybrid ultrathin metasurface for broadband sound absorption,"['Marnix P. Abrahams', 'Mourad Oudich', 'Yann Revalor', 'Nicolas Vukadinovic', 'Badreddine Assouar']","To this day, achieving broadband low-frequency sound absorption remains a challenge even with the possibilities promised by the advent of metamaterials and metasurfaces, especially when size and structural restrictions exist. Solving this engineering challenge relies on stringent impedance matching and coupling of the multiple independent local resonators in metasurface absorbers. In this letter, we present an innovative design approach to broaden the sound absorption bandwidth at low-frequency regime. A hybrid metasurface design is proposed where four coupled planar coiled resonators are also coupled to a well designed thin planar cavity. This hybrid metasurface creates a broad sound absorption band (130-200 Hz) that is twice as wide as that of the traditional single layer metasurface utilizing four coiled cavities at a deep sub-wavelength thickness (< Î»/51). This design strategy open routes towards engineering a class of high performance thin metasurfaces for ultra-broadband sound absorption while keeping the planar size unchanged."
https://arxiv.org/abs/2403.00368,2024-03-01,Recommending Target Actions Outside Sessions in the Data-poor Insurance Domain,"['Simone Borg Bruun', 'Christina Lioma', 'Maria Maistro']","Providing personalized recommendations for insurance products is particularly challenging due to the intrinsic and distinctive features of the insurance domain. First, unlike more traditional domains like retail, movie etc., a large amount of user feedback is not available and the item catalog is smaller. Second, due to the higher complexity of products, the majority of users still prefer to complete their purchases over the phone instead of online. We present different recommender models to address such data scarcity in the insurance domain. We use recurrent neural networks with 3 different types of loss functions and architectures (cross-entropy, censored Weibull, attention). Our models cope with data scarcity by learning from multiple sessions and different types of user actions. Moreover, differently from previous session-based models, our models learn to predict a target action that does not happen within the session. Our models outperform state-of-the-art baselines on a real-world insurance dataset, with ca. 44K users, 16 items, 54K purchases and 117K sessions. Moreover, combining our models with demographic data boosts the performance. Analysis shows that considering multiple sessions and several types of actions are both beneficial for the models, and that our models are not unfair with respect to age, gender and income."
https://arxiv.org/abs/2403.00367,2024-03-01,A Novel Quantum Algorithm for Ant Colony Optimization,"['Qian Qiu', 'Mohan Wu', 'Qichun Sun', 'Xiaogang Li', 'Hua Xu']","Quantum ant colony optimization (QACO) has drew much attention since it combines the advantages of quantum computing and ant colony optimization (ACO) algorithms and overcomes some limitations of the traditional ACO algorithm. However, due to the hardware resource limitations of currently available quantum computers, such as the limited number of qubits, lack of high-fidelity gating operation, and low noisy tolerance, the practical application of the QACO is quite challenging. In this paper, we introduce a hybrid quantum-classical algorithm by combining the clustering algorithm with QACO algorithm, so that this extended QACO can handle large-scale optimization problems, which makes the practical application of QACO based on available quantum computation resource possible. To verify the effectiveness and performance of the algorithm, we tested the developed QACO algorithm with the Travelling Salesman Problem (TSP) as benchmarks. The developed QACO algorithm shows better performance under multiple data set. In addition, the developed QACO algorithm also manifests the robustness to noise of calculation process, which is typically a major barrier for practical application of quantum computers. Our work shows that the combination of the clustering algorithm with QACO has effectively extended the application scenario of QACO in current NISQ era of quantum computing."
https://arxiv.org/abs/2403.00366,2024-03-01,Exploring the dynamic interplay of cognitive load and emotional arousal by using multimodal measurements: Correlation of pupil diameter and emotional arousal in emotionally engaging tasks,"['C. Kosel', 'S. Michel', 'T. Seidel', 'M. Foerster']","Multimodal data analysis and validation based on streams from state-of-the-art sensor technology such as eye-tracking or emotion recognition using the Facial Action Coding System (FACTs) with deep learning allows educational researchers to study multifaceted learning and problem-solving processes and to improve educational experiences. This study aims to investigate the correlation between two continuous sensor streams, pupil diameter as an indicator of cognitive workload and FACTs with deep learning as an indicator of emotional arousal (RQ 1a), specifically for epochs of high, medium, and low arousal (RQ 1b). Furthermore, the time lag between emotional arousal and pupil diameter data will be analyzed (RQ 2). 28 participants worked on three cognitively demanding and emotionally engaging everyday moral dilemmas while eye-tracking and emotion recognition data were collected. The data were pre-processed in Phyton (synchronization, blink control, downsampling) and analyzed using correlation analysis and Granger causality tests. The results show negative and statistically significant correlations between the data streams for emotional arousal and pupil diameter. However, the correlation is negative and significant only for epochs of high arousal, while positive but non-significant relationships were found for epochs of medium or low arousal. The average time lag for the relationship between arousal and pupil diameter was 2.8 ms. In contrast to previous findings without a multimodal approach suggesting a positive correlation between the constructs, the results contribute to the state of research by highlighting the importance of multimodal data validation and research on convergent vagility. Future research should consider emotional regulation strategies and emotional valence."
https://arxiv.org/abs/2403.00365,2024-03-01,Can a Funny Chatbot Make a Difference? Infusing Humor into Conversational Agent for Behavioral Intervention,"['Xin Sun', 'Isabelle Teljeur', 'Zhuying Li', 'Jos A. Bosch']","Regular physical activity is crucial for reducing the risk of non-communicable disease (NCD). With NCDs on the rise globally, there is an urgent need for effective health interventions, with chatbots emerging as a viable and cost-effective option because of limited healthcare accessibility. Although health professionals often utilize behavior change techniques (BCTs) to boost physical activity levels and enhance client engagement and motivation by affiliative humor, the efficacy of humor in chatbot-delivered interventions is not well-understood. This study conducted a randomized controlled trial to examine the impact of the generative humorous communication style in a 10-day chatbot-delivered intervention for physical activity. It further investigated if user engagement and motivation act as mediators between the communication style and changes in physical activity levels. 66 participants engaged with the chatbots across three groups (humorous, non-humorous, and no-intervention) and responded to daily ecological momentary assessment questionnaires assessing engagement, motivation, and physical activity levels. Multilevel time series analyses revealed that an affiliative humorous communication style positively impacted physical activity levels over time, with user engagement acting as a mediator in this relationship, whereas motivation did not. These findings clarify the role of humorous communication style in chatbot-delivered physical activity interventions, offering valuable insights for future development of intelligent conversational agents incorporating humor."
https://arxiv.org/abs/2403.00364,2024-03-01,Optimal Control of a Diffusive Epidemiological Model Involving the Caputo-Fabrizio Fractional Time-Derivative,"['Achraf Zinihi', 'Moulay Rchid Sidi Ammi', 'Matthias Ehrhardt']","In this work we study a fractional SEIR biological model of a reaction-diffusion, using the non-singular kernel Caputo-Fabrizio fractional derivative in the Caputo sense and employing the Laplacian operator. In our PDE model, the government seeks immunity through the vaccination program, which is considered a control variable. Our study aims to identify the ideal control pair that reduces the number of infected/infectious people and the associated vaccine and treatment costs over a limited time and space. Moreover, by using the forward-backward algorithm, the approximate results are explained by dynamic graphs to monitor the effectiveness of vaccination."
